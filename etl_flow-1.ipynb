{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306d153a-b457-46bd-bee6-9178b77fb766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 run_etl.json files found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2236/2384020999.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event:  -DATASET- values:  {'-DATASET-': 'Paid Solicitors Disclosed on Charity Registration Forms in Colorado', '-ETL-': 'ETL Summary'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standardized Title for Dataset</th>\n",
       "      <th>Data Link</th>\n",
       "      <th>CIM Data Type</th>\n",
       "      <th>GoCodePublishYear</th>\n",
       "      <th>Standardized Short Description</th>\n",
       "      <th>CIM Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Paid Solicitors Disclosed on Charity Registrat...</td>\n",
       "      <td>wwbh-7bpa</td>\n",
       "      <td>table</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Paid Solicitors and Professional Fundraising C...</td>\n",
       "      <td>https://data.colorado.gov/dataset/wwbh-7bpa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Standardized Title for Dataset  Data Link  \\\n",
       "221  Paid Solicitors Disclosed on Charity Registrat...  wwbh-7bpa   \n",
       "\n",
       "    CIM Data Type  GoCodePublishYear  \\\n",
       "221         table                1.0   \n",
       "\n",
       "                        Standardized Short Description  \\\n",
       "221  Paid Solicitors and Professional Fundraising C...   \n",
       "\n",
       "                                        CIM Link  \n",
       "221  https://data.colorado.gov/dataset/wwbh-7bpa  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paid Solicitors Disclosed on Charity Registration Forms in Colorado\n",
      "node /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\n",
      "T2 extract:\n",
      "    language     :  node\n",
      "    file             :  general/scripts/sftp_extract.js\n",
      "    options       : -f charity/char_orgs_sol.txt\n",
      "                       : -o cdos/business/nonprofit/data_source/\n",
      "                       : -a .tsv\n",
      "\n",
      "\n",
      "transform:\n",
      "    language     :  node\n",
      "    file             :  scripts/char_orgs_sol.js\n",
      "\n",
      "\n",
      "load:\n",
      "    file             :  char_paid_solicitors.sij\n",
      "    type             :  datasync\n",
      "    format         :  csv\n",
      "    load_file   :  char_orgs_sol.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actions Strings\n",
      "Extract\n",
      "node /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\n",
      "Link  221    https://data.colorado.gov/dataset/wwbh-7bpa\n",
      "Name: CIM Link, dtype: object 0\n",
      "event:  -EXTRACT- values:  {'-DATASET-': 'Paid Solicitors Disclosed on Charity Registration Forms in Colorado', '-ETL-': 'extract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv'}\n",
      "event:  -EXTRACT- values:  {'-DATASET-': 'Paid Solicitors Disclosed on Charity Registration Forms in Colorado', '-ETL-': 'extract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:44.588Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:44.892Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:44.892Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:44.912Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:48.639Z'}\n",
      "event:  -EXTRACT- values:  {'-DATASET-': 'Paid Solicitors Disclosed on Charity Registration Forms in Colorado', '-ETL-': 'extract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:44.588Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:44.892Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:44.892Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:44.912Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:48.639Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:48.736Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:48.974Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:48.974Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:48.988Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:51.041Z'}\n",
      "event:  -EXTRACT- values:  {'-DATASET-': 'Paid Solicitors Disclosed on Charity Registration Forms in Colorado', '-ETL-': 'extract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:44.588Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:44.892Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:44.892Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:44.912Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:48.639Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:48.736Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:48.974Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:48.974Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:48.988Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:51.041Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:51.137Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:51.441Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:51.441Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:51.456Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:54.933Z'}\n",
      "event:  -EXTRACT- values:  {'-DATASET-': 'Paid Solicitors Disclosed on Charity Registration Forms in Colorado', '-ETL-': 'extract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:44.588Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:44.892Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:44.892Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:44.912Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:48.639Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:48.736Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:48.974Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:48.974Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:48.988Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:51.041Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:51.137Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:51.441Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:51.441Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:51.456Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:54.933Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:55.033Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:55.341Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:55.341Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:55.361Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:58.565Z'}\n",
      "event:  -EXTRACT- values:  {'-DATASET-': 'Paid Solicitors Disclosed on Charity Registration Forms in Colorado', '-ETL-': 'extract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:44.588Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:44.892Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:44.892Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:44.912Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:48.639Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:48.736Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:48.974Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:48.974Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:48.988Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:51.041Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:51.137Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:51.441Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:51.441Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:51.456Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:54.933Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:55.033Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:55.341Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:55.341Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:55.361Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:58.565Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:58.659Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:58.925Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:58.925Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:58.944Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:21:02.233Z'}\n",
      "event:  Quit values:  {'-DATASET-': 'Paid Solicitors Disclosed on Charity Registration Forms in Colorado', '-ETL-': 'extract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:44.588Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:44.892Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:44.892Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:44.912Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:48.639Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:48.736Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:48.974Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:48.974Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:48.988Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:51.041Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:51.137Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:51.441Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:51.441Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:51.456Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:54.933Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:55.033Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:55.341Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:55.341Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:55.361Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:20:58.565Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:20:58.659Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:20:58.925Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:20:58.925Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:20:58.944Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:21:02.233Z\\n\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-01T04:21:02.326Z\\ninfo msg: Connection to SFTP server made at 2023-08-01T04:21:02.574Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-01T04:21:02.574Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-07-26T19:07:01-06:00 at 2023-08-01T04:21:02.593Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-01T04:21:05.368Z'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys,os,inspect\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from cronsim import CronSim\n",
    "import argparse\n",
    "import json\n",
    "import PySimpleGUI as sg\n",
    "#import PySimpleGUIWeb as sg\n",
    "import pathlib\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import re\n",
    "import webbrowser\n",
    "import subprocess\n",
    "import collections\n",
    "import pyglet,tkinter\n",
    "from pyglet import font\n",
    "# import OpenGL\n",
    "# from OpenGL import GLU\n",
    "font.add_file('/etc/fonts/fonts/CENTAUR.TTF')\n",
    "font='Courier 10 bold '\n",
    "\n",
    "def splitL(data):\n",
    "    if data:\n",
    "        head, *tail = data  # This is a nicer way of doing head, tail = data[0], data[1:]\n",
    "        return {head: splitL(tail)}\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "groups = []\n",
    "desktop = pathlib.Path(\"/home/joe/bic_etl\")\n",
    "runEtls = []\n",
    "dataSets = []\n",
    "# .rglob() produces a generator too\n",
    "desktop.rglob(\"*\")\n",
    "files = list(desktop.rglob(\"*\"))\n",
    "# Which you can wrap in a list() constructor to materialize\n",
    "for ff in files:\n",
    "    # if ff.find(\"run_etl.json\") >  0:\n",
    "     \n",
    "        if (str(ff).split(\"/\")[-1] == \"run_etl.json\"):     \n",
    "            a=str(ff).split(\"/\")\n",
    "            m = a.index(\"bic_etl\")\n",
    "  #          print(ff)\n",
    "            b = a[m+1:-1]\n",
    "            ll = splitL(b)\n",
    "            groups.append(ll)\n",
    "            runEtls.append(ff)\n",
    "            \n",
    "print(f\"{len(runEtls)} run_etl.json files found\")\n",
    "\n",
    "def go_deeper(aDict,value,nit):\n",
    "    nit+=1\n",
    "    for k, v in aDict.items():\n",
    "         if not bool(v):            \n",
    "             aDict[k] = []\n",
    "             aDict[k].append(value)\n",
    "         elif isinstance(v,list):\n",
    "             aDict[k].append(value)\n",
    "         else:\n",
    "             go_deeper(v,value,nit)\n",
    "   \n",
    "    return aDict\n",
    "\n",
    "\n",
    "dataSets = []\n",
    "groups = []\n",
    "for file in runEtls:\n",
    "  f = open(file,\"r\")\n",
    "  data = json.load(f)\n",
    "  # print(file)\n",
    "  # print(\"----\")\n",
    "  a=str(file).split(\"/\")\n",
    "  m = a.index(\"bic_etl\")\n",
    "  b = a[m+1:-1]\n",
    "  ll = splitL(b)\n",
    "#  print(ll)\n",
    "#  groups.append(ll)\n",
    "  for val in data:\n",
    "        if \"title\" in val:\n",
    "              title=val[\"title\"]\n",
    "#              print(title,ll)\n",
    "              nit=0\n",
    "              ll = go_deeper(ll,title,nit)\n",
    " #             print(ll)\n",
    " #             groups.append(ll)\n",
    "        dataSets.append(val)\n",
    "#  print(\"FF \",ll) \n",
    "  groups.append(ll)\n",
    "\n",
    "datasets = []\n",
    "dataSetsEtl={}\n",
    "for val in dataSets:\n",
    "    if \"title\" in val:\n",
    "      datasets.append(val[\"title\"])\n",
    "      title=val[\"title\"]\n",
    "      dataSetsEtl[title] = {}  \n",
    "      for k,v in val.items():\n",
    "      #      print(k,v)\n",
    "            if k != \"title\":\n",
    "                dataSetsEtl[title][k] = {}\n",
    "                if isinstance(v,dict):\n",
    "                    for k1,v1 in v.items():\n",
    "                        dataSetsEtl[title][k][k1]=v1\n",
    "                        \n",
    "datasets = sorted(datasets)\n",
    "\n",
    "mf = pd.read_excel(\"BICDataInventoryandMetadata.xlsx\",skiprows=0,sheet_name=\"Inventory_Active\",engine=\"openpyxl\")\n",
    "def map4x4(row):\n",
    "    \n",
    "    if isinstance(row[\"Data Link\"],str) and  len(row[\"Data Link\"]) == 9 and re.findall( \"\\w{4}-\\w{4}\",row[\"Data Link\"]):\n",
    "  #      link = '<a href=\"https://data.colorado.gov/dataset/{}\">{}</a>'.format(row[\"Data Link\"],row[\"Data Link\"])\n",
    "        \n",
    "        link = 'https://data.colorado.gov/dataset/{}'.format(row[\"Data Link\"])\n",
    "    else:\n",
    "        link = \"\"\n",
    "        \n",
    "    return link\n",
    "    \n",
    "mf[\"CIM Link\"] = mf.apply(map4x4,axis=1)\n",
    "\n",
    "mf=mf.loc[~mf[\"Standardized Title for Dataset\"].isna()]\n",
    "mfShort = mf[['Standardized Title for Dataset', 'Data Link','CIM Data Type','GoCodePublishYear','Standardized Short Description','CIM Link']]\n",
    "mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)\n",
    "\n",
    "def exceptionLog(exception,funCall):\n",
    "  exception_message = str(exception)\n",
    "  exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "  filename = os.path.split(exception_traceback.tb_frame.f_code.co_filename)[1]\n",
    "  print(f\"{exception_message} {exception_type} {funCall}, Line {exception_traceback.tb_lineno}\")\n",
    "\n",
    "def getFile(how,file,WindowP):\n",
    "    if how == \"Local\":\n",
    "        if file[-3:].lower() == \"tsv\":\n",
    "            delim = \"\\t\"\n",
    "            df=pd.read_csv(file,encoding=\"latin\",delimiter=delim)\n",
    "        elif file[-4:].lower() == \"xlsx\":\n",
    "            df=pd.read_excel(file,engine=\"openpyxl\")\n",
    "        else:\n",
    "            try:\n",
    "                df=pd.read_csv(file)\n",
    "            except Exception as err:\n",
    "                print(\"Error, trying with encoding=latin\")\n",
    "                df=pd.read_csv(file,encoding=\"latin\")\n",
    "    elif how == \"Fetch\":\n",
    "        print(\"Getting that web data\")\n",
    "        file=values[\"-WEB-\"]\n",
    "        getPrevFiles(2,file)\n",
    "\n",
    "        windowP[\"-PINFO-\"].update(f\"START reading WEB File:{file}:\")\n",
    "        df=pd.read_csv(file)\n",
    "        windowP[\"-PINFO-\"].update(f\"FINISHED reading WEB File:{file}:\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "##############################################################\n",
    "def setRowColors(lst,col1,col2,colsp,header):\n",
    "    count=0\n",
    "    colors = {}\n",
    "    nrec = header.index(\"% Missing\")\n",
    "    for vals in lst:\n",
    "        key = vals[0]\n",
    "        if count%2 == 0:\n",
    "            colors[key] = col1\n",
    "        else:\n",
    "            colors[key] = col2\n",
    "        if vals[nrec] > 99.0:\n",
    "            colors[key] = colsp\n",
    "        count+=1\n",
    "    colTab = []\n",
    "    for key,colr in colors.items():\n",
    "        colTab.append(colr)\n",
    "    rowNums = [num for num in range(0,len(colTab)+1)]\n",
    "    colText = [\"black\"]*len(colTab)\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "        \n",
    "    return colrw\n",
    "\n",
    "###########################################################\n",
    "def sortTable(row,stats,colSortState,table,event,header):\n",
    "    \n",
    "        e = table.user_bind_event \n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        if region == 'heading':\n",
    "            row = 0\n",
    "        elif region == 'cell':\n",
    "            row = int(table.Widget.identify_row(e.y))\n",
    "   \n",
    "        if row == 0:\n",
    "            colClicked = int(table.Widget.identify_column(e.x)[1:])\n",
    "            statClicked = header[colClicked-1].strip()\n",
    "            colSortState[statClicked]*=-1\n",
    "            if colSortState[statClicked] == -1:\n",
    "                sortAsc=False\n",
    "            else:\n",
    "                sortAsc=True\n",
    "            if colClicked > 1:  # user number sort\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[1][statClicked],reverse=sortAsc))\n",
    "            else:\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[0],reverse=sortAsc))\n",
    "\n",
    "\n",
    "            statsVals=[]\n",
    "            for col in statsS:\n",
    "                 vals=[]\n",
    "                 vals.append(col)\n",
    "                 for k in header[1:]:\n",
    "                    vals.append(statsS[col][k.strip()])\n",
    "                 statsVals.append(vals)\n",
    "           # slen= len(statsVals)\n",
    "#             colorsTable = setRowColors(statsVals,\"#b3f0ff\",\"#33d6ff\",\"pink\",header_list)\n",
    "\n",
    "#             window['-TABLE-'].update(values=statsVals,row_colors=colorsTable)\n",
    "        return statsVals,colSortState\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "def dfAnalyze(df):\n",
    "    stats = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        typs = df[col].apply(type).value_counts().to_dict()\n",
    "        stats[col] = {}\n",
    "        if str in typs:\n",
    "           stats[col][\"string\"] = typs[str]\n",
    "        else:\n",
    "           stats[col][\"string\"] = 0\n",
    "\n",
    "        if int in typs:\n",
    "           stats[col][\"integer\"] = typs[int]\n",
    "        else:\n",
    "           stats[col][\"integer\"] = 0\n",
    "\n",
    "        if float in typs:\n",
    "           stats[col][\"float\"] = typs[float]\n",
    "        else:\n",
    "           stats[col][\"float\"] = 0\n",
    "\n",
    "        if bool in typs:\n",
    "           stats[col][\"boolean\"] = typs[bool]\n",
    "        else:\n",
    "           stats[col][\"boolean\"] = 0\n",
    "\n",
    "        stats[col][\"Missing\"] = df[col].isna().sum()\n",
    "        stats[col][\"% Missing\"] = round(df[col].isna().sum()/df.shape[0]*100,1)\n",
    "        \n",
    "    return stats\n",
    "#############################################  \n",
    "def getValues(stats,header):\n",
    "\n",
    "    statsVals=[]\n",
    "    for col in sorted(stats.keys()):\n",
    "         vals=[]\n",
    "         vals.append(col)\n",
    "         for k in header[1:]:\n",
    "            vals.append(stats[col][k.strip()])\n",
    "         statsVals.append(vals)\n",
    "    return statsVals     \n",
    "############################################################\n",
    "def getFilesClicked(values,window):\n",
    "        if len(values[\"-FILE1-\"]) > 0:\n",
    "            file = values[\"-FILE1-\"]\n",
    "        elif len(values[\"-WEB1-\"]) > 0:\n",
    "            file = values[\"-WEB1-\"]\n",
    "        \n",
    "        df = getFile(\"Local\",file,window)\n",
    "        stats = dfAnalyze(df)\n",
    "\n",
    "        return df,stats,file\n",
    "\n",
    "############################################################\n",
    "\n",
    "def getRowClicked(table,columns):\n",
    "    col=\"\"\n",
    "    e = table.user_bind_event \n",
    "    region = table.Widget.identify('region', e.x, e.y)\n",
    "    if region == 'heading':\n",
    "        row = 0\n",
    "    elif region == 'cell':\n",
    "        row = int(table.Widget.identify_row(e.y))  \n",
    "        col = columns[row-1][0]\n",
    "    return row,col    \n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def showDFUN(col,unq,windowParent,colr1,colr2):\n",
    "  \n",
    "    valuesUNQ = list(zip(unq.index.tolist(),unq.tolist()))\n",
    "    hUNQ = []\n",
    "    hUNQ.append(\"Values\")\n",
    "    hUNQ.append(\"Count\")\n",
    "\n",
    "    \n",
    "    sortState = {}\n",
    "    for val in hUNQ:\n",
    "        sortState[val]=-1\n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Showing unique Values for Column\"),sg.Text(f\" {col}\",text_color=\"red\"),sg.Text(f\" and Reg Ex\",text_color=\"black\")],\n",
    "                \n",
    "                   [sg.Button('Quit')],\n",
    "            \n",
    "                   [sg.Button('Write Unique'),\n",
    "                    sg.Table(values=valuesUNQ,\n",
    "                       background_color=colr1,vertical_scroll_only=False,col_widths=60,font='Courier 10 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',alternating_row_color=colr2,\n",
    "                       key='-TABLE-', headings = hUNQ,metadata=sortState)]\n",
    "            ]\n",
    "    window2 = sg.Window(f\"Unique\", layout2,finalize=True,resizable=True, grab_anywhere=False)\n",
    "\n",
    "    table = window2['-TABLE-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    return window2,table,valuesUNQ,hUNQ\n",
    "\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def sortUniqe(table,window,dataStore,headerStore):\n",
    "    try:\n",
    "        e = table.user_bind_event\n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        sortAsc = {}\n",
    "        sortAsc[1] =False\n",
    "        sortAsc[-1]=True\n",
    "        print(\"R \",region)\n",
    "        if region == 'heading':\n",
    "            values = dataStore[table]\n",
    "           \n",
    "            header = headerStore[table]\n",
    "           \n",
    "            column = int(table.Widget.identify_column(e.x)[1:])\n",
    "            col=header[column-1]\n",
    "          \n",
    "            sortState = table.metadata\n",
    "            sortState[col]*=-1\n",
    "            table.metadata = sortState\n",
    "          \n",
    "            values = sorted(values, key=lambda element: (element[column-1]),reverse=sortAsc[sortState[col]]) \n",
    "           \n",
    "            window[\"-TABLE-\"].update(values=values)\n",
    "            dataStore[table] = values\n",
    "    except Exception as err:\n",
    "        exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "                    \n",
    "        \n",
    "\n",
    "def wrap(string, lenght=60):\n",
    "    if isinstance(string,str):\n",
    "       return '\\n'.join(textwrap.wrap(string, lenght))\n",
    "    else:\n",
    "        return \"\"\n",
    "def runETL(k):\n",
    "    global extract,a,string\n",
    "    text2 = \"\"\n",
    "    print(k)\n",
    "## Build Summary Text string\n",
    "    for ky1 in dataSetsEtl[k].keys():\n",
    "        text2+=f\"{ky1}:\\n\" \n",
    "        for k2,v2 in dataSetsEtl[k][ky1].items(): \n",
    "            sl = 10 - len(k2)\n",
    "            s = \" \"*sl\n",
    "        \n",
    "            if isinstance(v2,list) == False:\n",
    "                text2+=f\"    {k2:10s}{s} :  {v2}\\n\"\n",
    "            else:\n",
    "                text2+=f\"    {k2:10s}{s} : {v2[0]}\\n\"\n",
    "                if len(v2) > 1:\n",
    "                    for val in v2[1:]:\n",
    "                        text2+= f\"                   {s} : {val}\\n\"\n",
    "\n",
    "        text2+=f\"\\n\\n\"\n",
    "## Build actions\n",
    "    extract = \"\"\n",
    "    if 'extract' in dataSetsEtl[ds]:\n",
    "        if (dataSetsEtl[ds]['extract']['language'] == 'node'):\n",
    "            pgm =  dataSetsEtl[ds]['extract']['file']\n",
    "            options=\"\"\n",
    "            if 'options' in dataSetsEtl[ds]['extract']:\n",
    "\n",
    "                for opts in dataSetsEtl[ds]['extract']['options']:\n",
    "                    options+= f\" {opts}\" \n",
    "            extract = f\"node /home/joe/bic_etl/{pgm} {options}\"\n",
    "            print(extract)\n",
    "    text2+=f\"\\n\\nActions Strings\\nExtract\\n{extract}\"\n",
    "        \n",
    "    return text2,extract\n",
    "    \n",
    "    \n",
    "def cronGUI():\n",
    "    global ds,text2,a,string\n",
    "    header_list = list(mfShort.columns)\n",
    "    # mfV = []\n",
    "    # a = [\"\",\"\",nan,nan,\"\"]\n",
    "    # mfV.append(a)\n",
    "    layout = [\n",
    "             [sg.Text(\"BIC Cron DataSets\")],\n",
    "             [sg.Combo(datasets,enable_events=True,key=\"-DATASET-\",font='Courier 10 bold ')],\n",
    "              [sg.Button('Quit'),sg.Button(\"Plot Crons\")],\n",
    "              [sg.Button(\"Extract\",font='Courier 10 bold ',key=\"-EXTRACT-\",visible=False)],\n",
    "              [sg.Button('Go to CIM Dataset',visible=False,key=\"-LINK-\",metadata=\"\")],\n",
    "              [sg.Text(text=\"Dataset Summary\",enable_events=True,font='Courier 15 bold ',background_color=\"blue\",key=\"-OUTPUT-\",size=[70,10]),\n",
    "       #       [sg.Multiline(default_text=\"Dataset Summary\",key=\"-OUTPUT-\",size=[70,10]),\n",
    "\n",
    "               sg.Multiline(default_text=\"ETL Summary\",key=\"-ETL-\",size=[70,20],font='Courier 15 bold ')\n",
    "              ]\n",
    "\n",
    "       ]\n",
    "    # Create the Window\n",
    "    sg.theme('Dark Green 5')\n",
    "    window2 = sg.Window('ETL', layout,finalize=True,resizable=True)\n",
    "    #window = sg.Window('Window Title', layout, web_port=2222, web_start_browser=False)\n",
    "    #table = window2['-TABLE2-']\n",
    "\n",
    "    #window2.move(window.current_location()[0]+600, window.current_location()[1])\n",
    "    try: \n",
    "        while True:\n",
    "\n",
    "            event, values = window2.read()\n",
    "            print('event: ',event, 'values: ',values)\n",
    " #           print(\"W2\",event,values)\n",
    "        #    window, event, values = sg.read_all_windows()\n",
    "            if event == sg.WIN_CLOSED or event == 'Quit':\n",
    "                window2.close()\n",
    "        #        sys.exit(1)\n",
    "                what = \"QUIT\"\n",
    "                break\n",
    "            elif event == \"-DATASET-\":\n",
    "\n",
    "                (ds)  = list(values.items())\n",
    "                ds=ds[0][1]\n",
    "                mmf = mfShort.loc[mfShort[\"Standardized Title for Dataset\"].str.strip() == ds.strip()]\n",
    "                if mmf.shape[0] > 0:\n",
    "                #            mmf[\"Standardized Short Description\"] = mmf[\"Standardized Short Description\"].map(wrap)          \n",
    "                    text = f\"Title             : {mmf['Standardized Title for Dataset'].values.tolist()[0]}\\nSocrata        : {mmf['Data Link'].values.tolist()[0]}\\nData Type    : {mmf['CIM Data Type'].values.tolist()[0]}\\nPublish Year: {mmf['GoCodePublishYear'].values.tolist()[0]}\\nCIM Link : {mmf['CIM Link'].values.tolist()[0]}\\nDescription  : {mmf['Standardized Short Description'].values.tolist()[0]}\"            \n",
    "                    display(mmf)\n",
    "                else:\n",
    "                    text = \"None\"\n",
    "                if ds in dataSetsEtl:\n",
    "                      text2,extract = runETL(ds)\n",
    "                else:\n",
    "                      text2=\"\"\n",
    "                      extract = \"\"\n",
    "                if len(extract) > 10:\n",
    "                    window2[\"-EXTRACT-\"].update(visible=True)\n",
    "                print(\"T2\",text2)\n",
    "                window2[\"-OUTPUT-\"].update(text)\n",
    "                window2[\"-ETL-\"].update(text2)\n",
    "                link =  mmf['CIM Link'].values.tolist()[0]\n",
    "                print(\"Link \",mmf['CIM Link'],link.find(\"http\"))\n",
    "                \n",
    "                if link.find(\"http\") > -1:\n",
    "                     window2[\"-LINK-\"].update (visible=True)\n",
    "                else:\n",
    "                     window2[\"-LINK-\"].update (visible=False)\n",
    "               \n",
    "            elif event == \"-LINK-\":\n",
    "                    print(\"Going To: \",link) \n",
    "                    if len(link) > 10:\n",
    "                        webbrowser.open(link)\n",
    "            elif event == \"Plot Crons\":    \n",
    "                plotCrons(crons_all)\n",
    "                \n",
    "            elif event == \"-EXTRACT-\":\n",
    "                a=subprocess.run(extract,shell=True,capture_output=True,text=True)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"Extract Output\\n\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= \"fError:\\n {a.stderr}\"\n",
    "                string+=f\"STDOUT: {a.stdout}\"\n",
    "                window2[\"-ETL-\"].update(string,append=True)\n",
    "             #   sg.popup(string)\n",
    "                \n",
    "    except  Exception as err: \n",
    "       exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "    \n",
    "cronGUI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70477181-d53b-4b61-b80e-a14874a998b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fileBrowser",
   "language": "python",
   "name": "filebrowser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
