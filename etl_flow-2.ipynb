{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5247b38-4a96-46a3-8945-a8fd5b731a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 run_etl.json files found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1803/2531032954.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event:  GO values:  {'-DATASET-': '', '-ETL-': 'ETL Summary'}\n",
      "event:  -EXTRACT- values:  {'-DATASET-': '', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/char_orgs_sol.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/wwbh-7bpa/rows.csv?accessType=DOWNLOAD'}\n",
      "event:  -EXTRACTANAL- values:  {'-DATASET-': '', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/char_orgs_sol.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/wwbh-7bpa/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-10T17:15:09.774Z\\ninfo msg: Connection to SFTP server made at 2023-08-10T17:15:10.212Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-10T17:15:10.213Z\\ndebug msg: File updated 16 hours ago. at 2023-08-10T17:15:10.237Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-10T17:15:17.576Z'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1803/2531032954.py:298: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file,encoding=\"latin\",delimiter=delim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event:  -TABLEFILE-Click values:  {'-TABLEFILE-': []}\n",
      "event:  Quit values:  {'-TABLE-': []}\n",
      "event:  Quit values:  {'-TABLEFILE-': [2]}\n",
      "event:  Close values:  {'-DATASET-': '', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/char_orgs_sol.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/wwbh-7bpa/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-10T17:15:09.774Z\\ninfo msg: Connection to SFTP server made at 2023-08-10T17:15:10.212Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-10T17:15:10.213Z\\ndebug msg: File updated 16 hours ago. at 2023-08-10T17:15:10.237Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-10T17:15:17.576Z'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys,os,inspect\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from cronsim import CronSim\n",
    "import argparse\n",
    "import json\n",
    "import PySimpleGUI as sg\n",
    "#import PySimpleGUIWeb as sg\n",
    "import pathlib\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import re\n",
    "from shlex import split\n",
    "import webbrowser\n",
    "import subprocess\n",
    "import collections\n",
    "import pyglet,tkinter\n",
    "from pyglet import font\n",
    "global datasets\n",
    "# import OpenGL\n",
    "# from OpenGL import GLU\n",
    "font.add_file('/etc/fonts/fonts/CENTAUR.TTF')\n",
    "font='Courier 10 bold '\n",
    "bicHome = \"/home/joe/bic_etl/\"\n",
    "numWindows=0\n",
    "headerStore = {}\n",
    "\n",
    "colorPairs = [[\"#D6EAF8\",\"#85C1E9\"],[\"#b3f0ff\",\"#33d6ff\"],[\"#D5F5E3\",\"#A3E4D7\"],[\"#FCF3CF\",\"#F7DC6F\"]]\n",
    "windowsOpen = {}\n",
    "windowsOpen[\"main\"] = []\n",
    "windowsOpen[\"unique\"] = []\n",
    "\n",
    "#############################################\n",
    "\n",
    "def runETL(k):\n",
    "    global extract,a,string,dataSetsEtl\n",
    "    text2 = \"\"\n",
    "  #  print(k)\n",
    "    directory = \"\"\n",
    "    group = \"\"\n",
    "    if \"info\" in dataSetsEtl[k]:\n",
    "        if \"directory\" in dataSetsEtl[k][\"info\"]:\n",
    "            directory = dataSetsEtl[k][\"info\"][\"directory\"]\n",
    "            group = dataSetsEtl[k][\"info\"][\"group\"]\n",
    "            \n",
    "## Build Summary Text string\n",
    "    for ky1 in dataSetsEtl[k].keys():\n",
    "        text2+=f\"{ky1}:\\n\" \n",
    "        for k2,v2 in dataSetsEtl[k][ky1].items(): \n",
    "            sl = 10 - len(k2)\n",
    "            s = \" \"*sl\n",
    "        \n",
    "            if isinstance(v2,list) == False:\n",
    "                text2+=f\"    {k2:10s}{s} :  {v2}\\n\"\n",
    "            else:\n",
    "                text2+=f\"    {k2:10s}{s} : {v2[0]}\\n\"\n",
    "                if len(v2) > 1:\n",
    "                    for val in v2[1:]:\n",
    "                        text2+= f\"                   {s} : {val}\\n\"\n",
    "        text2+=f\"\\n\\n\"\n",
    "## Build actions\n",
    "    extract = \"\"\n",
    "    if 'extract' in dataSetsEtl[ds]:\n",
    "        if (dataSetsEtl[ds]['extract']['language'] == 'node'):\n",
    "            pgm =  dataSetsEtl[ds]['extract']['file']\n",
    "            options=\"\"\n",
    "            if 'options' in dataSetsEtl[ds]['extract']:\n",
    "\n",
    "                for opts in dataSetsEtl[ds]['extract']['options']:\n",
    "                    options+= f\" {opts}\" \n",
    "            extract = f\"node {bicHome}{pgm} {options}\"\n",
    "        #    print(extract)\n",
    "    if 'transform' in dataSetsEtl[ds]:\n",
    "        \n",
    "        if dataSetsEtl[ds][\"transform\"][\"language\"] == \"node\":\n",
    "            ff=dataSetsEtl[ds][\"transform\"][\"file\"]\n",
    "            transform=f\"node {bicHome}{directory}/{ff}\"\n",
    "            \n",
    "        else:\n",
    "            file=\"\"        \n",
    "        \n",
    "    text2+=f\"\\n\\nActions Strings\\nExtract\\n{extract}\\n\\nTransform\\n{transform}\"\n",
    "        \n",
    "    return text2,extract,transform\n",
    "\n",
    "###############################################\n",
    "\n",
    "def compareWindow(stats1,df1,file1,title=\"Compare\",colorTheme=\"'Dark Green 5'\"):\n",
    "    global color1,color2\n",
    "    header_list = [\"Column\",\"% Missing\",\"Missing\",\"string\",\"integer\",\"float\",\"boolean\"]\n",
    "  \n",
    "    col_widths = [8]*len(header_list)\n",
    "    col_widths[0] = 25\n",
    "    columnSortStateTable1 = {}\n",
    "  \n",
    "\n",
    "    ## set up sort state for the column in both tables\n",
    "    for col in header_list:\n",
    "         columnSortStateTable1[col] = -1\n",
    "       \n",
    "            \n",
    "    valsFile1 = getValues(stats1,header_list)\n",
    "   \n",
    "    \n",
    "    rowFile1Colors = setRowColors(valsFile1,color1,color2,\"pink\",header_list)\n",
    "    \n",
    "    layCol1 = [[sg.Text(f\"File 1 {file1}\",font=\"CENTAUR 15\")],[sg.Text(f\"File 1 Shape {df1.shape}\",font=\"CENTAUR 15\")],\n",
    "               [sg.Table(values=valsFile1,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=20,col_widths=col_widths,font=\"CENTAUR 10\",\n",
    "                   justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                   key='-TABLEFILE-',row_colors=rowFile1Colors,headings = header_list,metadata=columnSortStateTable1)]\n",
    "               ]\n",
    "    \n",
    "\n",
    "    layout = [[sg.Button(\"Quit\")],\n",
    "    layCol1]  \n",
    "        \n",
    "\n",
    "              \n",
    "    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(title,layout,finalize=True,resizable=True,metadata=colorTheme)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableFile1 = window2['-TABLEFILE-']\n",
    "    tableFile1.bind('<Button-1>', \"Click\")\n",
    "    headerStore[tableFile1] = header_list\n",
    "    return window2,tableFile1,valsFile1,rowFile1Colors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "\n",
    "def stringArgs(string):\n",
    "#  This is set to decode the extract string to get the location and name of the \n",
    "#  extracted data file\n",
    "    h =split(string)\n",
    "    inf = h.index(\"-f\")\n",
    "    inf = h[inf+1]\n",
    "    ot = h.index(\"-a\")\n",
    "    ot = h[ot+1]\n",
    "    of = h.index(\"-o\")\n",
    "    of = h[of+1]\n",
    "    inf=inf.replace(inf[-4:],ot)\n",
    "    f = inf.split(\"/\")\n",
    "    finalFile = f\"{bicHome}{of}{f[-1]}\"\n",
    "    return finalFile\n",
    " \n",
    "###################################################    \n",
    "\n",
    "def splitL(data):\n",
    "    if data:\n",
    "        head, *tail = data  # This is a nicer way of doing head, tail = data[0], data[1:]\n",
    "        return {head: splitL(tail)}\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def go_deeper(aDict,value,nit):\n",
    "    nit+=1\n",
    "    for k, v in aDict.items():\n",
    "         if not bool(v):            \n",
    "             aDict[k] = []\n",
    "             aDict[k].append(value)\n",
    "         elif isinstance(v,list):\n",
    "             aDict[k].append(value)\n",
    "         else:\n",
    "             go_deeper(v,value,nit)\n",
    "   \n",
    "    return aDict\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def init():\n",
    "    global dataSetsEtl,datasets\n",
    "    groups = []\n",
    "    desktop = pathlib.Path(\"/home/joe/bic_etl\")\n",
    "    runEtls = []\n",
    "    dataSets = []\n",
    "    info = {}\n",
    "    # .rglob() produces a generator too\n",
    "    desktop.rglob(\"*\")\n",
    "    files = list(desktop.rglob(\"*\"))\n",
    "# Which you can wrap in a list() constructor to materialize\n",
    "    for ff in files:\n",
    "\n",
    "            if (str(ff).split(\"/\")[-1] == \"run_etl.json\"):     \n",
    "                a=str(ff).split(\"/\")\n",
    "                m = a.index(\"bic_etl\")\n",
    "                b = a[m+1:-1]\n",
    "                ll = splitL(b)\n",
    "                groups.append(ll)\n",
    "                runEtls.append(ff)\n",
    "            \n",
    "    print(f\"{len(runEtls)} run_etl.json files found\")    \n",
    "    \n",
    "    dataSets = []\n",
    "    groups = []\n",
    "    for file in runEtls:\n",
    "      f = open(file,\"r\")\n",
    "      data = json.load(f)\n",
    "      # print(file)\n",
    "      # print(\"----\")\n",
    "      a=str(file).split(\"/\")\n",
    "      m = a.index(\"bic_etl\")\n",
    "      b = a[m+1:-1]\n",
    "      group = b[0]\n",
    "      ll = splitL(b)\n",
    "      bdir = \"/\".join(b)  \n",
    "      \n",
    "    #  groups.append(ll)\n",
    "      for val in data:\n",
    "            if \"title\" in val:\n",
    "                  title=val[\"title\"]\n",
    "                  info[title]={}\n",
    "                  info[title][\"directory\"] = bdir\n",
    "                  info[title][\"group\"] = group\n",
    "                \n",
    "    #              print(title,ll)\n",
    "                  nit=0\n",
    "                  ll = go_deeper(ll,title,nit)\n",
    "             #     info[title][\"groups\"] = ll\n",
    "            \n",
    "     #             print(ll)\n",
    "     #             groups.append(ll)\n",
    "            dataSets.append(val)\n",
    "    #  print(\"FF \",ll) \n",
    "      groups.append(ll)\n",
    "\n",
    "    datasets = []\n",
    "    dataSetsEtl={}\n",
    "    for val in dataSets:\n",
    "        if \"title\" in val:\n",
    "          datasets.append(val[\"title\"])\n",
    "          title=val[\"title\"]\n",
    "          dataSetsEtl[title] = {}  \n",
    "          dataSetsEtl[title][\"info\"] = {}\n",
    "          dataSetsEtl[title][\"info\"][\"directory\"] = info[title][\"directory\"]\n",
    "          dataSetsEtl[title][\"info\"][\"group\"] = info[title][\"group\"]\n",
    "     #     dataSetsEtl[title][\"info\"][\"groups\"] = info[title][\"groups\"]\n",
    "            \n",
    "        \n",
    "            \n",
    "          for k,v in val.items():\n",
    "          #      print(k,v)\n",
    "                if k != \"title\":\n",
    "                    dataSetsEtl[title][k] = {}\n",
    "                    if isinstance(v,dict):\n",
    "                        for k1,v1 in v.items():\n",
    "                            dataSetsEtl[title][k][k1]=v1\n",
    "\n",
    "    return sorted(datasets)\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def map4x4(row):\n",
    "    \n",
    "    if isinstance(row[\"Data Link\"],str) and  len(row[\"Data Link\"]) == 9 and re.findall( \"\\w{4}-\\w{4}\",row[\"Data Link\"]):\n",
    "  #      link = '<a href=\"https://data.colorado.gov/dataset/{}\">{}</a>'.format(row[\"Data Link\"],row[\"Data Link\"])\n",
    "        \n",
    "        link = 'https://data.colorado.gov/dataset/{}'.format(row[\"Data Link\"])\n",
    "    else:\n",
    "        link = \"\"\n",
    "        \n",
    "    return link\n",
    "    \n",
    "#     mf[\"CIM Link\"] = mf.apply(map4x4,axis=1)\n",
    "\n",
    "#     mf=mf.loc[~mf[\"Standardized Title for Dataset\"].isna()]\n",
    "#     mfShort = mf[['Standardized Title for Dataset', 'Data Link','CIM Data Type','GoCodePublishYear','Standardized Short Description','CIM Link']]\n",
    "#     mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def exceptionLog(exception,funCall):\n",
    "  exception_message = str(exception)\n",
    "  exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "  filename = os.path.split(exception_traceback.tb_frame.f_code.co_filename)[1]\n",
    "  print(f\"{exception_message} {exception_type} {funCall}, Line {exception_traceback.tb_lineno}\")\n",
    "\n",
    "######################################################    \n",
    "    \n",
    "def getFile(how,file,WindowP):\n",
    "    \n",
    "    if how == \"Local\":\n",
    "        if file[-3:].lower() == \"tsv\":\n",
    "            delim = \"\\t\"\n",
    "            df=pd.read_csv(file,encoding=\"latin\",delimiter=delim)\n",
    "        elif file[-4:].lower() == \"xlsx\":\n",
    "            df=pd.read_excel(file,engine=\"openpyxl\")\n",
    "        else:\n",
    "            try:\n",
    "                df=pd.read_csv(file)\n",
    "            except Exception as err:\n",
    "                print(\"Error, trying with encoding=latin\")\n",
    "                df=pd.read_csv(file,encoding=\"latin\")\n",
    "    elif how == \"Fetch\":\n",
    "      \n",
    "  #      file=values[\"-WEB-\"]\n",
    "      #  getPrevFiles(2,file)\n",
    "\n",
    "  #      windowP[\"-PINFO-\"].update(f\"START reading WEB File:{file}:\")\n",
    "        df=pd.read_csv(file)\n",
    "      \n",
    "  #      windowP[\"-PINFO-\"].update(f\"FINISHED reading WEB File:{file}:\")\n",
    "   \n",
    "    stats = dfAnalyze(df)\n",
    "        \n",
    "    return df,stats\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def setRowColors(lst,col1,col2,colsp,header):\n",
    "    count=0\n",
    "    colors = {}\n",
    "    # print(\"SRC head \",header)\n",
    "    # print(\"SRC list\",lst)\n",
    "\n",
    "    nrec = header.index(\"% Missing\")\n",
    "    for vals in lst:\n",
    "        key = vals[0]\n",
    "        if count%2 == 0:\n",
    "            colors[key] = col1\n",
    "        else:\n",
    "            colors[key] = col2\n",
    "        if vals[nrec] > 99.0:\n",
    "           \n",
    "            colors[key] = colsp\n",
    "        count+=1\n",
    "    colTab = []\n",
    "    for key,colr in colors.items():\n",
    "        colTab.append(colr)\n",
    "    rowNums = [num for num in range(0,len(colTab)+1)]\n",
    "    colText = [\"black\"]*len(colTab)\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "  \n",
    "    return colrw\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def setRowColorsGeneric(lst,col1,col2):\n",
    "    count=0\n",
    "    rowNums=[]\n",
    "    colTab=[]\n",
    "\n",
    "    for vals in lst:       \n",
    "        if count%2 == 0:\n",
    "            colTab.append(col1)\n",
    "        else:\n",
    "            colTab.append(col2)\n",
    "        rowNums.append(count)\n",
    "        count+=1\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "  \n",
    "    return colrw\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def sortTable(row,stats,table,event,header):\n",
    "    \n",
    "        e = table.user_bind_event \n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        if region == 'heading':\n",
    "            row = 0\n",
    "        elif region == 'cell':\n",
    "            row = int(table.Widget.identify_row(e.y))\n",
    "   \n",
    "        if row == 0:\n",
    "            colSortState = table.metadata\n",
    "            colClicked = int(table.Widget.identify_column(e.x)[1:])\n",
    "            header = headerStore[table]\n",
    "            \n",
    "            statClicked = header[colClicked-1].strip()\n",
    "           \n",
    "            colSortState[statClicked]*=-1\n",
    "            if colSortState[statClicked] == -1:\n",
    "                sortAsc=False\n",
    "            else:\n",
    "                sortAsc=True\n",
    "            if colClicked > 1:  # user number sort\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[1][statClicked],reverse=sortAsc))\n",
    "            else:\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[0],reverse=sortAsc))\n",
    "\n",
    "\n",
    "            statsVals=[]\n",
    "            for col in statsS:\n",
    "                 vals=[]\n",
    "                 vals.append(col)\n",
    "                 for k in header[1:]:\n",
    "                    vals.append(statsS[col][k.strip()])\n",
    "                 statsVals.append(vals)\n",
    "           # slen= len(statsVals)\n",
    "#             colorsTable = setRowColors(statsVals,\"#b3f0ff\",\"#33d6ff\",\"pink\",header_list)\n",
    "\n",
    "#             window['-TABLE-'].update(values=statsVals,row_colors=colorsTable)\n",
    "        \n",
    "        return statsVals,colSortState\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "def dfAnalyze(df):\n",
    "    stats = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        typs = df[col].apply(type).value_counts().to_dict()\n",
    "        stats[col] = {}\n",
    "        if str in typs:\n",
    "           stats[col][\"string\"] = typs[str]\n",
    "        else:\n",
    "           stats[col][\"string\"] = 0\n",
    "\n",
    "        if int in typs:\n",
    "           stats[col][\"integer\"] = typs[int]\n",
    "        else:\n",
    "           stats[col][\"integer\"] = 0\n",
    "\n",
    "        if float in typs:\n",
    "           stats[col][\"float\"] = typs[float]\n",
    "        else:\n",
    "           stats[col][\"float\"] = 0\n",
    "\n",
    "        if bool in typs:\n",
    "           stats[col][\"boolean\"] = typs[bool]\n",
    "        else:\n",
    "           stats[col][\"boolean\"] = 0\n",
    "\n",
    "        stats[col][\"Missing\"] = df[col].isna().sum()\n",
    "        stats[col][\"% Missing\"] = round(df[col].isna().sum()/df.shape[0]*100,1)\n",
    "        \n",
    "    return stats\n",
    "\n",
    "############################################# \n",
    "\n",
    "def getValues(stats,header):\n",
    "\n",
    "    statsVals=[]\n",
    "    for col in sorted(stats.keys()):\n",
    "         vals=[]\n",
    "         vals.append(col)\n",
    "         for k in header[1:]:\n",
    "            vals.append(stats[col][k.strip()])\n",
    "         statsVals.append(vals)\n",
    "    return statsVals     \n",
    "############################################################\n",
    "\n",
    "def getFilesClicked(file,window):\n",
    "#         if len(values[\"-FILE1-\"]) > 0:\n",
    "#             file = values[\"-FILE1-\"]\n",
    "#         elif len(values[\"-WEB1-\"]) > 0:\n",
    "#             file = values[\"-WEB1-\"]\n",
    "      \n",
    "        df = getFile(\"Local\",file,window)\n",
    "        stats = dfAnalyze(df)\n",
    "\n",
    "        return df,stats\n",
    "\n",
    "############################################################\n",
    "\n",
    "def getRowClicked(table,columns):\n",
    "    col=\"\"\n",
    "    e = table.user_bind_event \n",
    "    region = table.Widget.identify('region', e.x, e.y)\n",
    "    if region == 'heading':\n",
    "        row = 0\n",
    "    elif region == 'cell':\n",
    "        row = int(table.Widget.identify_row(e.y))  \n",
    "        col = columns[row-1][0]\n",
    "    return row,col    \n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def showDFUN(col,unq,windowParent,colr1,colr2,colorTheme):\n",
    "    global dataStore\n",
    "    valuesUNQ = list(zip(unq.index.tolist(),unq.tolist()))\n",
    "    hUNQ = []\n",
    "    hUNQ.append(\"Values\")\n",
    "    hUNQ.append(\"Count\")\n",
    "\n",
    "    \n",
    "    sortState = {}\n",
    "    for val in hUNQ:\n",
    "        sortState[val]=-1\n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Showing unique Values for Column\"),sg.Text(f\" {col}\",text_color=\"white\",font='Courier 15 bold '),sg.Text(f\" and Reg Ex\",text_color=\"white\",font='Courier 10 bold ')],\n",
    "                \n",
    "                   [sg.Button('Quit')],\n",
    "            \n",
    "                   [sg.Button('Write Unique'),\n",
    "                    sg.Table(values=valuesUNQ,\n",
    "                       background_color=colr1,vertical_scroll_only=False,col_widths=60,font='Courier 10 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',alternating_row_color=colr2,\n",
    "                       key='-TABLE-', headings = hUNQ,metadata=sortState)]\n",
    "            ]\n",
    "    sg.theme(colorTheme)    \n",
    "    window2 = sg.Window(f\"Unique\", layout2,finalize=True,resizable=True, grab_anywhere=False)\n",
    "\n",
    "    table = window2['-TABLE-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    dataStore[table]=valuesUNQ\n",
    "    \n",
    "    return window2,table,valuesUNQ,hUNQ\n",
    "\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def sortUniqe(table,window,dataStore,headerStore):\n",
    "    global color1,color2\n",
    "    try:\n",
    "        e = table.user_bind_event\n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        sortAsc = {}\n",
    "        sortAsc[1] =False\n",
    "        sortAsc[-1]=True\n",
    "   #     print(\"R \",region)\n",
    "        if region == 'heading':\n",
    "            values = dataStore[table]\n",
    "            \n",
    "           \n",
    "            header = headerStore[table]\n",
    "            # print(\"SU header \",header)\n",
    "            column = int(table.Widget.identify_column(e.x)[1:])\n",
    "            col=header[column-1]\n",
    "            \n",
    "            sortState = table.metadata\n",
    "           \n",
    "            sortState[col]*=-1\n",
    "            table.metadata = sortState\n",
    "          \n",
    "            values = sorted(values, key=lambda element: (element[column-1]),reverse=sortAsc[sortState[col]]) \n",
    "#            rowFile1Colors = setRowColors(values,color1,color2,\"pink\",header)\n",
    "            rowFile1Colors = setRowColorsGeneric(values,color1,color2)\n",
    "\n",
    "            window[\"-TABLE-\"].update(values=values)\n",
    "            dataStore[table] = values\n",
    "    except Exception as err:\n",
    "        exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "                    \n",
    "#####################################################        \n",
    "\n",
    "def wrap(string, lenght=60):\n",
    "    if isinstance(string,str):\n",
    "       return '\\n'.join(textwrap.wrap(string, lenght))\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "############################################################\n",
    "       \n",
    "def cronGUI():\n",
    "    global ds,text2,a,string,numWindows,color1,color2,file,transform,dataStore\n",
    "    dataStore = {}\n",
    "    datasets = init()\n",
    "  \n",
    "    mf = pd.read_excel(\"BICDataInventoryandMetadata.xlsx\",skiprows=0,sheet_name=\"Inventory_Active\",engine=\"openpyxl\")\n",
    "    \n",
    "    mf[\"CIM Link\"] = mf.apply(map4x4,axis=1)\n",
    "\n",
    "    mf=mf.loc[~mf[\"Standardized Title for Dataset\"].isna()]\n",
    "    mfShort = mf[['Standardized Title for Dataset', 'Data Link','CIM Data Type','GoCodePublishYear','Standardized Short Description','CIM Link']]\n",
    "    mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)   \n",
    "    \n",
    "    header_list = list(mfShort.columns)\n",
    "    # mfV = []\n",
    "    # a = [\"\",\"\",nan,nan,\"\"]\n",
    "    # mfV.append(a)\n",
    "    layout = [\n",
    "             [sg.Text(\"BIC Cron DataSets\")],\n",
    "             [sg.Combo(datasets,enable_events=True,key=\"-DATASET-\",font='Courier 10 bold ')],\n",
    "              [sg.Button('Close'),sg.Button(\"Plot Crons\")],\n",
    "             [sg.Button(\"GO\")],\n",
    "              [sg.Button(\"Extract\",font='Courier 10 bold ',key=\"-EXTRACT-\",visible=False),\n",
    "               sg.Button(\"Analyze-Extr\",font='Courier 10 bold ',key=\"-EXTRACTANAL-\",visible=False),\n",
    "               sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-EXTRACTINFO-\")],\n",
    "              [sg.Button(\"Transform\",visible=False,font='Courier 10 bold ',key=\"-TRANSFORM-\"),\n",
    "               sg.Button(\"Ananlyze-Trans\",font='Courier 10 bold ',key=\"-TRANSFORMANAL-\",visible=False),\n",
    "               sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-TRANSFORMINFO-\")\n",
    "              ],\n",
    "              [sg.Button(\"CIM API\",font='Courier 15 bold ',key=\"-CIMAPI-\",visible=False),sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-CIMINFO-\")],\n",
    "              [sg.Text(text=\"Dataset Summary\",enable_events=True,font='Courier 15 bold ',background_color=\"blue\",key=\"-OUTPUT-\",size=[70,10]),\n",
    "               sg.Multiline(default_text=\"ETL Summary\",key=\"-ETL-\",size=[70,20],font='Courier 15 bold ')]\n",
    "              ]\n",
    "\n",
    "       \n",
    "    # Create the Window\n",
    "    sg.theme('Dark Green 5')\n",
    "    window2 = sg.Window('ETL', layout,finalize=True,resizable=True)\n",
    "    #window = sg.Window('Window Title', layout, web_port=2222, web_start_browser=False)\n",
    "    #table = window2['-TABLE2-']\n",
    "\n",
    "    #window2.move(window.current_location()[0]+600, window.current_location()[1])\n",
    "    try: \n",
    "        while True:\n",
    "\n",
    "         #   event, values = window2.read()\n",
    "            wid, event, values = sg.read_all_windows()\n",
    "            print('event: ',event, 'values: ',values)\n",
    " \n",
    "            if event == sg.WIN_CLOSED or event == 'Close':\n",
    "                window2.close()\n",
    "                break\n",
    "            elif event ==  event == 'Quit':\n",
    "                wid.close()\n",
    "                \n",
    "           # elif event == \"-DATASET-\":\n",
    "            elif event == \"GO\":#\n",
    "             \n",
    "                (ds)  = list(values.items())\n",
    "                ds=ds[0][1]\n",
    "                ds = \"Paid Solicitors Disclosed on Charity Registration Forms in Colorado\"\n",
    "          \n",
    "                mmf = mfShort.loc[mfShort[\"Standardized Title for Dataset\"].str.strip() == ds.strip()]\n",
    "                cim4x4 = mmf['Data Link'].values.tolist()[0]\n",
    "                cimApi = f\"https://data.colorado.gov/api/views/{cim4x4}/rows.csv?accessType=DOWNLOAD\"\n",
    "                if mmf.shape[0] > 0:\n",
    "                #            mmf[\"Standardized Short Description\"] = mmf[\"Standardized Short Description\"].map(wrap)          \n",
    "                    text = f\"Title             : {mmf['Standardized Title for Dataset'].values.tolist()[0]}\\nSocrata        : {mmf['Data Link'].values.tolist()[0]}\\nData Type    : {mmf['CIM Data Type'].values.tolist()[0]}\\nPublish Year: {mmf['GoCodePublishYear'].values.tolist()[0]}\\nCIM Link : {mmf['CIM Link'].values.tolist()[0]}\\nDescription  : {mmf['Standardized Short Description'].values.tolist()[0]}\"            \n",
    "                   # display(mmf)\n",
    "                else:\n",
    "                    text = \"None\"\n",
    "                if ds in dataSetsEtl:\n",
    "                      text2,extract,transform = runETL(ds)\n",
    "                else:\n",
    "                      text2=\"\"\n",
    "                      extract = \"\"\n",
    "                if len(extract) > 10:\n",
    "                    window2[\"-EXTRACT-\"].update(visible=True)\n",
    "                if len(transform) > 10:\n",
    "                    window2[\"-TRANSFORM-\"].update(visible=True)\n",
    "                    window2[\"-TRANSFORM-\"].update(visible=True)\n",
    "          \n",
    "                if len(cimApi) > 10:                 \n",
    "                    text2+=  f\"\\n\\nCIM API\\n{cimApi}\"\n",
    "                    window2[\"-CIMAPI-\"].update(visible=True)\n",
    "                    \n",
    "                   \n",
    "                window2[\"-OUTPUT-\"].update(text)\n",
    "                window2[\"-ETL-\"].update(text2)\n",
    "                link =  mmf['CIM Link'].values.tolist()[0]\n",
    "           #     print(\"Link \",mmf['CIM Link'],link.find(\"http\"))\n",
    "                \n",
    "                # if link.find(\"http\") > -1:\n",
    "                #      window2[\"-LINK-\"].update (visible=True)\n",
    "                # else:\n",
    "                #      window2[\"-LINK-\"].update (visible=False)\n",
    "               \n",
    "            elif event == \"-LINK-\":\n",
    "                    print(\"Going To: \",link) \n",
    "                    if len(link) > 10:\n",
    "                        webbrowser.open(link)\n",
    "            elif event == \"Plot Crons\":    \n",
    "                plotCrons(crons_all)\n",
    "                \n",
    "            elif event == \"-CIMAPI-\":\n",
    "                  #  df1,stats1 = getFilesClicked(cimApi,window2)\n",
    "                    df1,stats1 = getFile(\"Fetch\",cimApi,window2)\n",
    "                    \n",
    "                    color1 = colorPairs[numWindows][0]\n",
    "                    color2 = colorPairs[numWindows][1]\n",
    "\n",
    "                    numWindows+=1\n",
    "                    if numWindows > len(colorPairs):\n",
    "                        numWindows=0\n",
    "\n",
    "                    WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1,df1,cimApi,\"CMI Analysis\",\"DarkRed\")\n",
    "                    dataStore[tabl1]=valsFile1\n",
    "                    \n",
    "                    windowsOpen[\"main\"].append(WindowC)        \n",
    "                \n",
    "            elif event == \"-TRANSFORM-\":\n",
    "               \n",
    "                a=subprocess.run(transform,shell=True,capture_output=True,text=True)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"TRANSFORM Output\\n\"\n",
    "                tfile=\"\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= f\"Error:\\n {a.stderr}\"\n",
    "                else:\n",
    "                    for msg in a.stdout.split(\"debug msg:\"):    \n",
    "                        if msg.find(\"final file is at:\") > -1:\n",
    "                           \n",
    "                            tmp = msg.split(\" \")\n",
    "                            tfile = tmp[-3]\n",
    "                            if os.path.isfile(tfile):\n",
    "                                \n",
    "                                window2[\"-TRANSFORMANAL-\"].update(visible=True)\n",
    "                                fileStats = os.stat(tfile)\n",
    "                                dt = datetime.fromtimestamp(fileStats.st_ctime)\n",
    "                                string = f\"{fileStats.st_size:,} bytes Created: {dt}  file: {tfile}\"\n",
    "                                window2[\"-TRANSFORMINFO-\"].update(string,visible=True)\n",
    "                            \n",
    "                    string+=f\"STDOUT: {a.stdout}\"\n",
    "                    window2[\"-ETL-\"].update(string,append=True)    \n",
    "            elif event == \"-TRANSFORMANAL-\":\n",
    "                #    df1,stats1 = getFilesClicked(tfile,window2)\n",
    "                    df1,stats1 = getFile(\"Local\",tfile,window2)\n",
    "                    \n",
    "                    color1 = colorPairs[numWindows][0]\n",
    "                    color2 = colorPairs[numWindows][1]\n",
    "                  \n",
    "                    numWindows+=1\n",
    "                    if numWindows > len(colorPairs):\n",
    "                        numWindows=0\n",
    "\n",
    "                    WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1,df1,tfile,\"Transform Analysis\",\"DarkPurple\")\n",
    "                    dataStore[tabl1]=valsFile1\n",
    "                    windowsOpen[\"main\"].append(WindowC)    \n",
    "                  \n",
    "            elif event == \"-EXTRACT-\":\n",
    "                a=subprocess.run(extract,shell=True,capture_output=True,text=True)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"Extract Output\\n\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= \"fError:\\n {a.stderr}\"\n",
    "                string+=f\"STDOUT: {a.stdout}\"\n",
    "                window2[\"-ETL-\"].update(string,append=True)\n",
    "                sx = string.find(\"successfully download to\")\n",
    "                string[sx+25:]\n",
    "                sxo = string[sx+25:].find(\"!\")\n",
    "             \n",
    "                file=f\"/home/joe/bic_etl{string[sx+25:sx+25+sxo]}\"\n",
    "              \n",
    "                if os.path.isfile(file):\n",
    "                  \n",
    "                    window2[\"-EXTRACTANAL-\"].update(visible=True)\n",
    "                    fileStats = os.stat(file)\n",
    "                    dt = datetime.fromtimestamp(fileStats.st_ctime)\n",
    "                    string = f\"{fileStats.st_size:,} bytes Created: {dt}  file: {file}\"\n",
    "                    window2[\"-EXTRACTINFO-\"].update(string,visible=True)\n",
    "                      \n",
    "            elif event == \"-EXTRACTANAL-\":\n",
    "                file=stringArgs(extract)\n",
    "                \n",
    "             #   df1,stats1 = getFilesClicked(file,window2)\n",
    "                df1,stats1 = getFile(\"Local\",file,window2)\n",
    "                \n",
    "                color1 = colorPairs[numWindows][0]\n",
    "                color2 = colorPairs[numWindows][1]\n",
    "                \n",
    "                numWindows+=1\n",
    "                if numWindows > len(colorPairs):\n",
    "                    numWindows=0\n",
    "                    \n",
    "                WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1,df1,file,\"Extract Analysis\",\"DarkBlue16\")\n",
    "                dataStore[tabl1]=valsFile1\n",
    "                windowsOpen[\"main\"].append(WindowC)\n",
    "            \n",
    "            ###########\n",
    "            elif event == \"-TABLEFILE-Click\":\n",
    "               \n",
    "                row,col=getRowClicked(tabl1,valsFile1)\n",
    "               \n",
    "                if row == 0:\n",
    "                   header = headerStore[tabl1]\n",
    "                  \n",
    "                   valsFile1,columnSortStateTable1 = sortTable(row,stats1,tabl1,event,header)          \n",
    "                   rowFile1Colors=setRowColors(valsFile1,color1,color2,\"pink\",header)\n",
    "                   wid[\"-TABLEFILE-\"].update(values=valsFile1,row_colors=rowFile1Colors)\n",
    "                   wid[\"-TABLEFILE-\"].metadata=columnSortStateTable1\n",
    "                else:\n",
    "                    unq = df1[col].value_counts()\n",
    "                    colorTheme=wid.metadata\n",
    "                    w,t,values,uHead = showDFUN(col,unq,wid,color1,color2,colorTheme)\n",
    "                  #dataStore[t] = values\n",
    "                    headerStore[t] = uHead\n",
    "                    windowsOpen[\"main\"].append(w)\n",
    "            elif event == \"-TABLE-Click\":\n",
    "              \n",
    "                table = wid['-TABLE-']\n",
    "               \n",
    "                \n",
    "                sortUniqe(table,wid,dataStore,headerStore)\n",
    "                \n",
    "    except  Exception as err: \n",
    "       exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    " \n",
    "for wid in windowsOpen[\"main\"]:\n",
    "    print(\"window MA\",wid)\n",
    "    if wid:\n",
    "        print(\"cosing \",wid)\n",
    "        wid.close()\n",
    "        wid = None\n",
    "\n",
    "cronGUI()\n",
    "\n",
    "\n",
    "\n",
    "### Bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142982a8-7994-4e81-96e6-be6d9b9bdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.theme_previewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44390dd0-0fec-4cbb-8bf2-dfb62052e4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fileBrowser",
   "language": "python",
   "name": "filebrowser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
