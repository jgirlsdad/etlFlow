{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5247b38-4a96-46a3-8945-a8fd5b731a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 run_etl.json files found\n",
      "{'id': '1pVj8GwL13QtiyX7qG1xWf0kLacZwG7gV2wGT4xqmHCE', 'name': 'BIC Data Inventory and Metadata', 'createdTime': '2023-06-14T16:13:40.567Z', 'modifiedTime': '2023-08-07T19:07:17.931Z'}\n",
      "{'id': '1WTaOglzbSsYiHhAGguGxHQXmAGmOhfFHkGkMLowxAOA', 'name': 'BIC Data Inventory and Metadata-OLD', 'createdTime': '2021-05-19T20:34:56.598Z', 'modifiedTime': '2023-06-14T17:17:41.383Z'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1949/2641892562.py:749: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event:  4x4 values:  {'-DATASET-': '', '-4x4-': 'wwbh-7bpa', '-ETL-': 'ETL Summary'}\n",
      "XREF DS  wwbh-7bpa Paid Solicitors Disclosed on Charity Registration Forms in Colorado\n",
      "event:  -EXTRACT- values:  {'-DATASET-': '', '-4x4-': 'wwbh-7bpa', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/char_orgs_sol.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/wwbh-7bpa/rows.csv?accessType=DOWNLOAD'}\n",
      "event:  -EXTRACTANAL- values:  {'-DATASET-': '', '-4x4-': 'wwbh-7bpa', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/char_orgs_sol.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/wwbh-7bpa/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-12T01:05:30.891Z\\ninfo msg: Connection to SFTP server made at 2023-08-12T01:05:31.155Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-12T01:05:31.155Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-08-09T19:07:50-06:00 at 2023-08-12T01:05:31.170Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-12T01:05:34.343Z'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1949/2641892562.py:384: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file,encoding=\"latin\",delimiter=delim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event:  Column Analysis values:  {'-DATASET-': '', '-4x4-': 'wwbh-7bpa', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/char_orgs_sol.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/wwbh-7bpa/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-12T01:05:30.891Z\\ninfo msg: Connection to SFTP server made at 2023-08-12T01:05:31.155Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-12T01:05:31.155Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-08-09T19:07:50-06:00 at 2023-08-12T01:05:31.170Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-12T01:05:34.343Z'}\n",
      "TRFILE  /home/joe/bic_etl/cdos/business/nonprofit/scripts/char_orgs_sol.js\n",
      "XrfT2O  {'    let tRow                   = {};': '    let tRow                   = {};', 'entityId': 'entity_id_input', 'documentId': 'Document Id', 'fein': 'Ce Fein', 'name': 'Org Name', 'nameofPS-PFC-CCV': 'Ol Org Name', 'title': 'Ol Title', 'firstName': 'Ol Fname', 'middleName': 'Ol Mname', 'lastName': 'Ol Lname', 'registrantTypeAbbr': 'Person Type', 'registrantType': 'Person Type]', 'address': 'Address', 'city': 'State', 'state': 'State', 'zipCode': 'Zip', 'zipCode4': 'Zip', 'mailingAddress': 'Ol Maddr', 'mailingCity': 'Ol Mcity', 'mailingState': 'OlMstate', 'mailingZipCode': 'Ol Mzip', 'mailingZipCode4': 'Ol Mzip', 'performedAddress': 'Ol Waddr', 'performedCity': 'Ol Wcity', 'performedState': 'Ol Wstate', 'performedZipCode': 'Ol Wzip', 'performedZipCode4': 'Ol Wzip', 'phone': 'Ol Wphone'}\n",
      "event:  Quit values:  {'-TABLECOLUMN-': []}\n",
      "event:  Quit values:  {'-TABLEFILE-': []}\n",
      "event:  Close values:  {'-DATASET-': '', '-4x4-': 'wwbh-7bpa', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/char_orgs_sol.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/wwbh-7bpa/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-12T01:05:30.891Z\\ninfo msg: Connection to SFTP server made at 2023-08-12T01:05:31.155Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-12T01:05:31.155Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-08-09T19:07:50-06:00 at 2023-08-12T01:05:31.170Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-12T01:05:34.343Z'}\n",
      "window MA <PySimpleGUI.PySimpleGUI.Window object at 0x7f3048118b50>\n",
      "cosing  <PySimpleGUI.PySimpleGUI.Window object at 0x7f3048118b50>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys,os,inspect\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from cronsim import CronSim\n",
    "import argparse\n",
    "import json\n",
    "import PySimpleGUI as sg\n",
    "#import PySimpleGUIWeb as sg\n",
    "import pathlib\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import re\n",
    "from shlex import split\n",
    "import webbrowser\n",
    "import subprocess\n",
    "import collections\n",
    "import pyglet,tkinter\n",
    "from pyglet import font\n",
    "\n",
    "import requests\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "global datasets\n",
    "# import OpenGL\n",
    "# from OpenGL import GLU\n",
    "font.add_file('/etc/fonts/fonts/CENTAUR.TTF')\n",
    "font='Courier 10 bold '\n",
    "bicHome = \"/home/joe/bic_etl/\"\n",
    "numWindows=0\n",
    "headerStore = {}\n",
    "\n",
    "colorPairs = [[\"#D6EAF8\",\"#85C1E9\"],[\"#b3f0ff\",\"#33d6ff\"],[\"#D5F5E3\",\"#A3E4D7\"],[\"#FCF3CF\",\"#F7DC6F\"]]\n",
    "windowsOpen = {}\n",
    "windowsOpen[\"main\"] = []\n",
    "windowsOpen[\"unique\"] = []\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "def getXrefs():\n",
    "    scope = ['https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "             \"https://www.googleapis.com/auth/drive.file\",\n",
    "                  \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json',\n",
    "     scope)\n",
    "    client = gspread.authorize(creds)\n",
    "\n",
    "    gc = gspread.service_account(\"./client_secret.json\")\n",
    "    for gg in gc.list_spreadsheet_files():\n",
    "         print(gg)\n",
    "    # https://docs.google.com/spreadsheets/d/1WTaOglzbSsYiHhAGguGxHQXmAGmOhfFHkGkMLowxAOA/edit?usp=sharing\n",
    "    sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "        'Maintenance_Framework')\n",
    "    repo_sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "        'MetadataRepository')\n",
    "\n",
    "    dfRepo = pd.DataFrame(repo_sheet.get_all_records(head=3))\n",
    "    xrefsBy4x4 = {}\n",
    "    xrefsByTitle = {}\n",
    "\n",
    "    for index,row in dfRepo[['Dataset Title','Socrata Link']].iterrows():\n",
    "        xrefsByTitle[row['Dataset Title']] = row['Socrata Link']\n",
    "        xrefsBy4x4[row['Socrata Link']] = row['Dataset Title']\n",
    "        \n",
    "    return xrefsBy4x4,xrefsByTitle\n",
    "    \n",
    "#############################################\n",
    "\n",
    "def showDfRecs(df1,colUn,val,windowP,title=\"DF Unique Record Values\"):\n",
    "    global color1,color2\n",
    "    header_list = list(df1.columns)\n",
    "  \n",
    "    col_widths = [8]*len(header_list)\n",
    " #   col_widths[0] = 25\n",
    "    columnSortStateTable1 = {}\n",
    "  \n",
    "\n",
    "    ## set up sort state for the column in both tables\n",
    "    for col in header_list:\n",
    "        columnSortStateTable1[col] = -1\n",
    "       \n",
    "            \n",
    "#    valsFile1 = getValues(stats1,header_list)\n",
    "    values = df1.values.tolist()\n",
    "    \n",
    "    rowFile1Colors = setRowColorsGeneric(values,color1,color2)\n",
    "    \n",
    "    layout = [[sg.Text(f\"Column: \",font=\"CENTAUR 10\"),\n",
    "               sg.Text(f\"{colUn}\",font=\"CENTAUR 15\")],\n",
    "              [sg.Text(f\"Unique Value: \",font=\"CENTAUR 10\"),\n",
    "               sg.Text(f\"{val}\",font=\"CENTAUR 15\")],\n",
    "               [sg.Button(\"Quit\")],\n",
    "               [sg.Table(values=values,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=20,col_widths=col_widths,font=\"CENTAUR 10\",\n",
    "                   justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                   key='-TABLEFILE-',row_colors=rowFile1Colors,headings = header_list,metadata=columnSortStateTable1)]\n",
    "               ]\n",
    "    \n",
    "\n",
    " \n",
    "\n",
    "    colorTheme = windowP.metadata[0]          \n",
    "#    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(title,layout,finalize=True,resizable=True,metadata=[colorTheme,df1])\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableFile1 = window2['-TABLEFILE-']\n",
    "    tableFile1.bind('<Button-1>', \"Click\")\n",
    "    headerStore[tableFile1] = header_list\n",
    "    return window2,tableFile1,values,rowFile1Colors\n",
    "\n",
    "#############################################\n",
    "\n",
    "def runETL(k):\n",
    "    global extract,a,string,dataSetsEtl\n",
    "    text2 = \"\"\n",
    "  #  print(k)\n",
    "    directory = \"\"\n",
    "    group = \"\"\n",
    "    if \"info\" in dataSetsEtl[k]:\n",
    "        if \"directory\" in dataSetsEtl[k][\"info\"]:\n",
    "            directory = dataSetsEtl[k][\"info\"][\"directory\"]\n",
    "            group = dataSetsEtl[k][\"info\"][\"group\"]\n",
    "            \n",
    "## Build Summary Text string\n",
    "    for ky1 in dataSetsEtl[k].keys():\n",
    "        text2+=f\"{ky1}:\\n\" \n",
    "        for k2,v2 in dataSetsEtl[k][ky1].items(): \n",
    "            sl = 10 - len(k2)\n",
    "            s = \" \"*sl\n",
    "        \n",
    "            if isinstance(v2,list) == False:\n",
    "                text2+=f\"    {k2:10s}{s} :  {v2}\\n\"\n",
    "            else:\n",
    "                text2+=f\"    {k2:10s}{s} : {v2[0]}\\n\"\n",
    "                if len(v2) > 1:\n",
    "                    for val in v2[1:]:\n",
    "                        text2+= f\"                   {s} : {val}\\n\"\n",
    "        text2+=f\"\\n\\n\"\n",
    "## Build actions\n",
    "    extract = \"\"\n",
    "    if 'extract' in dataSetsEtl[ds]:\n",
    "        if (dataSetsEtl[ds]['extract']['language'] == 'node'):\n",
    "            pgm =  dataSetsEtl[ds]['extract']['file']\n",
    "            options=\"\"\n",
    "            if 'options' in dataSetsEtl[ds]['extract']:\n",
    "\n",
    "                for opts in dataSetsEtl[ds]['extract']['options']:\n",
    "                    options+= f\" {opts}\" \n",
    "            extract = f\"node {bicHome}{pgm} {options}\"\n",
    "        #    print(extract)\n",
    "    transform=\"\"    \n",
    "    if 'transform' in dataSetsEtl[ds]:\n",
    "        \n",
    "        if dataSetsEtl[ds][\"transform\"][\"language\"] == \"node\":\n",
    "            ff=dataSetsEtl[ds][\"transform\"][\"file\"]\n",
    "            transform=f\"node {bicHome}{directory}/{ff}\"\n",
    "            \n",
    "        else:\n",
    "            file=\"\"        \n",
    "        \n",
    "    text2+=f\"\\n\\nActions Strings\\nExtract\\n{extract}\\n\\nTransform\\n{transform}\"\n",
    "        \n",
    "    return text2,extract,transform\n",
    "\n",
    "###############################################\n",
    "\n",
    "def compareWindow(stats1,df1,file1,title=\"Compare\",colorTheme=\"'Dark Green 5'\"):\n",
    "    global color1,color2\n",
    "    header_list = [\"Column\",\"% Missing\",\"Missing\",\"string\",\"integer\",\"float\",\"boolean\"]\n",
    "  \n",
    "    col_widths = [8]*len(header_list)\n",
    "    col_widths[0] = 25\n",
    "    columnSortStateTable1 = {}\n",
    "  \n",
    "\n",
    "    ## set up sort state for the column in both tables\n",
    "    for col in header_list:\n",
    "         columnSortStateTable1[col] = -1\n",
    "       \n",
    "            \n",
    "    valsFile1 = getValues(stats1,header_list)\n",
    "   \n",
    "    \n",
    "    rowFile1Colors = setRowColors(valsFile1,color1,color2,\"pink\",header_list)\n",
    "    \n",
    "    layCol1 = [[sg.Text(f\"File 1 {file1}\",font=\"CENTAUR 15\")],[sg.Text(f\"File 1 Shape {df1.shape}\",font=\"CENTAUR 15\")],\n",
    "               [sg.Table(values=valsFile1,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=20,col_widths=col_widths,font=\"CENTAUR 10\",\n",
    "                   justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                   key='-TABLEFILE-',row_colors=rowFile1Colors,headings = header_list,metadata=columnSortStateTable1)]\n",
    "               ]\n",
    "    \n",
    "\n",
    "    layout = [[sg.Button(\"Quit\")],\n",
    "    layCol1]  \n",
    "        \n",
    "\n",
    "              \n",
    "    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(title,layout,finalize=True,resizable=True,metadata=[colorTheme,df1])\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableFile1 = window2['-TABLEFILE-']\n",
    "    tableFile1.bind('<Button-1>', \"Click\")\n",
    "    headerStore[tableFile1] = header_list\n",
    "    return window2,tableFile1,valsFile1,rowFile1Colors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "\n",
    "def stringArgs(string):\n",
    "#  This is set to decode the extract string to get the location and name of the \n",
    "#  extracted data file\n",
    "    h =split(string)\n",
    "    inf = h.index(\"-f\")\n",
    "    inf = h[inf+1]\n",
    "    ot = h.index(\"-a\")\n",
    "    ot = h[ot+1]\n",
    "    of = h.index(\"-o\")\n",
    "    of = h[of+1]\n",
    "    inf=inf.replace(inf[-4:],ot)\n",
    "    f = inf.split(\"/\")\n",
    "    finalFile = f\"{bicHome}{of}{f[-1]}\"\n",
    "    return finalFile\n",
    " \n",
    "###################################################    \n",
    "\n",
    "def splitL(data):\n",
    "    if data:\n",
    "        head, *tail = data  # This is a nicer way of doing head, tail = data[0], data[1:]\n",
    "        return {head: splitL(tail)}\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def go_deeper(aDict,value,nit):\n",
    "    nit+=1\n",
    "    for k, v in aDict.items():\n",
    "         if not bool(v):            \n",
    "             aDict[k] = []\n",
    "             aDict[k].append(value)\n",
    "         elif isinstance(v,list):\n",
    "             aDict[k].append(value)\n",
    "         else:\n",
    "             go_deeper(v,value,nit)\n",
    "   \n",
    "    return aDict\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def init():\n",
    "    global dataSetsEtl,datasets\n",
    "    groups = []\n",
    "    desktop = pathlib.Path(\"/home/joe/bic_etl\")\n",
    "    runEtls = []\n",
    "    dataSets = []\n",
    "    info = {}\n",
    "    # .rglob() produces a generator too\n",
    "    desktop.rglob(\"*\")\n",
    "    files = list(desktop.rglob(\"*\"))\n",
    "# Which you can wrap in a list() constructor to materialize\n",
    "    for ff in files:\n",
    "\n",
    "            if (str(ff).split(\"/\")[-1] == \"run_etl.json\"):     \n",
    "                a=str(ff).split(\"/\")\n",
    "                m = a.index(\"bic_etl\")\n",
    "                b = a[m+1:-1]\n",
    "                ll = splitL(b)\n",
    "                groups.append(ll)\n",
    "                runEtls.append(ff)\n",
    "            \n",
    "    print(f\"{len(runEtls)} run_etl.json files found\")    \n",
    "    \n",
    "    dataSets = []\n",
    "    groups = []\n",
    "    for file in runEtls:\n",
    "      f = open(file,\"r\")\n",
    "      data = json.load(f)\n",
    "      # print(file)\n",
    "      # print(\"----\")\n",
    "      a=str(file).split(\"/\")\n",
    "      m = a.index(\"bic_etl\")\n",
    "      b = a[m+1:-1]\n",
    "      group = b[0]\n",
    "      ll = splitL(b)\n",
    "      bdir = \"/\".join(b)  \n",
    "      \n",
    "    #  groups.append(ll)\n",
    "      for val in data:\n",
    "            if \"title\" in val:\n",
    "                  title=val[\"title\"]\n",
    "                  info[title]={}\n",
    "                  info[title][\"directory\"] = bdir\n",
    "                  info[title][\"group\"] = group\n",
    "                \n",
    "    #              print(title,ll)\n",
    "                  nit=0\n",
    "                  ll = go_deeper(ll,title,nit)\n",
    "             #     info[title][\"groups\"] = ll\n",
    "            \n",
    "     #             print(ll)\n",
    "     #             groups.append(ll)\n",
    "            dataSets.append(val)\n",
    "    #  print(\"FF \",ll) \n",
    "      groups.append(ll)\n",
    "\n",
    "    datasets = []\n",
    "    dataSetsEtl={}\n",
    "    for val in dataSets:\n",
    "        if \"title\" in val:\n",
    "          datasets.append(val[\"title\"])\n",
    "          title=val[\"title\"]\n",
    "          dataSetsEtl[title] = {}  \n",
    "          dataSetsEtl[title][\"info\"] = {}\n",
    "          dataSetsEtl[title][\"info\"][\"directory\"] = info[title][\"directory\"]\n",
    "          dataSetsEtl[title][\"info\"][\"group\"] = info[title][\"group\"]\n",
    "     #     dataSetsEtl[title][\"info\"][\"groups\"] = info[title][\"groups\"]\n",
    "            \n",
    "        \n",
    "            \n",
    "          for k,v in val.items():\n",
    "          #      print(k,v)\n",
    "                if k != \"title\":\n",
    "                    dataSetsEtl[title][k] = {}\n",
    "                    if isinstance(v,dict):\n",
    "                        for k1,v1 in v.items():\n",
    "                            dataSetsEtl[title][k][k1]=v1\n",
    "\n",
    "    return sorted(datasets)\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def map4x4(row):\n",
    "    \n",
    "    if isinstance(row[\"Data Link\"],str) and  len(row[\"Data Link\"]) == 9 and re.findall( \"\\w{4}-\\w{4}\",row[\"Data Link\"]):\n",
    "  #      link = '<a href=\"https://data.colorado.gov/dataset/{}\">{}</a>'.format(row[\"Data Link\"],row[\"Data Link\"])\n",
    "        \n",
    "        link = 'https://data.colorado.gov/dataset/{}'.format(row[\"Data Link\"])\n",
    "    else:\n",
    "        link = \"\"\n",
    "        \n",
    "    return link\n",
    "    \n",
    "#     mf[\"CIM Link\"] = mf.apply(map4x4,axis=1)\n",
    "\n",
    "#     mf=mf.loc[~mf[\"Standardized Title for Dataset\"].isna()]\n",
    "#     mfShort = mf[['Standardized Title for Dataset', 'Data Link','CIM Data Type','GoCodePublishYear','Standardized Short Description','CIM Link']]\n",
    "#     mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def exceptionLog(exception,funCall):\n",
    "  exception_message = str(exception)\n",
    "  exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "  filename = os.path.split(exception_traceback.tb_frame.f_code.co_filename)[1]\n",
    "  print(f\"{exception_message} {exception_type} {funCall}, Line {exception_traceback.tb_lineno}\")\n",
    "\n",
    "######################################################    \n",
    "    \n",
    "def getFile(how,file,WindowP):\n",
    "    \n",
    "    if how == \"Local\":\n",
    "        if file[-3:].lower() == \"tsv\":\n",
    "            delim = \"\\t\"\n",
    "            df=pd.read_csv(file,encoding=\"latin\",delimiter=delim)\n",
    "        elif file[-4:].lower() == \"xlsx\":\n",
    "            df=pd.read_excel(file,engine=\"openpyxl\")\n",
    "        else:\n",
    "            try:\n",
    "                df=pd.read_csv(file)\n",
    "            except Exception as err:\n",
    "                print(\"Error, trying with encoding=latin\")\n",
    "                df=pd.read_csv(file,encoding=\"latin\")\n",
    "    elif how == \"Fetch\":\n",
    "      \n",
    "  #      file=values[\"-WEB-\"]\n",
    "      #  getPrevFiles(2,file)\n",
    "\n",
    "  #      windowP[\"-PINFO-\"].update(f\"START reading WEB File:{file}:\")\n",
    "        df=pd.read_csv(file)\n",
    "      \n",
    "  #      windowP[\"-PINFO-\"].update(f\"FINISHED reading WEB File:{file}:\")\n",
    "   \n",
    "    stats = dfAnalyze(df)\n",
    "        \n",
    "    return df,stats\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def setRowColors(lst,col1,col2,colsp,header):\n",
    "    count=0\n",
    "    colors = {}\n",
    "    # print(\"SRC head \",header)\n",
    "    # print(\"SRC list\",lst)\n",
    "\n",
    "    nrec = header.index(\"% Missing\")\n",
    "    for vals in lst:\n",
    "        key = vals[0]\n",
    "        if count%2 == 0:\n",
    "            colors[key] = col1\n",
    "        else:\n",
    "            colors[key] = col2\n",
    "        if vals[nrec] > 99.0:\n",
    "           \n",
    "            colors[key] = colsp\n",
    "        count+=1\n",
    "    colTab = []\n",
    "    for key,colr in colors.items():\n",
    "        colTab.append(colr)\n",
    "    rowNums = [num for num in range(0,len(colTab)+1)]\n",
    "    colText = [\"black\"]*len(colTab)\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "  \n",
    "    return colrw\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def setRowColorsGeneric(lst,col1,col2):\n",
    "    count=0\n",
    "    rowNums=[]\n",
    "    colTab=[]\n",
    "\n",
    "    for vals in lst:       \n",
    "        if count%2 == 0:\n",
    "            colTab.append(col1)\n",
    "        else:\n",
    "            colTab.append(col2)\n",
    "        rowNums.append(count)\n",
    "        count+=1\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "  \n",
    "    return colrw\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def sortTable(row,stats,table,event,header):\n",
    "    \n",
    "        e = table.user_bind_event \n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        if region == 'heading':\n",
    "            row = 0\n",
    "        elif region == 'cell':\n",
    "            row = int(table.Widget.identify_row(e.y))\n",
    "   \n",
    "        if row == 0:\n",
    "            colSortState = table.metadata\n",
    "            colClicked = int(table.Widget.identify_column(e.x)[1:])\n",
    "            header = headerStore[table]\n",
    "            \n",
    "            statClicked = header[colClicked-1].strip()\n",
    "           \n",
    "            colSortState[statClicked]*=-1\n",
    "            if colSortState[statClicked] == -1:\n",
    "                sortAsc=False\n",
    "            else:\n",
    "                sortAsc=True\n",
    "            if colClicked > 1:  # user number sort\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[1][statClicked],reverse=sortAsc))\n",
    "            else:\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[0],reverse=sortAsc))\n",
    "\n",
    "\n",
    "            statsVals=[]\n",
    "            for col in statsS:\n",
    "                 vals=[]\n",
    "                 vals.append(col)\n",
    "                 for k in header[1:]:\n",
    "                    vals.append(statsS[col][k.strip()])\n",
    "                 statsVals.append(vals)\n",
    "           # slen= len(statsVals)\n",
    "#             colorsTable = setRowColors(statsVals,\"#b3f0ff\",\"#33d6ff\",\"pink\",header_list)\n",
    "\n",
    "#             window['-TABLE-'].update(values=statsVals,row_colors=colorsTable)\n",
    "        \n",
    "        return statsVals,colSortState\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "def dfAnalyze(df):\n",
    "    stats = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        typs = df[col].apply(type).value_counts().to_dict()\n",
    "        stats[col] = {}\n",
    "        if str in typs:\n",
    "           stats[col][\"string\"] = typs[str]\n",
    "        else:\n",
    "           stats[col][\"string\"] = 0\n",
    "\n",
    "        if int in typs:\n",
    "           stats[col][\"integer\"] = typs[int]\n",
    "        else:\n",
    "           stats[col][\"integer\"] = 0\n",
    "\n",
    "        if float in typs:\n",
    "           stats[col][\"float\"] = typs[float]\n",
    "        else:\n",
    "           stats[col][\"float\"] = 0\n",
    "\n",
    "        if bool in typs:\n",
    "           stats[col][\"boolean\"] = typs[bool]\n",
    "        else:\n",
    "           stats[col][\"boolean\"] = 0\n",
    "\n",
    "        stats[col][\"Missing\"] = df[col].isna().sum()\n",
    "        stats[col][\"% Missing\"] = round(df[col].isna().sum()/df.shape[0]*100,1)\n",
    "        \n",
    "    return stats\n",
    "\n",
    "############################################# \n",
    "\n",
    "def getValues(stats,header):\n",
    "\n",
    "    statsVals=[]\n",
    "    for col in sorted(stats.keys()):\n",
    "         vals=[]\n",
    "         vals.append(col)\n",
    "         for k in header[1:]:\n",
    "            vals.append(stats[col][k.strip()])\n",
    "         statsVals.append(vals)\n",
    "    return statsVals     \n",
    "############################################################\n",
    "\n",
    "def getFilesClicked(file,window):\n",
    "#         if len(values[\"-FILE1-\"]) > 0:\n",
    "#             file = values[\"-FILE1-\"]\n",
    "#         elif len(values[\"-WEB1-\"]) > 0:\n",
    "#             file = values[\"-WEB1-\"]\n",
    "      \n",
    "        df = getFile(\"Local\",file,window)\n",
    "        stats = dfAnalyze(df)\n",
    "\n",
    "        return df,stats\n",
    "\n",
    "############################################################\n",
    "\n",
    "def getRowClicked(table,columns):\n",
    "    col=\"\"\n",
    "    e = table.user_bind_event \n",
    "    region = table.Widget.identify('region', e.x, e.y)\n",
    "    if region == 'heading':\n",
    "        row = 0\n",
    "    elif region == 'cell':\n",
    "        row = int(table.Widget.identify_row(e.y))  \n",
    "        col = columns[row-1][0]\n",
    "        \n",
    "    return row,col    \n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def getRowClickedUN(table):\n",
    "    val=\"\"\n",
    "    data = dataStore[table]\n",
    "    e = table.user_bind_event \n",
    "    region = table.Widget.identify('region', e.x, e.y)\n",
    "    if region == 'heading':\n",
    "        row = 0\n",
    "    elif region == 'cell':\n",
    "        row = int(table.Widget.identify_row(e.y))  \n",
    "        val = data[row-1][0]\n",
    "        print(\"Un VAL CLICKED \",val)\n",
    "    return row,val    \n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def showDFUN(col,unq,windowParent,colr1,colr2,colorTheme):\n",
    "    global dataStore\n",
    "    valuesUNQ = list(zip(unq.index.tolist(),unq.tolist()))\n",
    "    hUNQ = []\n",
    "    hUNQ.append(\"Values\")\n",
    "    hUNQ.append(\"Count\")\n",
    "\n",
    "    \n",
    "    sortState = {}\n",
    "    for val in hUNQ:\n",
    "        sortState[val]=-1\n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Showing unique Values for Column\"),sg.Text(f\" {col}\",text_color=\"white\",font='Courier 15 bold '),sg.Text(f\" and Reg Ex\",text_color=\"white\",font='Courier 10 bold ')],\n",
    "                \n",
    "                   [sg.Button('Quit')],\n",
    "            \n",
    "                   [sg.Button('Write Unique'),\n",
    "                    sg.Table(values=valuesUNQ,\n",
    "                       background_color=colr1,vertical_scroll_only=False,col_widths=60,font='Courier 10 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',alternating_row_color=colr2,\n",
    "                       key='-TABLE-', headings = hUNQ,metadata=sortState)]\n",
    "            ]\n",
    "    sg.theme(colorTheme)    \n",
    "    window2 = sg.Window(f\"Unique\", layout2,finalize=True,resizable=True, grab_anywhere=False,metadata=[windowParent,col])\n",
    "\n",
    "    table = window2['-TABLE-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    dataStore[table]=valuesUNQ\n",
    "    \n",
    "    return window2,table,valuesUNQ,hUNQ\n",
    "\n",
    "############################################################\n",
    "\n",
    "def showColAnal(xrefsO2T,xrefsT2O,colr1,colr2):\n",
    "    global dataStore\n",
    "    values=[]\n",
    "    header = [\"Original Column\",\"Transformed Column\"]\n",
    "    for col in sorted(xrefsO2T.keys()):\n",
    "        tmp = [col,xrefsO2T[col]]\n",
    "        values.append(tmp)\n",
    "    \n",
    "    sortState = {}\n",
    "    for val in header:\n",
    "        sortState[val]=-1\n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Original COlumns Transformed to Columns\")],\n",
    "                \n",
    "                   [sg.Button('Quit')],\n",
    "                   [ sg.Table(values=values,\n",
    "                       background_color=colr1,vertical_scroll_only=False,col_widths=60,font='Courier 10 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',alternating_row_color=colr2,\n",
    "                       key='-TABLECOLUMN-', headings = header,metadata=sortState)]\n",
    "             ]\n",
    "#    sg.theme(colorTheme)    \n",
    "    window2 = sg.Window(f\"Orig vs Trans Column Analysis\", layout2,finalize=True,resizable=True, grab_anywhere=False,metadata=\"nothing\")\n",
    "\n",
    "    table = window2['-TABLECOLUMN-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    dataStore[table]=values\n",
    "    headerStore[table]=header\n",
    "    \n",
    "    return window2,table,values,header\n",
    "\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def sortUniqe(table,window,dataStore,headerStore):\n",
    "    global color1,color2\n",
    "    try:\n",
    "        e = table.user_bind_event\n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        sortAsc = {}\n",
    "        sortAsc[1] =False\n",
    "        sortAsc[-1]=True\n",
    "   #     print(\"R \",region)\n",
    "        if region == 'heading':\n",
    "            values = dataStore[table]\n",
    "            \n",
    "           \n",
    "            header = headerStore[table]\n",
    "            # print(\"SU header \",header)\n",
    "            column = int(table.Widget.identify_column(e.x)[1:])\n",
    "            col=header[column-1]\n",
    "            \n",
    "            sortState = table.metadata\n",
    "           \n",
    "            sortState[col]*=-1\n",
    "            table.metadata = sortState\n",
    "          \n",
    "            values = sorted(values, key=lambda element: (element[column-1]),reverse=sortAsc[sortState[col]]) \n",
    "#            rowFile1Colors = setRowColors(values,color1,color2,\"pink\",header)\n",
    "            rowFile1Colors = setRowColorsGeneric(values,color1,color2)\n",
    "\n",
    "            window[\"-TABLE-\"].update(values=values)\n",
    "            dataStore[table] = values\n",
    "    except Exception as err:\n",
    "        exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "                    \n",
    "#####################################################        \n",
    "\n",
    "def wrap(string, lenght=60):\n",
    "    if isinstance(string,str):\n",
    "       return '\\n'.join(textwrap.wrap(string, lenght))\n",
    "    else:\n",
    "        return \"\"\n",
    "        \n",
    "############################################################    \n",
    "\n",
    "def tranfColXref(file):\n",
    " #   fin = open(\"/home/joe/bic_etl/cdos/business/nonprofit/scripts/reg_finan.js\",\"r\")\n",
    "    fin = open(file,\"r\")\n",
    "    \n",
    "    lines = fin.readlines()\n",
    "    fout = open(\"output.txt\",\"w\")\n",
    "    org = []\n",
    "    xrefsO2T = {}\n",
    "    xrefsT2O = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if re.findall(\"row\",line.lower()) and re.findall(\"=\",line.lower()) and not re.findall(\"^//\",line.lstrip()):\n",
    "            st1=line.find(\"[\")\n",
    "            ed1=line.find(\"]\")\n",
    "            st2=line.rfind(\"[\")\n",
    "            ed2=line.rfind(\"]\")\n",
    "            org.append(line[st2+2:ed2-1])\n",
    "    #        print(line)\n",
    "    #        print(line[st1+1:ed1],line[st2+1:ed2])\n",
    "            fout.write(f\"{line[st1+1:ed1]}  {line[st2+1:ed2]}\\n\")\n",
    "            og = line[st2+1:ed2].replace(\"'\",\"\")\n",
    "            og = og.replace(\"].toLowerCase()\",\"\")\n",
    "\n",
    "\n",
    "            tr = line[st1+1:ed1].replace(\".toLowerCase()\",\"\")\n",
    "            tr = tr.replace('\"','')\n",
    "\n",
    "\n",
    "\n",
    "            # tr = line[st1+1:ed1]\n",
    "            # og = line[st2+1:ed2]\n",
    "\n",
    "            xrefsT2O[tr]  = og\n",
    "            xrefsO2T[og]  = tr\n",
    "    return xrefsO2T,xrefsT2O\n",
    "            \n",
    "    \n",
    "############################################################\n",
    "       \n",
    "def cronGUI():\n",
    "    global ds,text2,a,string,numWindows,color1,color2,file,transform,dataStore,xrefsBy4x4\n",
    "    dataStore = {}\n",
    "    datasets = init()\n",
    "##  get xrefs b/w 4x4 ids and datasert titles...yay   \n",
    "    xrefsBy4x4,xrefsByTitle = getXrefs()\n",
    "\n",
    "    mf = pd.read_excel(\"BICDataInventoryandMetadata.xlsx\",skiprows=0,sheet_name=\"Inventory_Active\",engine=\"openpyxl\")\n",
    "    \n",
    "    mf[\"CIM Link\"] = mf.apply(map4x4,axis=1)\n",
    "\n",
    "    mf=mf.loc[~mf[\"Standardized Title for Dataset\"].isna()]\n",
    "    mfShort = mf[['Standardized Title for Dataset', 'Data Link','CIM Data Type','GoCodePublishYear','Standardized Short Description','CIM Link']]\n",
    "    mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)   \n",
    "    \n",
    "    header_list = list(mfShort.columns)\n",
    "    # mfV = []\n",
    "    # a = [\"\",\"\",nan,nan,\"\"]\n",
    "    # mfV.append(a)\n",
    "    layout = [\n",
    "              [sg.Text(\"BIC Cron DataSets\")],\n",
    "              [sg.Combo(datasets,enable_events=True,key=\"-DATASET-\",font='Courier 10 bold ')],\n",
    "              [sg.Text(\"4x4\",font='Courier 15 bold '),sg.Input(\"wwbh-7bpa\",size=[8,1],key=\"-4x4-\",font='Courier 10 bold '),\n",
    "               sg.Button(\"4x4\")],\n",
    "              [sg.Button('Close'),sg.Button(\"Plot Crons\")],\n",
    "              [sg.Button(\"Column Analysis\")],\n",
    "   #          [sg.Button(\"GO\")],\n",
    "              [sg.Button(\"Extract\",font='Courier 10 bold ',key=\"-EXTRACT-\",visible=False),\n",
    "               sg.Button(\"Analyze-Extr\",font='Courier 10 bold ',key=\"-EXTRACTANAL-\",visible=False),\n",
    "               sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-EXTRACTINFO-\")],\n",
    "              [sg.Button(\"Transform\",visible=False,font='Courier 10 bold ',key=\"-TRANSFORM-\"),\n",
    "               sg.Button(\"Ananlyze-Trans\",font='Courier 10 bold ',key=\"-TRANSFORMANAL-\",visible=False),\n",
    "               sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-TRANSFORMINFO-\")\n",
    "              ],\n",
    "              [sg.Button(\"CIM API\",font='Courier 15 bold ',key=\"-CIMAPI-\",visible=False),sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-CIMINFO-\")],\n",
    "              [sg.Text(text=\"Dataset Summary\",enable_events=True,font='Courier 15 bold ',background_color=\"blue\",key=\"-OUTPUT-\",size=[70,10]),\n",
    "               sg.Multiline(default_text=\"ETL Summary\",key=\"-ETL-\",size=[70,20],font='Courier 15 bold ')]\n",
    "            ]\n",
    "\n",
    "       \n",
    "    # Create the Window\n",
    "    sg.theme('Dark Green 5')\n",
    "    window2 = sg.Window('ETL', layout,finalize=True,resizable=True)\n",
    "    #window = sg.Window('Window Title', layout, web_port=2222, web_start_browser=False)\n",
    "    #table = window2['-TABLE2-']\n",
    "\n",
    "    #window2.move(window.current_location()[0]+600, window.current_location()[1])\n",
    "    try: \n",
    "        while True:\n",
    "\n",
    "         #   event, values = window2.read()\n",
    "            wid, event, values = sg.read_all_windows()\n",
    "            print('event: ',event, 'values: ',values)\n",
    " \n",
    "            if event == sg.WIN_CLOSED or event == 'Close':\n",
    "                window2.close()\n",
    "                break\n",
    "            elif event ==  event == 'Quit':\n",
    "                wid.close()\n",
    "                \n",
    "            elif event == \"-DATASET-\" or event == \"4x4\":\n",
    "      #      elif event == \"GO\":#\n",
    "                if event == \"-DATASET-\":\n",
    "                    (ds)  = list(values.items())\n",
    "                    ds=ds[0][1]\n",
    "                else:\n",
    "                    ds = xrefsBy4x4[values[\"-4x4-\"]]\n",
    "                    print(\"XREF DS \",values[\"-4x4-\"],ds)\n",
    "  #              ds = \"Paid Solicitors Disclosed on Charity Registration Forms in Colorado\"\n",
    "          \n",
    "                mmf = mfShort.loc[mfShort[\"Standardized Title for Dataset\"].str.strip() == ds.strip()]\n",
    "                cim4x4 = mmf['Data Link'].values.tolist()[0]\n",
    "                cimApi = f\"https://data.colorado.gov/api/views/{cim4x4}/rows.csv?accessType=DOWNLOAD\"\n",
    "                if mmf.shape[0] > 0:\n",
    "                #            mmf[\"Standardized Short Description\"] = mmf[\"Standardized Short Description\"].map(wrap)          \n",
    "                    text = f\"Title             : {mmf['Standardized Title for Dataset'].values.tolist()[0]}\\nSocrata        : {mmf['Data Link'].values.tolist()[0]}\\nData Type    : {mmf['CIM Data Type'].values.tolist()[0]}\\nPublish Year: {mmf['GoCodePublishYear'].values.tolist()[0]}\\nCIM Link : {mmf['CIM Link'].values.tolist()[0]}\\nDescription  : {mmf['Standardized Short Description'].values.tolist()[0]}\"            \n",
    "                   # display(mmf)\n",
    "                else:\n",
    "                    text = \"None\"\n",
    "                if ds in dataSetsEtl:\n",
    "                      text2,extract,transform = runETL(ds)\n",
    "                else:\n",
    "                      text2=\"\"\n",
    "                      extract = \"\"\n",
    "                if len(extract) > 10:\n",
    "                    window2[\"-EXTRACT-\"].update(visible=True)\n",
    "                if len(transform) > 10:\n",
    "                    window2[\"-TRANSFORM-\"].update(visible=True)\n",
    "                    window2[\"-TRANSFORM-\"].update(visible=True)\n",
    "          \n",
    "                if len(cimApi) > 10:                 \n",
    "                    text2+=  f\"\\n\\nCIM API\\n{cimApi}\"\n",
    "                    window2[\"-CIMAPI-\"].update(visible=True)\n",
    "                    \n",
    "                   \n",
    "                window2[\"-OUTPUT-\"].update(text)\n",
    "                window2[\"-ETL-\"].update(text2)\n",
    "                link =  mmf['CIM Link'].values.tolist()[0]\n",
    "           #     print(\"Link \",mmf['CIM Link'],link.find(\"http\"))\n",
    "                \n",
    "                # if link.find(\"http\") > -1:\n",
    "                #      window2[\"-LINK-\"].update (visible=True)\n",
    "                # else:\n",
    "                #      window2[\"-LINK-\"].update (visible=False)\n",
    "               \n",
    "            elif event == \"-LINK-\":\n",
    "                    print(\"Going To: \",link) \n",
    "                    if len(link) > 10:\n",
    "                        webbrowser.open(link)\n",
    "            elif event == \"Plot Crons\":    \n",
    "                plotCrons(crons_all)\n",
    "            elif event == \"Column Analysis\":\n",
    "           #     trfile = dataSetsEtl[ds][\"transform\"][\"file\"]\n",
    "                trfile = transform[5:]\n",
    "                print(\"TRFILE \",trfile)\n",
    "                xrefsO2T,xrefsT2O = tranfColXref(trfile)\n",
    "                color1 = colorPairs[numWindows][0]\n",
    "                color2 = colorPairs[numWindows][1]\n",
    "                \n",
    "                numWindows+=1\n",
    "                if numWindows > len(colorPairs):\n",
    "                    numWindows=0\n",
    "                showColAnal(xrefsO2T,xrefsT2O,color1,color2)\n",
    "                print(\"XrfT2O \",xrefsT2O)\n",
    "            elif event == \"-CIMAPI-\":\n",
    "                  #  df1,stats1 = getFilesClicked(cimApi,window2)\n",
    "                    df1,stats1 = getFile(\"Fetch\",cimApi,window2)\n",
    "                    \n",
    "                    color1 = colorPairs[numWindows][0]\n",
    "                    color2 = colorPairs[numWindows][1]\n",
    "\n",
    "                    numWindows+=1\n",
    "                    if numWindows > len(colorPairs):\n",
    "                        numWindows=0\n",
    "\n",
    "                    WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1,df1,cimApi,\"CMI Analysis\",\"DarkRed\")\n",
    "                    dataStore[tabl1]=valsFile1\n",
    "                    \n",
    "                    windowsOpen[\"main\"].append(WindowC)        \n",
    "                \n",
    "            elif event == \"-TRANSFORM-\":\n",
    "               \n",
    "                a=subprocess.run(transform,shell=True,capture_output=True,text=True)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"TRANSFORM Output\\n\"\n",
    "                tfile=\"\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= f\"Error:\\n {a.stderr}\"\n",
    "                else:\n",
    "                    for msg in a.stdout.split(\"debug msg:\"):    \n",
    "                        if msg.find(\"final file is at:\") > -1:\n",
    "                           \n",
    "                            tmp = msg.split(\" \")\n",
    "                            tfile = tmp[-3]\n",
    "                            if os.path.isfile(tfile):\n",
    "                                \n",
    "                                window2[\"-TRANSFORMANAL-\"].update(visible=True)\n",
    "                                fileStats = os.stat(tfile)\n",
    "                                dt = datetime.fromtimestamp(fileStats.st_ctime)\n",
    "                                string = f\"{fileStats.st_size:,} bytes Created: {dt}  file: {tfile}\"\n",
    "                                window2[\"-TRANSFORMINFO-\"].update(string,visible=True)\n",
    "                            \n",
    "                    string+=f\"STDOUT: {a.stdout}\"\n",
    "                    window2[\"-ETL-\"].update(string,append=True)    \n",
    "            elif event == \"-TRANSFORMANAL-\":\n",
    "                #    df1,stats1 = getFilesClicked(tfile,window2)\n",
    "                    df1,stats1 = getFile(\"Local\",tfile,window2)\n",
    "                    \n",
    "                    color1 = colorPairs[numWindows][0]\n",
    "                    color2 = colorPairs[numWindows][1]\n",
    "                  \n",
    "                    numWindows+=1\n",
    "                    if numWindows > len(colorPairs):\n",
    "                        numWindows=0\n",
    "\n",
    "                    WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1,df1,tfile,\"Transform Analysis\",\"DarkPurple\")\n",
    "                    dataStore[tabl1]=valsFile1\n",
    "                    windowsOpen[\"main\"].append(WindowC)    \n",
    "                  \n",
    "            elif event == \"-EXTRACT-\":\n",
    "                a=subprocess.run(extract,shell=True,capture_output=True,text=True)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"Extract Output\\n\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= \"fError:\\n {a.stderr}\"\n",
    "                string+=f\"STDOUT: {a.stdout}\"\n",
    "                window2[\"-ETL-\"].update(string,append=True)\n",
    "                sx = string.find(\"successfully download to\")\n",
    "                string[sx+25:]\n",
    "                sxo = string[sx+25:].find(\"!\")\n",
    "             \n",
    "                file=f\"/home/joe/bic_etl{string[sx+25:sx+25+sxo]}\"\n",
    "              \n",
    "                if os.path.isfile(file):\n",
    "                  \n",
    "                    window2[\"-EXTRACTANAL-\"].update(visible=True)\n",
    "                    fileStats = os.stat(file)\n",
    "                    dt = datetime.fromtimestamp(fileStats.st_ctime)\n",
    "                    string = f\"{fileStats.st_size:,} bytes Created: {dt}  file: {file}\"\n",
    "                    window2[\"-EXTRACTINFO-\"].update(string,visible=True)\n",
    "                      \n",
    "            elif event == \"-EXTRACTANAL-\":\n",
    "                file=stringArgs(extract)\n",
    "                \n",
    "             #   df1,stats1 = getFilesClicked(file,window2)\n",
    "                df1,stats1 = getFile(\"Local\",file,window2)\n",
    "                \n",
    "                color1 = colorPairs[numWindows][0]\n",
    "                color2 = colorPairs[numWindows][1]\n",
    "                \n",
    "                numWindows+=1\n",
    "                if numWindows > len(colorPairs):\n",
    "                    numWindows=0\n",
    "                    \n",
    "                WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1,df1,file,\"Extract Analysis\",\"DarkBlue16\")\n",
    "                dataStore[tabl1]=valsFile1\n",
    "                windowsOpen[\"main\"].append(WindowC)\n",
    "                windowsStore[\"extract\"] = windowC\n",
    "            ###########\n",
    "            elif event == \"-TABLEFILE-Click\":\n",
    "               \n",
    "                row,col=getRowClicked(tabl1,valsFile1)\n",
    "               \n",
    "                if row == 0:\n",
    "                   header = headerStore[tabl1]\n",
    "                  \n",
    "                   valsFile1,columnSortStateTable1 = sortTable(row,stats1,tabl1,event,header)          \n",
    "                   rowFile1Colors=setRowColors(valsFile1,color1,color2,\"pink\",header)\n",
    "                   wid[\"-TABLEFILE-\"].update(values=valsFile1,row_colors=rowFile1Colors)\n",
    "                   wid[\"-TABLEFILE-\"].metadata=columnSortStateTable1\n",
    "                else:\n",
    "                    unq = df1[col].value_counts()\n",
    "                    colorTheme=wid.metadata[0]\n",
    "                    w,t,values,uHead = showDFUN(col,unq,wid,color1,color2,colorTheme)\n",
    "                  #dataStore[t] = values\n",
    "                    headerStore[t] = uHead\n",
    "                    windowsOpen[\"main\"].append(w)\n",
    "            elif event == \"-TABLE-Click\":  # This is the Unique Values tables\n",
    "                table = wid['-TABLE-']               \n",
    "               \n",
    "                \n",
    "                row,val =getRowClickedUN(table)\n",
    "                if row == 0:\n",
    "                    sortUniqe(table,wid,dataStore,headerStore)\n",
    "                else:\n",
    "                    widP = wid.metadata[0]\n",
    "                    col = wid.metadata[1]\n",
    "                    df = widP.metadata[1]\n",
    "                    tmp = df.loc[df[col] == val]\n",
    "                    showDfRecs(tmp,col,val,widP,title=\"DF Unique Record Values\")\n",
    "                   \n",
    "         \n",
    "    except  Exception as err: \n",
    "       exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    " \n",
    "    for wid in windowsOpen[\"main\"]:\n",
    "        print(\"window MA\",wid)\n",
    "        if wid:\n",
    "            print(\"cosing \",wid)\n",
    "            wid.close()\n",
    "            wid = None\n",
    "\n",
    "cronGUI()\n",
    "\n",
    "\n",
    "\n",
    "### Bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142982a8-7994-4e81-96e6-be6d9b9bdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.theme_previewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44390dd0-0fec-4cbb-8bf2-dfb62052e4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fileBrowser",
   "language": "python",
   "name": "filebrowser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
