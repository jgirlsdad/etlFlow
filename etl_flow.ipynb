{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f005e04-9796-4428-a128-b70ca0b21e4c",
   "metadata": {},
   "source": [
    "# ETL Flow GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18405b17-d473-4f5b-a49c-f5bd6d28158f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c295e4-6a60-4209-a57c-93ec40c50d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys,os,inspect\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "#from cronsim import CronSim\n",
    "import argparse\n",
    "import json\n",
    "import ast\n",
    "import pygsheets\n",
    "from tabulate import tabulate\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import PySimpleGUI as sg\n",
    "#import PySimpleGUIWeb as sg\n",
    "import pathlib\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import re\n",
    "from shlex import split\n",
    "import webbrowser\n",
    "import subprocess\n",
    "import collections\n",
    "import pyglet,tkinter\n",
    "from pyglet import font\n",
    "from tkinter import Tk\n",
    "import pygments.lexers\n",
    "from chlorophyll import CodeView\n",
    "import tkinter as tk\n",
    "from tkinter import ttk,Button,Label\n",
    "\n",
    "\n",
    "font.add_file('/etc/fonts/fonts/CENTAUR.TTF')\n",
    "font='Courier 10 bold '\n",
    "bicHome = \"/home/joe/bic_etl/\"\n",
    "numWindows=0\n",
    "headerStore = {}\n",
    "\n",
    "colorPairs = [[\"#D6EAF8\",\"#85C1E9\"],[\"#b3f0ff\",\"#33d6ff\"],[\"#D5F5E3\",\"#A3E4D7\"],[\"#FCF3CF\",\"#F7DC6F\"]]\n",
    "windowsOpen = {}\n",
    "windowsOpen[\"main\"] = []\n",
    "windowsOpen[\"unique\"] = []\n",
    "\n",
    "\n",
    "import requests\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "global datasets\n",
    "\n",
    "if sys.platform == \"linux\":\n",
    "    path=\"/home/joe/work/Logs/logs\"\n",
    "else:\n",
    "    path= \"\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\joe\\\\work\\\\Logs\\\\\"\n",
    "\n",
    "logging = 2\n",
    "today = datetime.today()\n",
    "## Directory where dataset difintions will be store... this will be inside\n",
    "## bic_etl/dataset_dirs/definitionDir\n",
    "definitionDir = \"defs\" \n",
    "sourceDefFile = \" \"\n",
    "nfieldsAdded = 0  # numbers of XREF Fields added\n",
    "\n",
    "## map etl dataset names to invenotry  dataset names:\n",
    "mapTitles = {}\n",
    "#mapTitles[etl title] = invenotry title\n",
    "mapTitles[\"Other Names a Registered Entity Uses to Solicit Contributions\"] = \\\n",
    "\"Other Names a Registered Entity Uses to Solicit Contributions in Colorado\"\n",
    "\n",
    "mapTitles[\"Registration for Charities, Paid Solicitors, Professional Fundraising Consultants, and for-profit Public Benefit Corporations in Colorado\"] =  \\\n",
    "\"Registration of Charities, Paid Solicitors, Professional Fundraising Consultants, and for-profit Public Benefit Corporations in Colorado\"\n",
    "\n",
    "\n",
    "\n",
    "# \"Recently Expired and Surrendered Liquor Licenses in Colorado\"\n",
    "# \"Recently Expired and Surrendered Liquor Licenses in Colorado\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b9628-c8fb-41a1-8abb-1bc5cc9be430",
   "metadata": {},
   "source": [
    "## Functions 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6bfb2-7e71-4707-9d4f-8e7a4ef54e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def showFile(file):\n",
    "    fin = open(file,\"r\") \n",
    "    text = fin.readlines()\n",
    "    string=\"\"\n",
    "    for aa in text:\n",
    "        string+=aa\n",
    "    root = Tk()\n",
    "    root.title(file)\n",
    "    codeview = CodeView(root, lexer=pygments.lexers.JavascriptLexer, color_scheme=\"monokai\")\n",
    "    codeview.pack(fill=\"both\", expand=True)\n",
    "    codeview.insert(tk.END,chars=string)\n",
    "    root.mainloop()\n",
    "\n",
    "#############################################################\n",
    "    \n",
    "def showInvFields(w4x4):\n",
    "    values = list(zip(fields[w4x4][\"source\"],fields[w4x4][\"cim\"]))\n",
    "    columns = [\"Source\",\"Transformed\"]\n",
    "    layout = [[sg.Text(f\"Inventory Field List\",font=\"CENTAUR 15 bold\")],\n",
    "              [sg.Button(\"Quit\")],\n",
    "               [sg.Table(values=values,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=20,font=\"CENTAUR 15\",\n",
    "                   justification='left',vertical_scroll_only=False,col_widths=30,\n",
    "                    background_color=\"#F8C471\",def_col_width = 20,\n",
    "                   alternating_row_color=\"#FAE5D3\",key='-INVFIELDS-',headings = columns)]\n",
    "               ]\n",
    "    \n",
    "\n",
    "#    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(\"Inventory Field List\",layout,finalize=True,resizable=True)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    # tableFile1 = window2['-LOGSUMMARY-']\n",
    "    # tableFile1.bind('<Button-1>', \"Click\")\n",
    "   # headerStore[tableFile1] = columns\n",
    "   # statsStore[tableFile1] = stats1\n",
    "\n",
    "#############################################################\n",
    "\n",
    "def getRecentErrorsNew():\n",
    "    global ids,errorsByDate\n",
    "    files = []\n",
    "    print(path)\n",
    "    ids={}\n",
    "    for x in os.listdir(path):\n",
    "            if re.findall(\"^log.json*\",x):\n",
    "                 # files2Process.append(x)\n",
    "                 files.append(x)\n",
    "\n",
    "    x = datetime.today() - timedelta(days=30)\n",
    "    monthM = x.month  \n",
    "    yearM = x.year\n",
    "    ff=f\"log_backup_{yearM}_{monthM}.json\"\n",
    "    files.append(ff)\n",
    "    # files=[\"log.json.0\"]\n",
    "    errorsByDate = {}\n",
    "    errorsByName = {}\n",
    "    found2=False\n",
    "    bad = []\n",
    "    tim=0\n",
    "    nfile=0\n",
    "   # print(sorted(files))\n",
    "    for file in sorted(files):\n",
    "        print(\"Processing \",file)\n",
    "        try:\n",
    "            jsf = open(f\"{path}/{file}\")\n",
    "            found=True\n",
    "        except:\n",
    "            print(f\"File not found {path}/{file}\")\n",
    "            sg.Popup(f\"File NOT FOUND, Please Download it {path}/{file}\")\n",
    "            found=False\n",
    "           \n",
    "        if found:  \n",
    "                log=[]\n",
    "                nline=0\n",
    "                nfile+=1\n",
    "                for line in jsf:\n",
    "                    try: \n",
    "                         xl=line.lower()\n",
    "\n",
    "                         if \"error\" in xl and \"metadata\" not in xl:\n",
    "                    #     if \"error\" in xl :\n",
    "                             log.append(ast.literal_eval(line))\n",
    "                    except Exception as err:\n",
    "                       print(\"ERROR \",err)\n",
    "                       bad.append(line)\n",
    "                       print(\"BAD \",line)\n",
    "                    nline+=1\n",
    "                    \n",
    "                    \n",
    "                if  len(log) > 0 and  found2 == False:\n",
    "                    msg = log[0]\n",
    "                    time0 = datetime.strptime(msg['time'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                    name0 = msg['name'].strip()\n",
    "                    found2=True\n",
    "                   # print(\"TIME0 \",file,time0)\n",
    "                    \n",
    "             #   tim=0\n",
    "                if found2:\n",
    "                  for line in log:\n",
    "                  #  print(line['time'],line['name'])\n",
    "                    time = line['time']\n",
    "                    time1 = datetime.strptime(time, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                    diff = time1-time0\n",
    "                    name1 = line['name'].strip()\n",
    "                  #  print(name0,name1,time0,time1,diff.total_seconds())\n",
    "                    if name1 == name0 and  abs(diff.total_seconds()) < 1:\n",
    "                        same=True\n",
    "                      #  print(\"    \",tim,name0,name1)\n",
    "                    else:\n",
    "                        tim+=1\n",
    "                    name0=name1\n",
    "                    time0=time1\n",
    "                    \n",
    "                    spl = time.split(\"T\")\n",
    "                    time = spl[0]\n",
    "                    name = line['name'].strip()\n",
    "\n",
    "                    msg= line['msg'].strip()\n",
    "\n",
    "                    emsg = \"\"\n",
    "                    if \"err\" in line:\n",
    "                        emsg = line['err']\n",
    "                #        msg+= f\"\\n\\n-------------\\n{err}\"\n",
    "\n",
    "\n",
    "                    uid = f\"{line['time']}{msg[1:20]}\"\n",
    "                    if uid in ids:\n",
    "                        ids[uid]+=1\n",
    "                    else:\n",
    "                        ids[uid]=1\n",
    "\n",
    "                    stitle=\"\"\n",
    "                    xm = msg.find(\"Full ETL failure for \")\n",
    "                    if xm > -1:\n",
    "                       stitle = msg[xm+20:].split(\":\")[0]\n",
    "                       stitle=stitle.replace(\" at load\",\"\")\n",
    "\n",
    "                    xm = msg.find(\"Error Loading \")\n",
    "                    if xm > -1:\n",
    "                       stitle = msg[xm+14:]\n",
    "\n",
    "                    xm = msg.find(\"Error Extracting \")\n",
    "                    if xm > -1:\n",
    "                       stitle=msg[xm+16:]\n",
    "\n",
    "                    xm = msg.find(\"Error Transforming \")\n",
    "                    if xm > -1:\n",
    "                       stitle=msg[xm+18:]\n",
    "\n",
    "                #   \n",
    "                    titl=\"\"\n",
    "                    s4x4=\"\"\n",
    "                    w4x4=\"\"\n",
    "                    try:\n",
    "                        s4x4s = re.findall(\"[\\w]{3,4}-[\\w]{3,4}\",line['msg'])\n",
    "\n",
    "\n",
    "                        if len(s4x4s) > 0:\n",
    "                          for s4x4 in s4x4s:\n",
    "                             if s4x4 in xrefsBy4x4:\n",
    "                                titl = xrefsBy4x4[s4x4]\n",
    "                                w4x4=s4x4\n",
    "\n",
    "\n",
    "                    except:\n",
    "                        titl=\"\"\n",
    "\n",
    "\n",
    "                    if tim in errorsByDate:\n",
    "                        errorsByDate[tim]['name'].append(name)\n",
    "                        errorsByDate[tim]['msg'].append(msg)\n",
    "                        errorsByDate[tim]['emsg'].append(emsg)\n",
    "                        errorsByDate[tim]['line'].append(line)\n",
    "                        errorsByDate[tim]['file'].append(file)\n",
    "                        errorsByDate[tim]['title'].append(titl)\n",
    "                        errorsByDate[tim]['stitle'].append(stitle)\n",
    "                        errorsByDate[tim]['4x4'].append(w4x4)\n",
    "                        errorsByDate[tim]['uid'].append(uid)\n",
    "                        errorsByDate[tim]['time'].append(time)\n",
    "                        \n",
    "\n",
    "                    else:\n",
    "                        errorsByDate[tim] = {}\n",
    "                        errorsByDate[tim]['name'] = []\n",
    "                        errorsByDate[tim]['msg'] = []\n",
    "                        errorsByDate[tim]['emsg'] = []              \n",
    "                        errorsByDate[tim]['line'] = []\n",
    "                        errorsByDate[tim]['file'] = []\n",
    "                        errorsByDate[tim]['title'] = []\n",
    "                        errorsByDate[tim]['stitle'] = []\n",
    "                        errorsByDate[tim]['4x4'] = []\n",
    "                        errorsByDate[tim]['uid'] = []\n",
    "                        errorsByDate[tim]['time'] = []\n",
    "                        \n",
    "\n",
    "                        errorsByDate[tim]['name'].append(name)\n",
    "                        errorsByDate[tim]['msg'].append(msg)\n",
    "                        errorsByDate[tim]['emsg'].append(emsg)            \n",
    "                        errorsByDate[tim]['line'].append(line)\n",
    "                        errorsByDate[tim]['file'].append(file)\n",
    "                        errorsByDate[tim]['title'].append(titl)\n",
    "                        errorsByDate[tim]['stitle'].append(stitle)\n",
    "                        errorsByDate[tim]['4x4'].append(w4x4)\n",
    "                        errorsByDate[tim]['uid'].append(uid)\n",
    "                        errorsByDate[tim]['time'].append(time)\n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "                    if name in errorsByName:\n",
    "                            errorsByName[name]['time'].append(tim)\n",
    "                            errorsByName[name]['msg'].append(msg)\n",
    "                            errorsByName[name]['line'].append(line)\n",
    "                            errorsByName[name]['file'].append(file)\n",
    "                            errorsByName[name]['title'].append(titl)\n",
    "                    else:\n",
    "                        errorsByName[name] = {}\n",
    "                        errorsByName[name]['time'] = []\n",
    "                        errorsByName[name]['msg'] = []\n",
    "                        errorsByName[name]['line'] = []\n",
    "                        errorsByName[name]['file'] = []\n",
    "                        errorsByName[name]['title'] = []\n",
    "\n",
    "                        errorsByName[name]['time'].append(tim)\n",
    "                        errorsByName[name]['msg'].append(msg)\n",
    "                        errorsByName[name]['line'].append(line)\n",
    "                        errorsByName[name]['file'].append(file)\n",
    "                        errorsByName[name]['title'].append(titl)\n",
    "\n",
    "#                 except Exception as err:\n",
    "#                     print(err)\n",
    "#                     print(line)\n",
    "    return errorsByDate,errorsByName\n",
    "\n",
    "#################################################\n",
    "\n",
    "def getRecentErrors():\n",
    "    global ids,errorsByDate\n",
    "    files = []\n",
    "    print(path)\n",
    "    ids={}\n",
    "    for x in os.listdir(path):\n",
    "            if re.findall(\"^log.json*\",x):\n",
    "                 # files2Process.append(x)\n",
    "                 files.append(x)\n",
    "\n",
    "    x = datetime.today() - timedelta(days=30)\n",
    "    monthM = x.month  \n",
    "    yearM = x.year\n",
    "    ff=f\"log_backup_{yearM}_{monthM}.json\"\n",
    "    files.append(ff)\n",
    "    # files=[\"log.json.0\"]\n",
    "    errorsByDate = {}\n",
    "    errorsByName = {}\n",
    "    print(files)\n",
    "    bad = []\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        try:\n",
    "            jsf = open(f\"{path}/{file}\")\n",
    "            found=True\n",
    "        except:\n",
    "            print(f\"File not found {path}/{file}\")\n",
    "            sg.Popup(f\"File NOT FOUND, Please Download it {path}/{file}\")\n",
    "            found=False\n",
    "           \n",
    "\n",
    "        if found:  \n",
    "                log=[]\n",
    "                nline=0\n",
    "                for line in jsf:\n",
    "                    try: \n",
    "                         xl=line.lower()\n",
    "\n",
    "                         if \"error\" in xl and \"metadata\" not in xl:\n",
    "                    #     if \"error\" in xl :\n",
    "                             log.append(ast.literal_eval(line))\n",
    "                    except Exception as err:\n",
    "                       print(\"ERROR \",err)\n",
    "                       bad.append(line)\n",
    "                       print(\"BAD \",line)\n",
    "                    nline+=1\n",
    "\n",
    "                for line in log:\n",
    "                  #  print(line['time'],line['name'])\n",
    "                    tim = line['time']\n",
    "\n",
    "                    spl = tim.split(\"T\")\n",
    "                    tim = spl[0]\n",
    "                    name = line['name'].strip()\n",
    "\n",
    "                    msg= line['msg'].strip()\n",
    "\n",
    "                    if \"err\" in line:\n",
    "                        err = line['err']\n",
    "                        msg+= f\"\\n\\n-------------\\n{err}\"\n",
    "\n",
    "\n",
    "                    uid = f\"{line['time']}{msg[1:20]}\"\n",
    "                    if uid in ids:\n",
    "                        ids[uid]+=1\n",
    "                    else:\n",
    "                        ids[uid]=1\n",
    "\n",
    "                    stitle=\"\"\n",
    "                    xm = msg.find(\"Full ETL failure for \")\n",
    "                    if xm > -1:\n",
    "                       stitle = msg[xm+20:].split(\":\")[0]\n",
    "                       stitle=stitle.replace(\" at load\",\"\")\n",
    "\n",
    "                    xm = msg.find(\"Error Loading \")\n",
    "                    if xm > -1:\n",
    "                       stitle = msg[xm+14:]\n",
    "\n",
    "                    xm = msg.find(\"Error Extracting \")\n",
    "                    if xm > -1:\n",
    "                       stitle=msg[xm+16:]\n",
    "\n",
    "                    xm = msg.find(\"Error Transforming \")\n",
    "                    if xm > -1:\n",
    "                       stitle=msg[xm+18:]\n",
    "\n",
    "                #   \n",
    "                    titl=\"\"\n",
    "                    s4x4=\"\"\n",
    "                    w4x4=\"\"\n",
    "                    try:\n",
    "                        s4x4s = re.findall(\"[\\w]{3,4}-[\\w]{3,4}\",line['msg'])\n",
    "\n",
    "\n",
    "                        if len(s4x4s) > 0:\n",
    "                          for s4x4 in s4x4s:\n",
    "                             if s4x4 in xrefsBy4x4:\n",
    "                                titl = xrefsBy4x4[s4x4]\n",
    "                                w4x4=s4x4\n",
    "\n",
    "\n",
    "                    except:\n",
    "                        titl=\"\"\n",
    "\n",
    "\n",
    "                    if tim in errorsByDate:\n",
    "                        errorsByDate[tim]['name'].append(name)\n",
    "                        errorsByDate[tim]['msg'].append(msg)\n",
    "                        errorsByDate[tim]['line'].append(line)\n",
    "                        errorsByDate[tim]['file'].append(file)\n",
    "                        errorsByDate[tim]['title'].append(titl)\n",
    "                        errorsByDate[tim]['stitle'].append(stitle)\n",
    "                        errorsByDate[tim]['4x4'].append(w4x4)\n",
    "                        errorsByDate[tim]['uid'].append(uid)\n",
    "\n",
    "                    else:\n",
    "                        errorsByDate[tim] = {}\n",
    "                        errorsByDate[tim]['name'] = []\n",
    "                        errorsByDate[tim]['msg'] = []\n",
    "                        errorsByDate[tim]['line'] = []\n",
    "                        errorsByDate[tim]['file'] = []\n",
    "                        errorsByDate[tim]['title'] = []\n",
    "                        errorsByDate[tim]['stitle'] = []\n",
    "                        errorsByDate[tim]['4x4'] = []\n",
    "                        errorsByDate[tim]['uid'] = []\n",
    "\n",
    "                        errorsByDate[tim]['name'].append(name)\n",
    "                        errorsByDate[tim]['msg'].append(msg)\n",
    "                        errorsByDate[tim]['line'].append(line)\n",
    "                        errorsByDate[tim]['file'].append(file)\n",
    "                        errorsByDate[tim]['title'].append(titl)\n",
    "                        errorsByDate[tim]['stitle'].append(stitle)\n",
    "                        errorsByDate[tim]['4x4'].append(w4x4)\n",
    "                        errorsByDate[tim]['uid'].append(uid)\n",
    "\n",
    "\n",
    "\n",
    "                    if name in errorsByName:\n",
    "                            errorsByName[name]['time'].append(tim)\n",
    "                            errorsByName[name]['msg'].append(msg)\n",
    "                            errorsByName[name]['line'].append(line)\n",
    "                            errorsByName[name]['file'].append(file)\n",
    "                            errorsByName[name]['title'].append(titl)\n",
    "                    else:\n",
    "                        errorsByName[name] = {}\n",
    "                        errorsByName[name]['time'] = []\n",
    "                        errorsByName[name]['msg'] = []\n",
    "                        errorsByName[name]['line'] = []\n",
    "                        errorsByName[name]['file'] = []\n",
    "                        errorsByName[name]['title'] = []\n",
    "\n",
    "                        errorsByName[name]['time'].append(tim)\n",
    "                        errorsByName[name]['msg'].append(msg)\n",
    "                        errorsByName[name]['line'].append(line)\n",
    "                        errorsByName[name]['file'].append(file)\n",
    "                        errorsByName[name]['title'].append(titl)\n",
    "\n",
    "#                 except Exception as err:\n",
    "#                     print(err)\n",
    "#                     print(line)\n",
    "    return errorsByDate,errorsByName\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def getXrefs():\n",
    "    '''Reads the Inventory google sheet and gets the datasets title and cross-refs it to the Socrata 4x4 id.  Also\n",
    "    gets the fields by 4x4 dataset id and by the title'''\n",
    "    scope = ['https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "             \"https://www.googleapis.com/auth/drive.file\",\n",
    "                  \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name('../client_secret.json',\n",
    "     scope)\n",
    "    client = gspread.authorize(creds)\n",
    "\n",
    "    gc = gspread.service_account(\"../client_secret.json\")\n",
    "    # for gg in gc.list_spreadsheet_files():\n",
    "    #      print(\"GGGGG \",gg)\n",
    "    # https://docs.google.com/spreadsheets/d/1WTaOglzbSsYiHhAGguGxHQXmAGmOhfFHkGkMLowxAOA/edit?usp=sharing\n",
    "    sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "        'Maintenance_Framework')\n",
    "    repo_sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "        'MetadataRepository')\n",
    "    fields_sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "        'Field Descriptions')\n",
    "    \n",
    "    \n",
    "#     sheet = client.open('https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/').worksheet(\n",
    "#         'Maintenance_Framework')\n",
    "#     repo_sheet = client.open('https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/').worksheet(\n",
    "#         'MetadataRepository')\n",
    "    \n",
    "#     fields_sheet = client.open('https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/').worksheet(\n",
    "#         'Field Descriptions')\n",
    "\n",
    "    dfRepo = pd.DataFrame(repo_sheet.get_all_records(head=3))\n",
    "    xrefsBy4x4 = {}\n",
    "    xrefsByTitle = {}\n",
    "\n",
    "    for index,row in dfRepo[['Dataset Title','Socrata Link']].iterrows():\n",
    "        xrefsByTitle[row['Dataset Title']] = row['Socrata Link']\n",
    "        xrefsBy4x4[row['Socrata Link']] = row['Dataset Title']\n",
    "        \n",
    "    dfFields = pd.DataFrame(fields_sheet.get_all_records(head=1))\n",
    "    fields = {}\n",
    "    for index,row in dfFields.iterrows():\n",
    "        s4x4 = row[\"Socrata ID\"]\n",
    "        of = row[\"Source Field Name\"]\n",
    "        tf = row[\"Full Field Name\"]\n",
    "        af = row[\"API Field Name\"]\n",
    "        des = row[\"Description\"]\n",
    "        if s4x4 in fields:\n",
    "            fields[s4x4][\"source\"].append(of)\n",
    "            fields[s4x4][\"cim\"].append(tf)\n",
    "            fields[s4x4][\"api\"].append(af)\n",
    "            fields[s4x4][\"description\"].append(des)\n",
    "        \n",
    "        else:\n",
    "            fields[s4x4] = {}\n",
    "            fields[s4x4][\"source\"] = []\n",
    "            fields[s4x4][\"cim\"] = []\n",
    "            fields[s4x4][\"api\"] = []\n",
    "            fields[s4x4][\"description\"] = []\n",
    "            \n",
    "            \n",
    "            fields[s4x4][\"source\"].append(of)\n",
    "            fields[s4x4][\"cim\"].append(tf)\n",
    "            fields[s4x4][\"api\"].append(af)\n",
    "            fields[s4x4][\"description\"].append(des)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    return xrefsBy4x4,xrefsByTitle,fields\n",
    "\n",
    "############################################################\n",
    "\n",
    "def toGoogleSheet(row):\n",
    "    '''Reads the Inventory google sheet and gets the datasets title and cross-refs it to the Socrata 4x4 id.  Also\n",
    "    gets the fields by 4x4 dataset id and by the title'''\n",
    "    # scope = ['https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "    #          \"https://www.googleapis.com/auth/drive.file\",\n",
    "    #               \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "    path='../client_secret.json'\n",
    "    gc=pygsheets.authorize(service_account_file=path)\n",
    "    sh=gc.open('Changes/Fixes Requested by BIC')\n",
    "    wk1=sh[0]\n",
    "    ret = wk1.append_table(row)\n",
    "    return ret\n",
    "\n",
    "#########################################################\n",
    "\n",
    "def markDone(row):\n",
    "    '''Reads the Inventory google sheet and gets the datasets title and cross-refs it to the Socrata 4x4 id.  Also\n",
    "    gets the fields by 4x4 dataset id and by the title'''\n",
    "    # scope = ['https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "    #          \"https://www.googleapis.com/auth/drive.file\",\n",
    "    #               \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "    path='../client_secret.json'\n",
    "    gc=pygsheets.authorize(service_account_file=path)\n",
    "    sh=gc.open('ETL Errors Accounted For')\n",
    "    wk1=sh[0]\n",
    "    ret = wk1.append_table(row)\n",
    "    return ret\n",
    "\n",
    "#################################################################\n",
    "\n",
    "def getErrorStatus():\n",
    "    '''Reads the Inventory google sheet and gets the datasets title and cross-refs it to the Socrata 4x4 id.  Also\n",
    "    gets the fields by 4x4 dataset id and by the title'''\n",
    "    # scope = ['https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "    #          \"https://www.googleapis.com/auth/drive.file\",\n",
    "    #               \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "    path='../client_secret.json'\n",
    "    gc=pygsheets.authorize(service_account_file=path)\n",
    "    sh=gc.open('ETL Errors Accounted For')\n",
    "    wk1=sh[0]\n",
    "    df = wk1.get_as_df()\n",
    "    x=df[[\"Unique ID\",\"Status\"]].values.tolist()\n",
    "    \n",
    "    return {y[0]:y[1] for y in x}\n",
    "\n",
    "#################################################################\n",
    "\n",
    "def getLogSummary():\n",
    "    '''Reads the Inventory google sheet and gets the datasets title and cross-refs it to the Socrata 4x4 id.  Also\n",
    "    gets the fields by 4x4 dataset id and by the title'''\n",
    "    # scope = ['https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "    #          \"https://www.googleapis.com/auth/drive.file\",\n",
    "    #               \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "    path='../client_secret.json'\n",
    "    gc=pygsheets.authorize(service_account_file=path)\n",
    "    sh=gc.open('Changes/Fixes Requested by BIC')\n",
    "    wk1=sh[0]\n",
    "    df = wk1.get_as_df()\n",
    "    x=df.values.tolist()\n",
    "    \n",
    "    return x,list(df.columns)\n",
    "\n",
    "#################################################################\n",
    "\n",
    "def showError(row):\n",
    "    layout = [\n",
    "        [sg.Button(\"Quit\")],\n",
    "        [sg.Button(\"Write Log\")],\n",
    "        [sg.Button(\"Mark Done\"),sg.Button(\"Mark Skip\")],\n",
    "        [sg.Multiline(\"\",s=(50,10),key=\"-ERRORSINGLE-\",font=\"CENTAUR 15 bold\")],\n",
    "        [sg.Text(\"Title: \",font=\"CENTAUR 15 bold\"),\n",
    "         sg.Multiline(\"\",s=(50,2),key=\"-ERRORTITLE-\",font=\"CENTAUR 15 bold\",text_color=\"black\")],\n",
    "         [sg.Multiline(\"JIRA BIC-\",s=(10,2),key=\"-ERRORJIRA-\",font=\"CENTAUR 15 bold\")],\n",
    "        [sg.Text(\"NOTES: \",font=\"CENTAUR 15 bold\"),\n",
    "         sg.Multiline(\"\",s=(20,10),key=\"-ERRORNOTES-\",font=\"CENTAUR 15 bold\")]\n",
    "        \n",
    "    ]\n",
    "    window = sg.Window('Show Error', layout, finalize=True,metadata=row)\n",
    "    window[\"-ERRORSINGLE-\"].print(f\"Date: {row[0]}\", text_color='black')\n",
    "    window[\"-ERRORSINGLE-\"].print(f\"Dataset: {row[1]}\", text_color='black')\n",
    "    window[\"-ERRORSINGLE-\"].print(f\"4x4: {row[2]}\", text_color='black')\n",
    "    window[\"-ERRORSINGLE-\"].print(f\"Title: {row[3]}\", text_color='black')\n",
    "    window[\"-ERRORSINGLE-\"].print(f\"Stitle: {row[5]}\", text_color='black')\n",
    "    \n",
    "    window[\"-ERRORSINGLE-\"].print(f\"\\nMessage:\\n{row[4]}\", text_color='red')\n",
    "    if len(row[3]) > 10:\n",
    "       window[\"-ERRORTITLE-\"].print(f\"{row[3]}\", text_color='black')\n",
    "    elif len(row[5]) > 10:\n",
    "       window[\"-ERRORTITLE-\"].print(f\"{row[5]}\", text_color='black')\n",
    "        \n",
    "##############################################################################       \n",
    "                                  \n",
    "def showRecentLogs(errorsByDate):\n",
    "    xx = []\n",
    "    colWidths = (10,10,10,80)\n",
    "    rowColors = []\n",
    "    count=0\n",
    "    date0=list(errorsByDate.keys())[0]\n",
    "    cols=(\"plum4\")\n",
    "    bg=\"white\"\n",
    "    bgs=[]\n",
    "    count2=0\n",
    "    order = {}\n",
    "    for nn in errorsByDate.keys():\n",
    "        order[nn]= min(errorsByDate[nn][\"time\"])\n",
    "    \n",
    "    order = sorted(order.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    errorStatus = getErrorStatus()\n",
    " #   for date in sorted(errorsByDate,reverse=True):\n",
    "    for mrec in order:\n",
    "        date = mrec[0]\n",
    "        \n",
    "        string=f\"Date: {date};;\\n\\n\"\n",
    "        msg=\"\"\n",
    "        for nn in range(len(errorsByDate[date][\"name\"])):\n",
    "    #        print(f'    {errorsByDate[date][\"name\"][nn]}\\n      M {errorsByDate[date][\"msg\"][nn]}\\n      F{errorsByDate[date][\"file\"][nn]}\\n      L {errorsByDate[date][\"line\"][nn]}\\n')\n",
    "        \n",
    "          #  msg = textwrap.fill(errorsByDate[date][\"msg\"][nn],75)\n",
    "            if nn > 0:\n",
    "                msg+=\"\\n-----------------------------------\\n\"\n",
    "            msg+= errorsByDate[date][\"msg\"][nn]\n",
    "            uid = errorsByDate[date][\"uid\"][nn]\n",
    "            if uid not in errorStatus:\n",
    "           ##     yy = [date,errorsByDate[date][\"name\"][nn],errorsByDate[date][\"4x4\"][nn],errorsByDate[date][\"title\"][nn],msg,errorsByDate[date][\"stitle\"][nn],errorsByDate[date][\"uid\"][nn]]\n",
    "           ##     xx.append(yy)\n",
    "                if date != date0:\n",
    "                    count+=1\n",
    "                    if count%2 == 0:\n",
    "                        cols = (\"plum4\")\n",
    "                        bg=\"white\"\n",
    "                    else:\n",
    "                        cols = (\"SteelBlue3\")\n",
    "                        bg=\"black\"\n",
    "                if count2%2 == 0:\n",
    "                    cols=\"plum4\"\n",
    "                else:\n",
    "                    cols=\"SteelBlue3\"\n",
    "                count2+=1\n",
    "                date0=date\n",
    "                rowColors.append(cols)\n",
    "                bgs.append(bg)\n",
    "        yy = [errorsByDate[date][\"time\"][0],errorsByDate[date][\"name\"][0],errorsByDate[date][\"4x4\"][0],errorsByDate[date][\"title\"][0],msg,errorsByDate[date][\"stitle\"][nn],errorsByDate[date][\"uid\"][0]]\n",
    "        xx.append(yy)\n",
    "\n",
    "    rowNums = [num for num in range(0,len(rowColors)+1)]\n",
    "    colrw = list(zip(rowNums,rowColors))\n",
    "    colrw=list(zip(rowNums,bgs,rowColors))\n",
    "   \n",
    " #   print(\"XX XX XX\",xx)\n",
    "\n",
    "    header = [\"Date\",\"Dataset\",\"4x4\",\"Title\",\"Message\",\"Title Guess\",\"UID\"]\n",
    "\n",
    "    layout = [\n",
    "        [sg.Button(\"Quit\",font=\"CENTAUR 15 bold\")],\n",
    "        [sg.Button(\"Include Completed\",visible=True,font=\"CENTAUR 15 bold\"),\n",
    "         sg.Button(\"Hide Completed\",visible=False,font=\"CENTAUR 15 bold\")],\n",
    "        [sg.Text(\"Errors for the Last 2 Months\",font=\"CENTAUR 15 bold\")],\n",
    "        [sg.Table(values=xx,headings=header,visible_column_map=[True,True,True,True,True,False,False], size=(120, 30),row_height=40,row_colors=colrw,vertical_scroll_only=False,max_col_width=60,enable_events=True, key='-DAILY-',col_widths=colWidths)],\n",
    "        [sg.Push(), sg.Button('Update')],\n",
    "    ]\n",
    "    window = sg.Window('Title', layout, finalize=True,metadata=xx)\n",
    "    table = window[\"-DAILY-\"]  \n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    window[\"-DAILY-\"].Widget.column('#4', anchor='w') \n",
    "    return window\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "def updateLogs(how=1):\n",
    "    #  how    1 = update just this month (log.json.nn\n",
    "    #         2 = update Last Months file (log_backup_year_mo.json\n",
    "    #         3 = update all this years log files \n",
    "    pw=os.environ[\"OIT_PW\"]\n",
    "    #  compute previous month\n",
    "    x = datetime.today() - timedelta(days=30)\n",
    "    monthM = x.month  \n",
    "    yearM = x.year\n",
    "    print(\"Updating ETL Error Logs\", flush=True)\n",
    "    year = datetime.today().year\n",
    "    \n",
    "    string = f'''sshpass -p {pw} sftp -o HostKeyAlgorithms=+ssh-rsa -o PubkeyAcceptedAlgorithms=+ssh-rsa  giddensm@165.127.62.8 << !'''\n",
    "\n",
    "    if how == 1:  #  update this month\n",
    "        string+= f\"\\nmget /usr/local/cim/bic_etl/general/logs/log.json* {path}\"\n",
    "##  remove all of this months logs first to account for month changes\n",
    "        print(\"\\nCleaning Up Old FIles for THIS Month\\n\", flush=True)\n",
    "        for x in os.listdir(path):\n",
    "            if  re.findall(\"^log.json\\.\\d+\",x):\n",
    "                 file=f\"{path}/{x}\"\n",
    "                 print(\"Removing Local Log File\",file, flush=True)\n",
    "                 os.remove(file)\n",
    "        file=f\"{path}/log.json\"\n",
    "        print(\"Removing Local Log File\",file, flush=True)\n",
    "        os.remove(file)\n",
    "        \n",
    "    elif how == 2: \n",
    "        string+=f\"\\nmget /usr/local/cim/bic_etl/general/logs/log_backup_{yearM}_{monthM}*.json {path}\"\n",
    "    elif how == 3:\n",
    "        string+=f\"\\nmget /usr/local/cim/bic_etl/general/logs/log_backup_{year}*.json {path}\"\n",
    "    \n",
    "    string+=\"\\n!'''\"\n",
    "\n",
    " #   print(string)\n",
    "    result=subprocess.run([string], shell=True, stdout=subprocess.PIPE)\n",
    "    x = str(result.stdout)\n",
    "    nfiles=0\n",
    "    files=x.split(\"\\\\n\")\n",
    "    filesOut=[]\n",
    "    for line in files:\n",
    "     #   print(line)\n",
    "        if \"fetch\" in line.lower():\n",
    "            nfiles+=1\n",
    "            filesOut.append(line)      \n",
    "            \n",
    "    return nfiles,filesOut\n",
    "    \n",
    "##################################################\n",
    "\n",
    "def orderErrors(errorsByDate,errorStatus,flag):\n",
    "    xx=[]\n",
    "    bgs=[]\n",
    "    rowColors=[]\n",
    "    date0=list(errorsByDate.keys())[0]\n",
    "    count=0\n",
    "    count2=0\n",
    "    cols=(\"plum4\")\n",
    "    bg=\"white\"\n",
    "    for date in sorted(errorsByDate,reverse=True):\n",
    "        string=f\"Date: {date};;\\n\\n\"\n",
    "        for nn in range(len(errorsByDate[date][\"name\"])):\n",
    "            msg = errorsByDate[date][\"msg\"][nn]\n",
    "            uid = errorsByDate[date][\"uid\"][nn]\n",
    "            if uid not in errorStatus or flag==1:\n",
    "                yy = [date,errorsByDate[date][\"name\"][nn],errorsByDate[date][\"4x4\"][nn],errorsByDate[date][\"title\"][nn],msg,errorsByDate[date][\"stitle\"][nn],errorsByDate[date][\"uid\"][nn]]\n",
    "                xx.append(yy)\n",
    "                if date != date0:\n",
    "                    count+=1\n",
    "                    if count%2 == 0:\n",
    "                        cols = (\"plum4\")\n",
    "                        bg=\"white\"\n",
    "                    else:\n",
    "                        cols = (\"SteelBlue3\")\n",
    "                        bg=\"black\"\n",
    "                if count2%2 == 0:\n",
    "                    cols=\"plum4\"\n",
    "                else:\n",
    "                    cols=\"SteelBlue3\"\n",
    "                count2+=1\n",
    "                date0=date\n",
    "                if uid in errorStatus:\n",
    "                    cols=\"grey\"\n",
    "                rowColors.append(cols)\n",
    "                bgs.append(bg)\n",
    "\n",
    "\n",
    "    rowNums = [num for num in range(0,len(rowColors)+1)]\n",
    "  # colrw = list(zip(rowNums,rowColors))\n",
    "    colrw=list(zip(rowNums,bgs,rowColors))\n",
    "    return xx,colrw\n",
    "   \n",
    "#####################################################################\n",
    "\n",
    "def showLogSummary(values,columns):\n",
    "    layout = [[sg.Text(f\"Log Summary\",font=\"CENTAUR 15 bold\")],\n",
    "              [sg.Button(\"Quit\")],\n",
    "               [sg.Table(values=values,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=10,font=\"CENTAUR 10\",\n",
    "                   justification='left',vertical_scroll_only=False,background_color=\"#F8C471\",\n",
    "                   alternating_row_color=\"#FAE5D3\",key='-LOGSUMMARY-',headings = columns)]\n",
    "               ]\n",
    "    \n",
    "\n",
    "#    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(\"Log Summary\",layout,finalize=True,resizable=True)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableFile1 = window2['-LOGSUMMARY-']\n",
    "    tableFile1.bind('<Button-1>', \"Click\")\n",
    "   # headerStore[tableFile1] = columns\n",
    "   # statsStore[tableFile1] = stats1\n",
    "   \n",
    "    return window2\n",
    "\n",
    "############################################\n",
    "\n",
    "def reorderList(string:str,a:list):\n",
    "    ''' If string exists in list a, it will be moved to the top of the list '''\n",
    "    b = a.copy()\n",
    "    if string in b:\n",
    "        ai = b.index(string)\n",
    "        b.pop(ai)\n",
    "        c = [string]\n",
    "        c[1:] = b\n",
    "    else:\n",
    "        c=a.copy()\n",
    "        \n",
    "    return c\n",
    "\n",
    "############################################\n",
    "\n",
    "def getMostLike(a:str,b:list):\n",
    "    '''Searchs a list of strings for the value that is most like input the string a\n",
    "       Returns the string most like a\n",
    "       \n",
    "       col = getMostLike(\"someString\",someList)\n",
    "    '''\n",
    "    rmax = SequenceMatcher(None,a.lower(),b[0].lower()).ratio()\n",
    "    column=b[0]\n",
    "    if len(b) > 1:\n",
    "        for col in b[1:]:\n",
    "            r=SequenceMatcher(None,a.lower(),col.lower()).ratio()\n",
    "            if r > rmax:\n",
    "                rmax=r\n",
    "                column=col\n",
    "    return column\n",
    "\n",
    "#####################################################\n",
    "\n",
    "def writeFieldFile(w4x4,values,tmp,dirr):\n",
    "    mapped = {}\n",
    "    mapped[w4x4] = {}\n",
    "    xrefs = {}\n",
    "    notes = {}\n",
    "    dates = {}\n",
    "    print(\"DDIR \",dirr)\n",
    "    for key,val in values.items():\n",
    "        print(key,val)\n",
    "        if isinstance(key,str) and \":\" in key:\n",
    "       #     'LISTBOX:entityId': 'Entity Id', 0: 'Entity Id', 'NOTES:entityId':\n",
    "            spl = key.split(\":\")\n",
    "            val = val.strip()\n",
    "            spl[1]=spl[1].strip()\n",
    "            spl[0]=spl[0].strip()\n",
    "\n",
    "\n",
    "            if spl[0] == \"LISTBOX\":  \n",
    "                if val not in mapped[w4x4]:                        \n",
    "                    mapped[w4x4][val] = {}  \n",
    "                mapped[w4x4][val][\"xref\"] =spl[1]\n",
    "                mapped[w4x4][val][\"desc\"] = tmp[spl[1]]\n",
    "                xrefs[spl[1]] = val\n",
    "            elif spl[0] == \"NOTES\":\n",
    "                notes[spl[1]] = val\n",
    "            elif spl[0] == \"DATE\":\n",
    "                dates[spl[1]] = val\n",
    "    for id in notes:\n",
    "        xrf = xrefs[id]\n",
    "        mapped[w4x4][xrf][\"notes\"] = notes[id]\n",
    "        mapped[w4x4][xrf][\"date\"] = dates[id]\n",
    "\n",
    "#    print(\"MAP \",mapped) \n",
    "    out = f\"{dirr}/{w4x4}_fields.json\"\n",
    "    with open(out,\"w\") as jfile:\n",
    "        jfile.write(json.dumps(mapped))\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def createFieldFile(w4x4,orig,trans):\n",
    "    todayDate=f\"{today.year}-{today.month}-{today.day}\"    \n",
    "    tmp = {}\n",
    "# create a dictionary of the descripitons of the transform fields for easy lookup\n",
    "    for nn,fld in enumerate(fields[w4x4]['cim']):\n",
    "        tmp[fld] = fields[cim4x4]['description'][nn]\n",
    "    tmpT2O = {}\n",
    "    for col in trans:\n",
    "        cc = getMostLike(col,orig)\n",
    "        tmpT2O[col]=cc\n",
    "    col1 = []\n",
    "    col2 = []\n",
    "    col3 = []\n",
    "    rows = []\n",
    "    origTmp = orig.copy()\n",
    "    for col in trans:\n",
    "        if col in tmp:\n",
    "          row=[]\n",
    "          origTmp = reorderList(tmpT2O[col],sorted(origTmp))\n",
    "          row.append(sg.Combo(origTmp,default_value=tmpT2O[col],enable_events=True,  \n",
    "                                font='Courier 15 bold ',key=f\"LISTBOX:{col}\",\n",
    "                         #       select_mode=\"LISTBOX_SELECT_MODE_SINGLE\",\n",
    "                                size=(20,6)))\n",
    "          row.append(sg.Text(col,font='Courier 15 bold ',size=(30,1)))\n",
    "          row.append(sg.Multiline(tmp[col],font='Courier 12',size=(30,2)))\n",
    "          row.append(sg.Multiline(\"\",font='Courier 12',size=(30,2),key=f\"NOTES:{col}\"))\n",
    "          row.append(sg.Input(todayDate,font='Courier 15 bold ',size=(10,1),key=f\"DATE:{col}\"))\n",
    "        \n",
    "          rows.append([sg.Frame(\"\",[row])])\n",
    "            \n",
    "    layout = [[sg.Button(\"Quit\"),sg.Button(\"Write Fields\")],rows]\n",
    "             \n",
    "    sg.theme(\"LightBrown6\")     \n",
    "    window2 = sg.Window(\"Log Summary\",layout,finalize=True,resizable=True)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    \n",
    "##########################################################\n",
    "    \n",
    "def tkPopup(string,title,bgColor=\"grey\"):\n",
    "    toWrite=False\n",
    "    def close():\n",
    "       popup.destroy()\n",
    "       popup.quit()\n",
    "\n",
    "    popup = tk.Tk()\n",
    "    popup.wm_title(title)\n",
    "    label = Label(popup, text=string,font=('Courier',20),justify=\"left\", relief=\"groove\")\n",
    "    label.configure(bg=bgColor)\n",
    "    label.pack(side=\"top\", fill=\"x\", pady=10)\n",
    "    my_button= Button(popup, text= \"OK\", font=('Courier',25),\n",
    "    borderwidth=2, command= close)\n",
    "    my_button.pack(pady=20)\n",
    "    popup.mainloop()\n",
    "      \n",
    "##########################################################\n",
    "    \n",
    "def tkPopupWrite(w4x4,string,title,bgColor=\"grey\"):\n",
    "    toWrite=False\n",
    "    def close():\n",
    "       popup.destroy()\n",
    "       popup.quit()\n",
    "    \n",
    "    def toFile():\n",
    "       with open(f\"{w4x4}_source_field_defintions.json\",\"w\") as jfile:\n",
    "            jfile.write(json.dumps(mapping))\n",
    "\n",
    "       popup.destroy()\n",
    "       popup.quit()\n",
    "        \n",
    "    popup = tk.Tk()\n",
    "    popup.wm_title(title)\n",
    "    label = Label(popup, text=string,font=('Courier',20),justify=\"left\", relief=\"groove\")\n",
    "    label.configure(bg=bgColor)\n",
    "    label.pack(side=\"top\", fill=\"x\", pady=10)\n",
    "    my_button_w= Button(popup, text= \"Write\", font=('Courier',25),\n",
    "    borderwidth=2, command= toFile)\n",
    "    my_button_w.pack(pady=20)\n",
    "    \n",
    "    my_button= Button(popup, text= \"Cancel\", font=('Courier',25),\n",
    "    borderwidth=2, command= close)\n",
    "    my_button.pack(pady=20)\n",
    "    popup.mainloop()\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def tkPopScroll(string,someFunc,outF,mapping):\n",
    "    def close():\n",
    "       root.destroy()\n",
    "       root.quit()\n",
    "\n",
    "    \n",
    "    \n",
    "    root = tk.Tk()\n",
    "    root.resizable(False, False)\n",
    "    root.title(\"Scrollbar Widget Example\")\n",
    "\n",
    "    # apply the grid layout\n",
    "    root.grid_columnconfigure(0, weight=1)\n",
    "    root.grid_rowconfigure(0, weight=1)\n",
    "\n",
    "    # create the text widget\n",
    "    text = tk.Text(root, height=10)\n",
    "    text.grid(row=0, column=0, sticky=tk.EW)\n",
    "\n",
    "    # create a scrollbar widget and set its command to the text widget\n",
    "    scrollbar = ttk.Scrollbar(root, orient='vertical', command=text.yview)\n",
    "    scrollbar.grid(row=0, column=1, sticky=tk.NS)\n",
    "\n",
    "    #  communicate back to the scrollbar\n",
    "    text['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "    # add sample text to the text widget to show the screen\n",
    "    # for i in range(1,50):\n",
    "    #     position = f'{i}.0'\n",
    "    for nn,val in enumerate(string.split(\"\\n\")):\n",
    "       m = float(nn+1)\n",
    "       text.insert(f\"{m}\",f\"{val}\\n\")\n",
    "\n",
    "    my_button= Button(root, text= \"Cancel\", font=('Courier',15),\n",
    "    borderwidth=2, command= close)\n",
    "    my_button.grid(row=nn+2, column=0, sticky=tk.EW)\n",
    "    \n",
    "    my_buttonW= Button(root, text= \"Write\", font=('Courier',15),\n",
    "    borderwidth=2, command= lambda: someFunc(root,outF,mapping))\n",
    "    my_buttonW.grid(row=nn+2, column=1, sticky=tk.EW)\n",
    "    \n",
    " #   my_button.pack(pady=20)\n",
    "    root.mainloop()\n",
    "     \n",
    "###################################################################################\n",
    "\n",
    "def tkPopScrollSimple(string):\n",
    "    def close():\n",
    "       root.destroy()\n",
    "       root.quit()\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.resizable(False, False)\n",
    "    root.title(\"Scrollbar Widget Example\")\n",
    "\n",
    "    # apply the grid layout\n",
    "    root.grid_columnconfigure(0, weight=1)\n",
    "    root.grid_rowconfigure(0, weight=1)\n",
    "\n",
    "    # create the text widget\n",
    "    text = tk.Text(root, height=10)\n",
    "    text.grid(row=0, column=0, sticky=tk.EW)\n",
    "\n",
    "    # create a scrollbar widget and set its command to the text widget\n",
    "    scrollbar = ttk.Scrollbar(root, orient='vertical', command=text.yview)\n",
    "    scrollbar.grid(row=0, column=1, sticky=tk.NS)\n",
    "\n",
    "    #  communicate back to the scrollbar\n",
    "    text['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "    # add sample text to the text widget to show the screen\n",
    "    # for i in range(1,50):\n",
    "    #     position = f'{i}.0'\n",
    "    for nn,val in enumerate(string.split(\"\\n\")):\n",
    "       m = float(nn+1)\n",
    "       text.insert(f\"{m}\",f\"{val}\\n\")\n",
    "\n",
    "    my_button= Button(root, text= \"OK\", font=('Courier',15),\n",
    "    borderwidth=2, command= close)\n",
    "    my_button.grid(row=nn+2, column=0, sticky=tk.EW)\n",
    "    \n",
    "    root.mainloop()\n",
    "        \n",
    "###########################################################################\n",
    "\n",
    "def toFile(win,outF,mapping):\n",
    "       print(\"writing out file\")\n",
    "       with open(outF,\"w\") as jfile:\n",
    "            jfile.write(json.dumps(mapping))\n",
    "        \n",
    "       win.destroy()\n",
    "       win.quit()\n",
    "\n",
    "######################################################################################\n",
    "    \n",
    "def writeSoureFieldList(w4x4,values,targDir,datasetCharId):      \n",
    "    mapping = {}\n",
    "    for k,v in values.items():\n",
    "        if k[:4] == \"DEFS\":\n",
    "           if v not in mapping:\n",
    "              mapping[v] = []\n",
    "           mapping[v].append(k[6:].strip())\n",
    "    stringGood=\"\"\n",
    "    stringBad=\"\"\n",
    "    nbad=0\n",
    "    finalMap = {}\n",
    "    for col,v in mapping.items():\n",
    "        if len(v) > 1:\n",
    "           for val in v:\n",
    "                stringBad+= f\"{col}  -> {val}\\n\"\n",
    "           nbad+=1\n",
    "           stringBad+= f\"\\n\"\n",
    "        else:\n",
    "           stringGood+= f\"{col}  -> {v[0]}\\n\\n\"\n",
    "           finalMap[col] = v[0]\n",
    "        \n",
    "    if len(stringBad) > 0:\n",
    "        stringAll = f\"Dataset: w4x4\\nError Inputing Definitions for Source Fields\\n\"\n",
    "        stringAll+= f\"{nbad} out of {len(mapping)} Fields have Multiple Definitions\\n\\n\"\n",
    "        print(f\"Bad {nbad} out of {len(mapping)} \",stringBad)\n",
    "        stringAll+=stringBad\n",
    "        tkPopup(stringAll,\"Errors in Creating Source Definitions\",\"pink\")\n",
    "    else:\n",
    "        print(\"Good\",stringGood)\n",
    "        outFile = os.path.join(targDir,f\"{w4x4}_{datasetCharId}_src_fld_defs.json\")\n",
    "        print(\"OUTFILE \",outFile)\n",
    " #       tkPopupWrite(w4x4,stringGood,\"Creating Source Definitions\",\"white\")\n",
    "        tkPopScroll(stringGood,toFile,outFile,finalMap)\n",
    "    return outFile\n",
    "    \n",
    "################################################################\n",
    "\n",
    "def createDir(targDir):\n",
    "    '''Creates a directory (targDir) if it does not exist\n",
    "    '''\n",
    "    print(targDir)\n",
    "    if os.path.isdir(targDir):\n",
    "        string=f\"{targDir}\\nAll Ready Exists\"\n",
    "        sg.popup(string)\n",
    "    else:\n",
    "        os.mkdir(targDir)\n",
    "        string=f\"Created Directory {targDir}\"\n",
    "        sg.popup(string)\n",
    "        \n",
    "#############################################\n",
    "\n",
    "def writeFieldFileN(w4x4,values,targDir,datasetCharId):\n",
    "    ''' Read the Form created for mapping Source Fields to Transformed Fields, \n",
    "        write out to a json file, called  w4x4_fields.json\n",
    "        This checks all the fiels for proper mapping b/w source fields and \n",
    "        transformed fields\n",
    "    '''\n",
    "    global mapped\n",
    "    mapped = {}\n",
    "    mapped[w4x4] = {}\n",
    "    xrefs = {}\n",
    "    notes = {}\n",
    "    dates = {}\n",
    "    hold = {}\n",
    "    print(\"OH YEah... WRITING SOME XREFS\")\n",
    "## Get Values read from Field List Form, put them into a dictionary for output \n",
    "## as a JSON\n",
    "    for key,val in values.items():\n",
    "        \n",
    "        if isinstance(key,str) and \":\" in key:\n",
    "       #     'LISTBOX:entityId': 'Entity Id', 0: 'Entity Id', 'NOTES:entityId':\n",
    "            spl = key.split(\":\")\n",
    "            val = val.strip()\n",
    "            spl[1]=spl[1].strip()\n",
    "            spl[0]=spl[0].strip()\n",
    "            \n",
    "            if spl[0] == \"SOURCE\":  \n",
    "                if spl[1] != \"CUST\":\n",
    "                    if spl[1] not in mapped[w4x4]:                        \n",
    "                        mapped[w4x4][spl[1]] = {}  \n",
    "            elif spl[0] == \"LISTBOX\":\n",
    "                if spl[1] not in mapped[w4x4]:                        \n",
    "                    mapped[w4x4][spl[1]] = {}  \n",
    "                mapped[w4x4][spl[1]][\"xref\"] = val \n",
    "            elif spl[0] == \"DESC\":\n",
    "                if spl[1] != \"CUST\":\n",
    "                   if spl[1] not in mapped[w4x4]:                        \n",
    "                        mapped[w4x4][spl[1]] = {}  \n",
    "                   mapped[w4x4][spl[1]][\"desc\"] = val        \n",
    "            elif spl[0] == \"NOTES\":\n",
    "                if spl[1] != \"CUST\":\n",
    "                    if spl[1] not in mapped[w4x4]:                        \n",
    "                        mapped[w4x4][spl[1]] = {}  \n",
    "                    mapped[w4x4][spl[1]][\"notes\"] = val \n",
    "            elif spl[0] == \"DATE\":\n",
    "                if spl[1] != \"CUST\":\n",
    "                    if spl[1] not in mapped[w4x4]:                        \n",
    "                        mapped[w4x4][spl[1]] = {}  \n",
    "                    mapped[w4x4][spl[1]][\"date\"] = val \n",
    "                    \n",
    "            elif spl[1] == \"CUST\" and spl[0] in [\"SOURCEC\",\"TRANSC\",\"DESCC\",\"NOTESC\",\"DATEC\"] and len(val) > 0:\n",
    "                print(\"CUSTOM \",key,spl[0])\n",
    "                nn = spl[2]\n",
    "                if nn not in hold:\n",
    "                    hold[nn] = {}\n",
    "                hold[nn][spl[0]] = val\n",
    "                \n",
    "##  Add any custom Fields to mapped\n",
    "    for k,v in hold.items():\n",
    "        print(\"KK,VV \",k,v)\n",
    "        if \"SOURCEC\" in v and len(v[\"SOURCEC\"]) > 0 :\n",
    "            mapped[w4x4][v[\"SOURCEC\"]] = {}\n",
    "            mapped[w4x4][v[\"SOURCEC\"]][\"xref\"]=v[\"TRANSC\"]\n",
    "            mapped[w4x4][v[\"SOURCEC\"]][\"notes\"]=v[\"NOTESC\"]\n",
    "            mapped[w4x4][v[\"SOURCEC\"]][\"desc\"]=v[\"DESCC\"]\n",
    "            mapped[w4x4][v[\"SOURCEC\"]][\"date\"]=v[\"DATEC\"]\n",
    "                       \n",
    "    try: \n",
    "##  Check mapped fields for duplicates\n",
    "        statsT2O = {}\n",
    "        statsO = {}\n",
    "        oFCount=0\n",
    "        tFCount=0\n",
    "        stringMap = \"\"\n",
    "        stringBad = \"\"\n",
    "        print(\"checking mapped data\")\n",
    "        for  w4x4,dct in mapped.items():\n",
    "             for oF,info in dct.items():\n",
    "                    tF = info['xref']\n",
    "                    if tF not in statsT2O:\n",
    "                        statsT2O[tF] = []\n",
    "                    statsT2O[tF].append(oF)\n",
    "                    if oF not in statsO:\n",
    "                        statsO[oF] = 0\n",
    "                    statsO[oF]+=1\n",
    "             print(\"Checking Transformed fields\")\n",
    "        ## Check that Transformed Fields are only being referenced by 1 Original Field            \n",
    "             for tF,xrfs in statsT2O.items():\n",
    "                if len(xrfs) > 1:\n",
    "                    print(f\"{tF} too many X-Refs\")\n",
    "                    for val in xrfs:\n",
    "                        stringBad+= f\" {tF} -> {val}\\n\"\n",
    "                    stringBad+=f\"\\n\"\n",
    "                elif tF == \"NONE\":\n",
    "                        stringBad+=\"Transformed Fields is set to NONE... Please set a Legitimate X-ref\\n\"\n",
    "                        stringBad+=f\"  {tF} -> {xrfs[0]}\\n\\n\"\n",
    "                else:\n",
    "                    stringMap+= f\" {xrfs[0]} -> {tF}\\n\"\n",
    "                    tFCount+=1\n",
    "\n",
    "             for oF,count in statsO.items():\n",
    "                if count > 1:\n",
    "                    print(f\"Roh-Roh... Mulitple listings for {oF}   Found {count} times\")\n",
    "                else:\n",
    "                    oFCount+=1\n",
    "    ##  Used to close tkinter window               \n",
    "        def close():\n",
    "            popup.destroy()\n",
    "            popup.quit()\n",
    "\n",
    "\n",
    "        if len(stringBad) == 0:\n",
    "            print(\"GOOD GOOD GOOD\")\n",
    "            stringAll = f\"Dataset {w4x4}\\n Source Fields {oFCount}\\nTransformed Fields {tFCount}\\n\\n\\n\"\n",
    "            stringAll+=stringMap\n",
    "            tkPopScrollSimple(stringAll)\n",
    "   #         sg.popup(stringAll)\n",
    "        else:\n",
    "            stringAll = \"Errors were Found... file will NOT be written\\n\\n\"\n",
    "            stringAll+= \"Please FIX ERRORS , then retry writing the file\\n\\n\"\n",
    "            stringAll+= \"Transformed Field xrefed to Multiple Source Fields and/or Transformed Fields are set to NONE\\n\\n\"\n",
    "            stringAll+= \" Transformed Field  ->  Source Field\\n\\n\"\n",
    "            stringAll+= stringBad\n",
    "            print(\"BAD BAD BAD\",stringAll)\n",
    "            popup = tk.Tk()\n",
    "            popup.wm_title(\"Field List Error\")\n",
    "            label = Label(popup, text=stringAll,font=('Courier',20),justify=\"left\", relief=\"groove\")\n",
    "            label.configure(bg=\"pink\")\n",
    "            label.pack(side=\"top\", fill=\"x\", pady=10)\n",
    "            # B1 = ttk.Button(popup, text=\"Okay\", command = popup.destroy)\n",
    "            # B1.pack()\n",
    "            my_button= Button(popup, text= \"OK\", font=('Courier',25),\n",
    "            borderwidth=2, command= close)\n",
    "            my_button.pack(pady=20)\n",
    "            popup.mainloop()\n",
    "            return\n",
    "\n",
    "        outFile = os.path.join(targDir,f\"{w4x4}_{datasetCharId}_src_trns_xrefs.json\")\n",
    "        print(\"WRITING XREF FIELDS TO \",outFile)\n",
    "        with open(outFile,\"w\") as jfile:\n",
    "            jfile.write(json.dumps(mapped))\n",
    "    except Exception as err:\n",
    "         exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "        \n",
    "\n",
    "##################################################################\n",
    "\n",
    "def createSrcTransFieldXref(w4x4,orig,trans,srcDefFile,targDir):\n",
    "    '''\n",
    "    This function creates a Cross Reference List between the \n",
    "    Source Field List and Transform Field list for a dataset\n",
    "    A form will be created and seeded with the Source Field list and \n",
    "    Descriptions found in the srcDefFile.  This will thne use the trans\n",
    "    column listsing for the Transformed Fields to  guess a best match\n",
    "    for each Source Field.  Users will then be able to fix the guesses \n",
    "    for the Transformed Fields.\n",
    "    The Form allows users to create a new Transform Field if needed.\n",
    "    The Form also allows for the creation of totally NEW Source and Transform\n",
    "    listings    \n",
    "    '''\n",
    "    todayDate=f\"{today.year}-{today.month}-{today.day}\"    \n",
    "    tmp = {}\n",
    "# create a dictionary of the descripitons of the transform fields for easy lookup\n",
    "## If there is a source definition file, use it to seed the defintion/descriptions\n",
    "    if len(srcDefFile) > 4:\n",
    "        fin = open(sourceDefFile,\"r\")\n",
    "        tmp=json.load(fin)\n",
    "    else:\n",
    "        # for nn,fld in enumerate(fields[w4x4]['cim']):\n",
    "        #     tmp[fld] = fields[cim4x4]['description'][nn]\n",
    "        sg.popup(\"No Source Definition File Found\")\n",
    "        return \"  \"\n",
    "    tmpO2T = {}\n",
    "    for col in orig:\n",
    "        cc = getMostLike(col,trans)\n",
    "        tmpO2T[col]=cc\n",
    "    col1 = []\n",
    "    col2 = []\n",
    "    col3 = []\n",
    "    rows = []\n",
    "    transTmp = trans.copy()\n",
    "    row=[]\n",
    "    rowC=[]\n",
    "    \n",
    " #   [\"Source Field\",\"Transformed Field\",\"Description\",\"Date\",\"Notes\"]\n",
    "    row.append(sg.Text(\"Source Field\",font='Courier 15 bold ',text_color=\"black\",justification=\"left\",size=(30,1))) \n",
    "    rowC.append(sg.Text(\"Source Field\",font='Courier 15 bold ',text_color=\"black\",key=\"HC1\",justification=\"center\",size=(30,1))) \n",
    "\n",
    "    row.append(sg.Text(\"Transformed Field\",font='Courier 15 bold ',text_color=\"black\",justification=\"left\",size=(30,1)))    \n",
    "    rowC.append(sg.Text(\"Transformed Field\",font='Courier 15 bold ',text_color=\"black\",key=\"HC2\",justification=\"center\",size=(30,1)))    \n",
    "\n",
    "    row.append(sg.Text(\"Description\",font='Courier 15 bold ',text_color=\"black\",justification=\"left\",size=(30,1)))    \n",
    "    rowC.append(sg.Text(\"Description\",font='Courier 15 bold ',text_color=\"black\",key=\"HC3\",justification=\"center\",size=(30,1)))    \n",
    "\n",
    "    row.append(sg.Text(\"Notes\",font='Courier 15 bold ',text_color=\"black\",justification=\"left\",size=(30,1)))    \n",
    "    rowC.append(sg.Text(\"Notes\",font='Courier 15 bold ',text_color=\"black\",key=\"HC4\",justification=\"center\",size=(30,1)))    \n",
    "\n",
    "    row.append(sg.Text(\"Change Date\",font='Courier 15 bold ',text_color=\"black\",justification=\"left\",size=(15,1)))   \n",
    "    rowC.append(sg.Text(\"Change Date\",font='Courier 15 bold ',text_color=\"black\",key=\"HC5\",justification=\"center\",size=(15,1)))   \n",
    "\n",
    "    #   frameCustHead = sg.Frame(\"\",[row],key=\"FRAME:CUSTHEAD\",visible=False)\n",
    "    rows.append([sg.Frame(\"\",[row],key=\"HEADER\")])\n",
    "    \n",
    "    for col in orig:\n",
    "        \n",
    "          row=[]\n",
    "          row.append(sg.Input(col,key=f\"SOURCE:{col}\",font='Courier 15 bold ',size=(30,1)))\n",
    "##  put the most likely matching string on top of list, so it appears as first\n",
    "##  option ins combo box\n",
    "          transTmp = reorderList(tmpO2T[col],sorted(transTmp))\n",
    "##  Add NONE as an option to account for No Matches in terms of a new field\n",
    "          a=transTmp.copy()\n",
    "          a.append(\"NONE\")    \n",
    "          row.append(sg.Combo(a,default_value=tmpO2T[col],enable_events=True,  \n",
    "                                font='Courier 15 bold ',key=f\"LISTBOX:{col}\",\n",
    "                         #       select_mode=\"LISTBOX_SELECT_MODE_SINGLE\",\n",
    "                                size=(30,6)))\n",
    "          row.append(sg.Multiline(tmp[col],font='Courier 15',key=f\"DESC:{col}\",size=(30,2)))\n",
    "          row.append(sg.Multiline(\"\",font='Courier 15',size=(30,2),key=f\"NOTES:{col}\"))\n",
    "          row.append(sg.Input(todayDate,font='Courier 15 bold ',size=(15,1),key=f\"DATE:{col}\"))\n",
    "        \n",
    "          rows.append([sg.Frame(\"\",[row])])\n",
    "        \n",
    "    rowsC = []\n",
    "    rowsC.append([sg.Frame(\"\",[rowC],key=\"someFrame\",visible=False)])\n",
    "\n",
    "##  Add custom fields, make them invisible until needed, one by one    \n",
    "    for nn in range(1,6):\n",
    "          row=[]\n",
    "         \n",
    "          row.append(sg.Input(\"\",\n",
    "                                font='Courier 15 bold ',key=f\"SOURCEC:CUST:{nn}\",visible=True,\n",
    "                         #       select_mode=\"LISTBOX_SELECT_MODE_SINGLE\",visible=False,\n",
    "                                size=(21,1),enable_events=False))\n",
    "          row.append(sg.Input(\"\",font='Courier 15 bold ',visible=True,key=f\"TRANSC:CUST:{nn}\",size=(31,1)))\n",
    "          row.append(sg.Input(\"\",font='Courier 15',size=(31,1),visible=True,key=f\"DESCC:CUST:{nn}\"))\n",
    "          row.append(sg.Multiline(\"\",font='Courier 15',size=(31,2),visible=True,key=f\"NOTESC:CUST:{nn}\"))\n",
    "          row.append(sg.Input(todayDate,font='Courier 15 bold ',visible=True,size=(11,1),key=f\"DATEC:CUST:{nn}\"))\n",
    "        \n",
    "          rowsC.append([sg.Frame(\"\",[row],visible = False,key=f\"FRAME:CUST:{nn}\")])\n",
    "  #  rows.append([sg.Frame(\"Custom Fields\",[rowsC])])\n",
    "        \n",
    "        \n",
    "    layout = [[sg.Button(\"Quit\"),sg.Button(\"Add XREF Field\")],\n",
    "               [sg.Button(\"Write XREF File\")],\n",
    "               [sg.Column(rows,scrollable=True)],\n",
    "               [sg.Frame(\"Custom Fields\",rowsC,font='Courier 15 bold ',visible=False,relief=\"sunken\",key=\"secondFrame\")]]\n",
    "             \n",
    "    sg.theme(\"LightBrown6\")     \n",
    "    window2 = sg.Window(\"Log Summary\",layout,finalize=True,resizable=True)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "      \n",
    "    return transTmp\n",
    "\n",
    "###############################################################\n",
    "\n",
    "def showSrc2TransXrefs(file):\n",
    "    '''  Display the Source to Transformed Fields Dictionary for the Dataset\n",
    "    '''\n",
    "    if not os.path.isfile(file):\n",
    "       sg.popup(f\"Source-Transform Dictionary File Does NOT EXIST..\")\n",
    "       return\n",
    "    \n",
    "    fin = open(file,\"r\")\n",
    "    info = json.load(fin)\n",
    "    rows=[]\n",
    "    row=[]\n",
    "    row.append(sg.Text(\"Source Field\",font='Courier 15 bold ',background_color=\"#c2c2d6\",text_color=\"black\",justification=\"left\",size=(30,1))) \n",
    "    row.append(sg.Text(\"Transformed Field\",font='Courier 15 bold ',background_color=\"#c2c2d6\",text_color=\"black\",justification=\"left\",size=(30,1)))    \n",
    "    row.append(sg.Text(\"Description\",font='Courier 15 bold ',background_color=\"#c2c2d6\",text_color=\"black\",justification=\"left\",size=(31,1)))    \n",
    "    row.append(sg.Text(\"Notes\",font='Courier 15 bold ',background_color=\"#c2c2d6\",text_color=\"black\",justification=\"left\",size=(31,1)))    \n",
    "    row.append(sg.Text(\"Change Date\",font='Courier 15 bold ',background_color=\"#c2c2d6\",text_color=\"black\",justification=\"left\",size=(15,1)))   \n",
    "    rows.append([row])\n",
    "    nrows=0\n",
    "    colors = [\"#6699ff\",\"#66ccff\"]\n",
    "    for w4x4,data in info.items():\n",
    "        for field,defs in data.items():\n",
    "              nrows+=1\n",
    "              colr = colors[nrows%2]\n",
    "              row=[]\n",
    "              row.append(sg.Input(field,font='Courier 15 bold ',background_color=colr,size=(30,1)))\n",
    "              row.append(sg.Input(defs['xref'],background_color=colr,font='Courier 15 bold ',size=(30,1)))  \n",
    "              row.append(sg.Multiline(defs['desc'],background_color=colr,font='Courier 15',size=(30,2)))\n",
    "              row.append(sg.Multiline(defs['notes'],background_color=colr,font='Courier 15',size=(30,2)))\n",
    "              row.append(sg.Input(defs['date'],background_color=colr,font='Courier 15 bold ',size=(15,1)))\n",
    "              rows.append(row)\n",
    "\n",
    "#         for nn in range(1,6):\n",
    "#           row=[]\n",
    "         \n",
    "#           row.append(sg.Input(\"\",\n",
    "#                                 font='Courier 15 bold ',key=f.0{nn}\",visible=True,\n",
    "#                          #       select_mode=\"LISTBOX_SELECT_MODE_SINGLE\",visible=False,\n",
    "#                                 size=(21,1),enable_events=False))\n",
    "#           row.append(sg.Input(\"\",font='Courier 15 bold ',visible=True,key=f\"TRANSC:CUST:{nn}\",size=(31,1)))\n",
    "#           row.append(sg.Multiline(\"\",font='Courier 15',size=(31,2),visible=True,key=f\"NOTESC:CUST:{nn}\"))\n",
    "#           row.append(sg.Multiline(\"\",font='Courier 15',size=(31,2),visible=True,key=f\"NOTESC:CUST:{nn}\"))\n",
    "#           row.append(sg.Input(todayDate,font='Courier 15 bold ',visible=True,size=(11,1),key=f\"DATEC:CUST:{nn}\"))\n",
    "         \n",
    "\n",
    "\n",
    "    header = [\"Source Field\",\"Transformed Field\",\"Description\",\"Notes\",\"Date\"]\n",
    "    layout = [[sg.Text(f\"Source-Transformed Field XREFS\",font=\"CENTAUR 15 bold\")],\n",
    "              [sg.Text(f\"{file}\",font=\"CENTAUR 15 bold\")],\n",
    "              [sg.Button(\"Quit\")],\n",
    "              rows     \n",
    "               ]\n",
    "    \n",
    "\n",
    "#    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(\"Source-Transform Field XREFS\",layout,background_color=\"white\",finalize=True,resizable=True)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "xrefsBy4x4,xrefsByTitle,fields = getXrefs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d8301-6cb3-4785-ad8b-8187a8764b02",
   "metadata": {},
   "source": [
    "## Functions 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697eea5d-a26a-4bf7-a2cc-bf36741927de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compareWindow -> ExtractAnal   -> TABLEFILE-Click(showDFUNwindow) -> TABLE-CLICK (showDFRecswindow)\n",
    "#                 TransformAnal\n",
    "#\n",
    "## sourceDefs2Fields -> writeSoureFieldList -> tkPopScroll -> toFile\n",
    "#\n",
    "#\n",
    "## createSrcTransFieldXref -> writeFieldFileN -> \n",
    "#############################################################   \n",
    "\n",
    "def sourceDefs2Fields(fields): \n",
    "    '''Reads a csv with the definition listings,and gets the fields listings from\n",
    "       the Extract process, and creates a form for creating a Source Field list to Source\n",
    "       Definition file\n",
    "    '''\n",
    "    global mapping\n",
    "    dfF = pd.read_csv(\"char_org_ext_Fields.csv\",delimiter=\"\\t\")\n",
    "    defs = dfF[\"Description\"].values.tolist()\n",
    "    rows = []\n",
    "    fieldsTmp = fields.copy()\n",
    "    tmpD2F = {}\n",
    "    mapping = {}\n",
    "    for col in defs:\n",
    "        cc = getMostLike(col,fields)\n",
    "        tmpD2F[col]=cc\n",
    "    \n",
    "    for nn,col in enumerate(defs):\n",
    "        row=[]\n",
    "        fieldsTmp = reorderList(tmpD2F[col],sorted(fieldsTmp))\n",
    "        row.append(sg.Combo(fieldsTmp,default_value=tmpD2F[col],enable_events=True,  \n",
    "                            font='Courier 15 bold ',key=f\"DEFS::{col}\",\n",
    "                     #       select_mode=\"LISTBOX_SELECT_MODE_SINGLE\",\n",
    "                            size=(30,6)))\n",
    "        row.append(sg.Text(col,font='Courier 15',key=f\"{col}\",size=(30,3)))\n",
    "        rows.append([sg.Frame(\"\",[row])])\n",
    "        \n",
    "    layout = [[sg.Button(\"Quit\")],\n",
    "              [sg.Button(\"Source Analysis\",key=\"-EXTRACTANAL-\")],\n",
    "              [sg.Button(\"Write Source Defs\")],\n",
    "               [sg.Column(rows,scrollable=True)]\n",
    "             ]\n",
    "  \n",
    "    sg.theme(\"LightBrown4\")     \n",
    "    window2 = sg.Window(\"Input Source Definitions\",layout,finalize=True,resizable=True)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def compare2Data(df,xrefs):\n",
    "    global dcols,pcols,rowColors,values,dnotpLines\n",
    "    dcols = list(df.columns)\n",
    "    pcols = list(xrefs.keys())\n",
    "    \n",
    "    wid = windowsStore[\"columnAnalysis\"]\n",
    "    rowColors = wid[\"-TABLECOLUMN-\"].metadata[1]\n",
    "    values = wid[\"-TABLECOLUMN-\"].metadata[0]\n",
    "   \n",
    "    colr1 = rowColors[0][1]\n",
    "    colr2 = rowColors[1][1]\n",
    "    \n",
    "    pnotd = []\n",
    "    dnotp = []\n",
    "    dnotpLines = {}\n",
    "\n",
    "    for col in pcols:\n",
    "        if col not in dcols:\n",
    "            pnotd.append(col)\n",
    "\n",
    "    for col in dcols:\n",
    "        if col not in pcols:\n",
    "            dnotp.append(col)\n",
    "            for line in transformProgram:\n",
    "                if line.find(col) > -1:\n",
    "                   if col in dnotpLines:\n",
    "                     dnotpLines[col].append(line)\n",
    "                   else:\n",
    "                     dnotpLines[col] = []\n",
    "                     dnotpLines[col].append(line)\n",
    "                                 \n",
    "    for nn,value in enumerate(values):    \n",
    "        if nn%2 == 0:\n",
    "            rowColor= colr1\n",
    "        else:\n",
    "            rowColor= colr2\n",
    "\n",
    "        col = value[0]\n",
    "\n",
    "        if col in pnotd:\n",
    "            rowColor = \"pink\"\n",
    "\n",
    "        colr = (nn,rowColor)\n",
    "        rowColors.append(colr)\n",
    "\n",
    "        \n",
    "    sp = \"\\n\".join(pnotd)\n",
    "    sd = \"\\n\".join(dnotp)\n",
    "    \n",
    "        \n",
    "    wid[\"-TABLECOLUMN-\"].update(row_colors=rowColors)  \n",
    "    wid[\"-PNOTD-\"].update(pnotd)    \n",
    "    wid[\"-DNOTP-\"].update(dnotp)    \n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "\n",
    "def compareWindow(parentWindow,stats1,df1,file1,title=\"Compare\",colorTheme=\"'Dark Green 5'\"):\n",
    "    global color1,color2,compWindow\n",
    "    header_list = [\"Column\",\"% Missing\",\"Missing\",\"string\",\"integer\",\"float\",\"boolean\"]\n",
    "  \n",
    "    col_widths = [8]*len(header_list)\n",
    "    col_widths[0] = 25\n",
    "    columnSortStateTable1 = {}\n",
    "  \n",
    "\n",
    "    ## set up sort state for the column in both tables\n",
    "    for col in header_list:\n",
    "         columnSortStateTable1[col] = -1\n",
    "       \n",
    "            \n",
    "    valsFile1 = getValues(stats1,header_list)\n",
    "   \n",
    "    \n",
    "    rowFile1Colors = setRowColors(valsFile1,color1,color2,\"pink\",header_list)\n",
    "    \n",
    "    layCol1 = [[sg.Text(f\"File 1 {file1}\",font=\"CENTAUR 15\")],[sg.Text(f\"File 1 Shape {df1.shape}\",font=\"CENTAUR 15\")],\n",
    "               [sg.Button(\"Output Columns\"),sg.Button(\"Output Text Table\"),sg.Button(\"Output CSV File\")],\n",
    "               [sg.Table(values=valsFile1,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=20,col_widths=col_widths,font=\"CENTAUR 10\",\n",
    "                   justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                   key='-TABLEFILE-',row_colors=rowFile1Colors,headings = header_list,metadata=columnSortStateTable1)]\n",
    "               ]\n",
    "    \n",
    "\n",
    "    layout = [[sg.Button(\"Quit\")],\n",
    "    layCol1]  \n",
    "              \n",
    "    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(title,layout,finalize=True,resizable=True,metadata=[colorTheme,df1,title,valsFile1,header_list,file1])\n",
    "    if parentWindow not in windowsReset:\n",
    "        windowsReset[parentWindow] = {}\n",
    "    if window2 not in  windowsReset[parentWindow]:\n",
    "         windowsReset[parentWindow][window2] = {}\n",
    "    compWindo = window2\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableFile1 = window2['-TABLEFILE-']\n",
    "    tableFile1.bind('<Button-1>', \"Click\")\n",
    "    headerStore[tableFile1] = header_list\n",
    "    statsStore[tableFile1] = stats1\n",
    "#    print(\"STATS \",stats1)\n",
    "    return window2,tableFile1,valsFile1,rowFile1Colors\n",
    "\n",
    "#############################################\n",
    "\n",
    "def dfAnalyze(df):\n",
    "    stats = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        typs = df[col].apply(type).value_counts().to_dict()\n",
    "        stats[col] = {}\n",
    "        if str in typs:\n",
    "           stats[col][\"string\"] = typs[str]\n",
    "        else:\n",
    "           stats[col][\"string\"] = 0\n",
    "\n",
    "        if int in typs:\n",
    "           stats[col][\"integer\"] = typs[int]\n",
    "        else:\n",
    "           stats[col][\"integer\"] = 0\n",
    "\n",
    "        if float in typs:\n",
    "           stats[col][\"float\"] = typs[float]\n",
    "        else:\n",
    "           stats[col][\"float\"] = 0\n",
    "\n",
    "        if bool in typs:\n",
    "           stats[col][\"boolean\"] = typs[bool]\n",
    "        else:\n",
    "           stats[col][\"boolean\"] = 0\n",
    "\n",
    "        stats[col][\"Missing\"] = df[col].isna().sum()\n",
    "        stats[col][\"% Missing\"] = round(df[col].isna().sum()/df.shape[0]*100,1)\n",
    "        \n",
    "    return stats\n",
    "\n",
    "############################################# \n",
    "\n",
    "def exceptionLog(exception,funCall):\n",
    "  exception_message = str(exception)\n",
    "  exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "  filename = os.path.split(exception_traceback.tb_frame.f_code.co_filename)[1]\n",
    "  print(f\"{exception_message} {exception_type} {funCall}, Line {exception_traceback.tb_lineno}\")\n",
    "\n",
    "###############################################################\n",
    "\n",
    "def fullDataColumnMap(cim4x4):\n",
    "    '''Map the data fields found in the source data file to all the other sources  '''\n",
    "    global missed\n",
    "    if cim4x4 in fields:\n",
    "        invc = fields[cim4x4][\"source\"].copy()\n",
    "    else:\n",
    "        invc = []\n",
    "    tfc = transformColumns.copy()\n",
    "    exc = extractColumns.copy()\n",
    "    excMissed = []\n",
    "    tfcsij = transformSijColumns.copy()\n",
    "    loadsij = loadSijColumns.copy()\n",
    "    cim = cimColumns.copy()\n",
    "    xrfo2t = xrefsO2T.copy()\n",
    "    names = []\n",
    "    columnDict = {}\n",
    "    names.append(\"BIC Inventory\")\n",
    "    names.append(\"Transform Program\")\n",
    "\n",
    "    names.append(\"Transform - Data\")\n",
    "    names.append(\"CIM - Data\")\n",
    "    names.append(\"Transform - SIJ\")\n",
    "    names.append(\"Load - SIJ\")\n",
    "\n",
    "    for k in exc:\n",
    "       # print(\"MAP \",k)\n",
    "    #for k,v in xrefsO2T.items():\n",
    "        columnDict[k] = []\n",
    "        nhit=0\n",
    "        v=\"\"\n",
    "        if k in invc:\n",
    "            v=k\n",
    "            vv=k\n",
    "            invc.remove(k)\n",
    "            nhit+=1\n",
    "        else:\n",
    "            vv=\"\"\n",
    "        columnDict[k].append(vv)\n",
    "        \n",
    "        if k in xrfo2t:\n",
    "            v = xrfo2t[k]\n",
    "            vv=v\n",
    "            del xrfo2t[k]\n",
    "            nhit+=1\n",
    "        else:\n",
    "            vv = \"\"\n",
    "        columnDict[k].append(vv)  \n",
    "\n",
    "   \n",
    "        if v in tfc:\n",
    "           tfc.remove(v)\n",
    "           cc = v\n",
    "           nhit+=1\n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "\n",
    "\n",
    "        if v in cim:\n",
    "           cim.remove(v)\n",
    "           cc = v\n",
    "           nhit+=1            \n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "\n",
    "\n",
    "\n",
    "        if v.lower() in tfcsij:\n",
    "           tfcsij.remove(v.lower())\n",
    "           cc = v.lower()\n",
    "           nhit+=1            \n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "\n",
    "        if v.lower() in loadsij:\n",
    "           loadsij.remove(v.lower())\n",
    "           cc = v.lower()\n",
    "           nhit+=1\n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "        \n",
    "        if nhit == 0:\n",
    "            excMissed.append(k)\n",
    "        \n",
    "\n",
    "    a = pd.DataFrame(columnDict).T\n",
    "    a.columns = names\n",
    "    a.reset_index(inplace=True)\n",
    "    values = a.values.tolist()\n",
    "    cols = list(a.columns)\n",
    "   \n",
    "    missed = {}\n",
    "    missed[\"Extract - Data\"] = excMissed\n",
    "    missed[\"BIC Inventory\"] = invc\n",
    "    missed[\"Transform Program\"] = list(xrfo2t.keys())\n",
    "    missed[\"Transform - Data\"] = tfc\n",
    "    missed[\"CIM - Data\"] = cim\n",
    "    missed[\"Transform - SIJ\"] = tfcsij\n",
    "    missed[\"Load - SIJ\"] = loadsij\n",
    "    \n",
    "    \n",
    " #   missed = [invc,list(xrfo2t.keys()),tfc,cim,tfcsij,loadsij]\n",
    "    return cols,values,missed\n",
    "        \n",
    "\n",
    "###############################################################\n",
    "def getFilesClicked(file,window):\n",
    "#         if len(values[\"-FILE1-\"]) > 0:\n",
    "#             file = values[\"-FILE1-\"]\n",
    "#         elif len(values[\"-WEB1-\"]) > 0:\n",
    "#             file = values[\"-WEB1-\"]\n",
    "      \n",
    "        df = getFile(\"Local\",file,window)\n",
    "        stats = dfAnalyze(df)\n",
    "\n",
    "        return df,stats\n",
    "\n",
    "####################################################################\n",
    "       \n",
    "def getFile(how,file,WindowP):\n",
    "    print(\"Getting file \",file,how)\n",
    "    if how == \"Local\":\n",
    "        if file[-3:].lower() == \"tsv\":\n",
    "            delim = \"\\t\"\n",
    "            df=pd.read_csv(file,encoding=\"latin\",delimiter=delim)\n",
    "        elif file[-4:].lower() == \"xlsx\":\n",
    "            df=pd.read_excel(file,engine=\"openpyxl\")\n",
    "        else:\n",
    "            try:\n",
    "                df=pd.read_csv(file)\n",
    "            except Exception as err:\n",
    "                print(\"Error, trying with encoding=latin\")\n",
    "                df=pd.read_csv(file,encoding=\"latin\")\n",
    "    elif how == \"Fetch\":\n",
    "      \n",
    "  #      file=values[\"-WEB-\"]\n",
    "      #  getPrevFiles(2,file)\n",
    "\n",
    "  #      windowP[\"-PINFO-\"].update(f\"START reading WEB File:{file}:\")\n",
    "        df=pd.read_csv(file)\n",
    "      \n",
    "  #      windowP[\"-PINFO-\"].update(f\"FINISHED reading WEB File:{file}:\")\n",
    "   \n",
    "    stats = dfAnalyze(df)\n",
    "        \n",
    "    return df,stats\n",
    "\n",
    "############################################################\n",
    "\n",
    "def getRowClicked(table,columns):\n",
    "    col=\"\"\n",
    "    print(\"RC TABLE \",table)\n",
    "    e = table.user_bind_event \n",
    "    print(\"e \",e)\n",
    "    region = table.Widget.identify('region', e.x, e.y)\n",
    "    print(\"region \",region)\n",
    "    if region == 'heading':\n",
    "        row = 0\n",
    "    elif region == 'cell':\n",
    "        row = int(table.Widget.identify_row(e.y))  \n",
    "        col = columns[row-1][0]\n",
    "    print(\"R,C \",row,col)\n",
    "    return row,col    \n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def getRowClickedUN(table):\n",
    "    val=\"\"\n",
    "    data = dataStore[table]\n",
    "    e = table.user_bind_event \n",
    "    region = table.Widget.identify('region', e.x, e.y)\n",
    "    if region == 'heading':\n",
    "        row = 0\n",
    "    elif region == 'cell':\n",
    "        row = int(table.Widget.identify_row(e.y))  \n",
    "        val = data[row-1][0]\n",
    "      #  print(\"Un VAL CLICKED \",val)\n",
    "    return row,val    \n",
    "\n",
    "##########################################################\n",
    "\n",
    "def getSijColumns(file):\n",
    "    '''Get the fields for both teh contrile file content and the ftp control file content '''\n",
    "    global transformSijColumns,loadSijColumns\n",
    "    with open(\"/home/joe/bic_etl/cdos/business/nonprofit/scripts/datasync/char_paid_solicitors.sij\") as fin:\n",
    "        lines = fin.readlines()\n",
    "        line = lines[0]\n",
    "        ss = json.loads(line)\n",
    "        cfc = json.loads(ss[\"controlFileContent\"])\n",
    "        transformSijColumns = cfc[\"csv\"][\"columns\"]\n",
    "        ftp = json.loads(ss[\"ftpControlFileContent\"])\n",
    "        loadSijColumns = ftp['csv']['columns']\n",
    "\n",
    "#         for col in transformColumns:\n",
    "#             if col in loadColumns:\n",
    "#                 hit+=1\n",
    "#             else:\n",
    "#                 miss+=1\n",
    "\n",
    "#         for col in loadColumns:\n",
    "#             if col in transformColumns:\n",
    "#                 hit+=1\n",
    "#             else:\n",
    "#                 miss+=1\n",
    "\n",
    "# ##########################################################\n",
    "\n",
    "def getValues(stats,header):\n",
    "\n",
    "    statsVals=[]\n",
    "    for col in sorted(stats.keys()):\n",
    "         vals=[]\n",
    "         vals.append(col)\n",
    "         for k in header[1:]:\n",
    "            vals.append(stats[col][k.strip()])\n",
    "         statsVals.append(vals)\n",
    "    return statsVals     \n",
    "\n",
    "##############################################################\n",
    "\n",
    "# def getXrefs():\n",
    "#     '''Reads the Inventory google sheet and gets the datasets title and cross-refs it to the Socrata 4x4 id.  Also\n",
    "#     gets the fields by 4x4 dataset id and by the title'''\n",
    "#     scope = ['https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "#              \"https://www.googleapis.com/auth/drive.file\",\n",
    "#                   \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "#     creds = ServiceAccountCredentials.from_json_keyfile_name('../client_secret.json',\n",
    "#      scope)\n",
    "#     client = gspread.authorize(creds)\n",
    "\n",
    "#     gc = gspread.service_account(\"../client_secret.json\")\n",
    "#     # for gg in gc.list_spreadsheet_files():\n",
    "#     #      print(\"GGGGG \",gg)\n",
    "#     # https://docs.google.com/spreadsheets/d/1WTaOglzbSsYiHhAGguGxHQXmAGmOhfFHkGkMLowxAOA/edit?usp=sharing\n",
    "#     sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "#         'Maintenance_Framework')\n",
    "#     repo_sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "#         'MetadataRepository')\n",
    "#     fields_sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "#         'Field Descriptions')\n",
    "    \n",
    "    \n",
    "# #     sheet = client.open('https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/').worksheet(\n",
    "# #         'Maintenance_Framework')\n",
    "# #     repo_sheet = client.open('https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/').worksheet(\n",
    "# #         'MetadataRepository')\n",
    "    \n",
    "# #     fields_sheet = client.open('https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/').worksheet(\n",
    "# #         'Field Descriptions')\n",
    "\n",
    "#     dfRepo = pd.DataFrame(repo_sheet.get_all_records(head=3))\n",
    "#     xrefsBy4x4 = {}\n",
    "#     xrefsByTitle = {}\n",
    "\n",
    "#     for index,row in dfRepo[['Dataset Title','Socrata Link']].iterrows():\n",
    "#         xrefsByTitle[row['Dataset Title']] = row['Socrata Link']\n",
    "#         xrefsBy4x4[row['Socrata Link']] = row['Dataset Title']\n",
    "        \n",
    "#     dfFields = pd.DataFrame(fields_sheet.get_all_records(head=1))\n",
    "#     fields = {}\n",
    "#     for index,row in dfFields.iterrows():\n",
    "#         s4x4 = row[\"Socrata ID\"]\n",
    "#         of = row[\"Source Field Name\"]\n",
    "#         tf = row[\"Full Field Name\"]\n",
    "#         af = row[\"API Field Name\"]\n",
    "#         if s4x4 in fields:\n",
    "#             fields[s4x4][\"source\"].append(of)\n",
    "#             fields[s4x4][\"cim\"].append(tf)\n",
    "#             fields[s4x4][\"api\"].append(af)\n",
    "#         else:\n",
    "#             fields[s4x4] = {}\n",
    "#             fields[s4x4][\"source\"] = []\n",
    "#             fields[s4x4][\"cim\"] = []\n",
    "#             fields[s4x4][\"api\"] = []\n",
    "            \n",
    "#             fields[s4x4][\"source\"].append(of)\n",
    "#             fields[s4x4][\"cim\"].append(tf)\n",
    "#             fields[s4x4][\"api\"].append(af)\n",
    "        \n",
    "        \n",
    "        \n",
    "#     return xrefsBy4x4,xrefsByTitle,fields\n",
    "\n",
    "#############################################\n",
    "\n",
    "def go_deeper(aDict,value,nit):\n",
    "    nit+=1\n",
    "    for k, v in aDict.items():\n",
    "         if not bool(v):            \n",
    "             aDict[k] = []\n",
    "             aDict[k].append(value)\n",
    "         elif isinstance(v,list):\n",
    "             aDict[k].append(value)\n",
    "         else:\n",
    "             go_deeper(v,value,nit)\n",
    "   \n",
    "    return aDict\n",
    "\n",
    "###################################################    \n",
    "\n",
    "def init():\n",
    "    global dataSetsEtl,datasets,groupMenu\n",
    "    groups = []\n",
    "    desktop = pathlib.Path(\"/home/joe/bic_etl\")\n",
    "    runEtls = []\n",
    "    dataSets = []\n",
    "    info = {}\n",
    "    # .rglob() produces a generator too\n",
    "    desktop.rglob(\"*\")\n",
    "    files = list(desktop.rglob(\"*\"))\n",
    "# Which you can wrap in a list() constructor to materialize\n",
    "    for ff in files:\n",
    "\n",
    "            if (str(ff).split(\"/\")[-1] == \"run_etl.json\"):     \n",
    "                a=str(ff).split(\"/\")\n",
    "                m = a.index(\"bic_etl\")\n",
    "                b = a[m+1:-1]\n",
    "                ll = splitL(b)\n",
    "                groups.append(ll)\n",
    "                runEtls.append(ff)\n",
    "            \n",
    " #   print(f\"{len(runEtls)} run_etl.json files found\")    \n",
    "    \n",
    "    dataSets = []\n",
    "    groups = []\n",
    "    for file in runEtls:\n",
    "      f = open(file,\"r\")\n",
    "      data = json.load(f)\n",
    "      # print(file)\n",
    "      # print(\"----\")\n",
    "      a=str(file).split(\"/\")\n",
    "      m = a.index(\"bic_etl\")\n",
    "      b = a[m+1:-1]\n",
    "      group = b[0]\n",
    "      ll = splitL(b)\n",
    "      bdir = \"/\".join(b)  \n",
    "    \n",
    "      \n",
    "    #  groups.append(ll)\n",
    "      for val in data:\n",
    "            if \"title\" in val:\n",
    "                  title=val[\"title\"]\n",
    "                  if title in mapTitles:\n",
    "                     title = mapTitles[title]\n",
    "                  info[title]={}\n",
    "                  info[title][\"directory\"] = bdir\n",
    "                  info[title][\"group\"] = group\n",
    "                \n",
    "    #              print(title,ll)\n",
    "                  nit=0\n",
    "                  ll = go_deeper(ll,title,nit)\n",
    "             #     info[title][\"groups\"] = ll\n",
    "            \n",
    "     #             print(ll)\n",
    "     #             groups.append(ll)\n",
    "            dataSets.append(val)\n",
    "    #  print(\"FF \",ll) \n",
    "      groups.append(ll)\n",
    "\n",
    "    datasets = []\n",
    "    dataSetsEtl={}\n",
    "    for val in dataSets:\n",
    "        if \"title\" in val:\n",
    "          datasets.append(val[\"title\"])\n",
    "          title=val[\"title\"]\n",
    "          if title in mapTitles:\n",
    "            title = mapTitles[title]\n",
    "          dataSetsEtl[title] = {}  \n",
    "          dataSetsEtl[title][\"info\"] = {}\n",
    "          dataSetsEtl[title][\"info\"][\"directory\"] = info[title][\"directory\"]\n",
    "          dataSetsEtl[title][\"info\"][\"group\"] = info[title][\"group\"]\n",
    "     #     dataSetsEtl[title][\"info\"][\"groups\"] = info[title][\"groups\"]\n",
    "            \n",
    "        \n",
    "            \n",
    "          for k,v in val.items():\n",
    "          #      print(k,v)\n",
    "                if k != \"title\":\n",
    "                    dataSetsEtl[title][k] = {}\n",
    "                    if isinstance(v,dict):\n",
    "                        for k1,v1 in v.items():\n",
    "                            dataSetsEtl[title][k][k1]=v1\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "    groupMenu = ['Groups',\n",
    "     ['boulder',\n",
    "      ['Restaurant Inspections in Boulder Colorado'],\n",
    "      'catalog',\n",
    "      ['CIM Catalog Download'],\n",
    "      'cdhe',\n",
    "      ['Enrollment Demographics for Post-Secondary Graduates in Colorado',\n",
    "       'Post-Secondary Financial Aid Demographics in Colorado'],\n",
    "      'cdor',[\n",
    "      'revenue_marijuana',\n",
    "      ['Marijuana Sales by County in Colorado',\n",
    "       'State Retail Marijuana Sales Tax Revenue by County in Colorado',\n",
    "       'Marijuana Tax and Fee Revenue in Colorado',\n",
    "       'Marijuana Sales Revenue in Colorado'],\n",
    "      'retail_reports',\n",
    "      ['Retail Sales Tax Return History in Colorado',\n",
    "       'Retail Reports by City in Colorado',\n",
    "       'Retail Reports by County in Colorado',\n",
    "       'Retail Reports by Industry and City in Colorado',\n",
    "       'Retail Reports by Industry and County in Colorado',\n",
    "       'Retail Reports by Industry in Colorado'],\n",
    "      'regulations_liquor',\n",
    "      ['Liquor Permits for Special Events in Colorado',\n",
    "       'Liquor Compliance Check Statistics in Colorado',\n",
    "       'Liquor Licenses in Colorado',\n",
    "       'Recently Approved Liquor Licenses in Colorado',\n",
    "       'Recently Expired and Surrendered Liquor Licenses in Colorado',\n",
    "       'Sales Rooms in Colorado',\n",
    "       'Manufacturer Temporary Sales Room Permits in Colorado']\n",
    "      ],\n",
    "      'cdos',[\n",
    "      'health',\n",
    "      ['Durable Medical Equipment Suppliers in Colorado'],\n",
    "      'government',\n",
    "      ['Current Notaries in Colorado'],\n",
    "      'business',[\n",
    "      'ucc',\n",
    "      ['Uniform Commercial Code (UCC) Collateral Information in Colorado',\n",
    "       'Uniform Commercial Code (UCC) Debtor Information in Colorado',\n",
    "       'Uniform Commercial Code (UCC) Filing Information in Colorado',\n",
    "       'Secured Party Information in Colorado'],\n",
    "      'business',\n",
    "      ['Business Entities in Colorado',\n",
    "       'Business Entity Transaction History',\n",
    "       'Trademarks for Businesses in Colorado',\n",
    "       'Trade Names for Businesses in Colorado',\n",
    "       'Master List in Colorado'],\n",
    "      'nonprofit',\n",
    "      ['Federal Tax-Exempt Subsection Codes in Colorado',\n",
    "       'Registration for Charities, Paid Solicitors, Professional Fundraising Consultants, and for-profit Public Benefit Corporations in Colorado',\n",
    "       'Charitable Organizations’ Offices in Colorado',\n",
    "       'Other State Solicitation of Charities’ Registrants in Colorado',\n",
    "       'Charitable Purpose of the Charity in Colorado',\n",
    "       'Paid Solicitor Solicitation Notices in Colorado',\n",
    "       'Campaign Reports for Solicitation Notices to Charities in Colorado',\n",
    "       'Solicitation Campaign Supervisors Listed on Solicitation Notices in Colorado',\n",
    "       'Charity Extension Requests',\n",
    "       'Persons Associated with Charitable Organizations, Paid Solicitors, and Professional Fundraising Consultants in Colorado',\n",
    "       'Other Names a Registered Entity Uses to Solicit Contributions',\n",
    "       'Paid Solicitors Disclosed on Charity Registration Forms in Colorado',\n",
    "       'Charitable Solicitation Call Center Locations in Colorado',\n",
    "       'Charities Solicitation Type by Solicitation in Colorado',\n",
    "       'Communication Methods Used in Solicitation Campaigns in Colorado']\n",
    "      ],\n",
    "      'lobbyist',\n",
    "      ['Directory of Lobbyists in Colorado',\n",
    "       'Directory of Lobbyist Clients in Colorado',\n",
    "       'Expenses for Lobbyists in Colorado',\n",
    "       'Characterization of Lobbyist Clients in Colorado',\n",
    "       'Subcontractors for Lobbyists in Colorado',\n",
    "       'Bill Information and Position with Income of Lobbyist in Colorado']\n",
    "      ],\n",
    "      'cdot',[\n",
    "      'transportation_road_attributes',\n",
    "      ['Highway Milepoints in Colorado',\n",
    "       'Highway Mileposts in Colorado',\n",
    "       'Highway Routes in Colorado',\n",
    "       'Highway Routes in Colorado',\n",
    "       'Local Roads in Colorado',\n",
    "       'Major Roads in Colorado',\n",
    "       'Scenic Byways in Colorado'],\n",
    "      'tops',\n",
    "      ['CDOT Expenses', 'CDOT Revenues', 'CDOT Payroll'],\n",
    "      'natural_resources',\n",
    "      ['Lakes in Colorado', 'Streams in Colorado'],\n",
    "      'transportation_infrastructure',\n",
    "      ['Airports in Colorado',\n",
    "       'Cities in Colorado',\n",
    "       'Counties in Colorado',\n",
    "       'Railroads in Colorado']\n",
    "      ],\n",
    "      'ceo',[\n",
    "      'useia',\n",
    "      ['Gasoline Prices in Colorado', 'Natural Gas Prices in Colorado']\n",
    "      ],\n",
    "      'denver',\n",
    "      ['Temporary Outdoor Expansions for Restaurants in Denver, Colorado'],\n",
    "      'dola',[\n",
    "      'special_districts',\n",
    "      ['Metro Districts in Colorado',\n",
    "       'Parks and Rec Districts in Colorado',\n",
    "       'Fire Districts in Colorado',\n",
    "       'Hospital Districts in Colorado',\n",
    "       'Water and Sanitation Districts in Colorado',\n",
    "       'Library Districts in Colorado',\n",
    "       'School Districts in Colorado',\n",
    "       'Soil Districts in Colorado',\n",
    "       'Cemetery Districts in Colorado',\n",
    "       'All Special Districts in Colorado'],\n",
    "      'boundaries',\n",
    "      ['Municipal Annexations in Colorado', 'Municipal Boundaries in Colorado'],\n",
    "      'demographics',\n",
    "      ['Population Projections in Colorado',\n",
    "       'Race Estimates in Colorado',\n",
    "       'Race Forecast in Colorado']\n",
    "      ],\n",
    "      'dora',[\n",
    "      'regulations',\n",
    "      ['Licensed Real Estate Professionals in Colorado',\n",
    "       'Professional and Occupational Licenses in Colorado']\n",
    "      ],\n",
    "      'dpa',\n",
    "      ['DPA Tops Data'],\n",
    "      'irs',\n",
    "      ['Purpose and Operational Size of Charities Operating in Colorado',\n",
    "       'Fundraising Revenue of Charities Operating in Colorado',\n",
    "       'Total Revenue of Charities Operating in Colorado',\n",
    "       'IRS Filing Information for Charities Operating in Colorado',\n",
    "       'Total Revenue and Types of Art for Charities Operating in Colorado',\n",
    "       'Conservation Easements for Charities Operating in Colorado',\n",
    "       'Activities of Charities Operating in Colorado',\n",
    "       'Expenses of Charities Operating in Colorado',\n",
    "       'Expenses of Charities Operating in Colorado'],\n",
    "      'tchd',\n",
    "      ['Restaurant Inspections in Tri-County Colorado']]]\n",
    "\n",
    "    return sorted(datasets)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def map4x4(row):\n",
    "    \n",
    "    if isinstance(row[\"Data Link\"],str) and  len(row[\"Data Link\"]) == 9 and re.findall( \"\\w{4}-\\w{4}\",row[\"Data Link\"]):\n",
    "  #      link = '<a href=\"https://data.colorado.gov/dataset/{}\">{}</a>'.format(row[\"Data Link\"],row[\"Data Link\"])\n",
    "        \n",
    "        link = 'https://data.colorado.gov/dataset/{}'.format(row[\"Data Link\"])\n",
    "    else:\n",
    "        link = \"\"\n",
    "        \n",
    "    return link\n",
    "    \n",
    "#####################################################################\n",
    "\n",
    "def runETL(k):\n",
    "    global extract,a,string,dataSetsEtl\n",
    "    text2 = \"\"\n",
    " \n",
    "    directory = \"\"\n",
    "    group = \"\"\n",
    " #   print(\"dse \",sorted(list(dataSetsEtl.keys())))\n",
    "    # for key in dataSetsEtl.keys():\n",
    "    #     print(f\"{len(key)}:{key}:\")\n",
    "        \n",
    "    if \"info\" in dataSetsEtl[k]:\n",
    "        if \"directory\" in dataSetsEtl[k][\"info\"]:\n",
    "            directory = dataSetsEtl[k][\"info\"][\"directory\"]\n",
    "            group = dataSetsEtl[k][\"info\"][\"group\"]\n",
    "            print(\"D G\",directory,group)\n",
    "            \n",
    "   \n",
    "## Build Summary Text string\n",
    "    for ky1 in dataSetsEtl[k].keys():\n",
    "        text2+=f\"{ky1}:\\n\" \n",
    "        for k2,v2 in dataSetsEtl[k][ky1].items(): \n",
    "            sl = 10 - len(k2)\n",
    "            s = \" \"*sl\n",
    "        \n",
    "            if isinstance(v2,list) == False:\n",
    "                text2+=f\"    {k2:10s}{s} :  {v2}\\n\"\n",
    "            else:\n",
    "                text2+=f\"    {k2:10s}{s} : {v2[0]}\\n\"\n",
    "                if len(v2) > 1:\n",
    "                    for val in v2[1:]:\n",
    "                        text2+= f\"                   {s} : {val}\\n\"\n",
    "        text2+=f\"\\n\\n\"\n",
    "## Build actions\n",
    "    extract = \"\"\n",
    "    datasetCharId=\"\"\n",
    "    if logging > 1:\n",
    "        print(dataSetsEtl[ds])\n",
    "    if 'extract' in dataSetsEtl[ds]:\n",
    "      #  if isinstance(dataSetsEtl[ds][\"extract\"],\"dict\"):\n",
    "            print(\"Extract Level 1\",dataSetsEtl[ds]['extract']['language'])\n",
    "            if ('language' in dataSetsEtl[ds]['extract'] and dataSetsEtl[ds]['extract']['language'] == 'node'):\n",
    "                pgm =  dataSetsEtl[ds]['extract']['file']\n",
    "                options=\"\"\n",
    "                print(\"Extract Level 2\")\n",
    "\n",
    "                if 'options' in dataSetsEtl[ds]['extract']:\n",
    "                    for opts in dataSetsEtl[ds]['extract']['options']:\n",
    "                        options+= f\" {opts}\" \n",
    "                        if opts[0:2] == \"-f\":\n",
    "                            spl = opts.split(\"/\")\n",
    "                            spl = spl[1].split(\".\")\n",
    "                            datasetCharId = spl[0]\n",
    "                            print(\"DATASETCHARID 2\",datasetCharId)\n",
    "                extract = f\"node {bicHome}{pgm} {options}\"\n",
    "                if logging > 0:\n",
    "                    print(\"Extract \",extract)\n",
    "    transform=\"\"\n",
    "    filetr = \"\"\n",
    "    print(\"Get Transform\")\n",
    "    \n",
    "    if 'transform' in dataSetsEtl[ds]:\n",
    "        \n",
    "        if dataSetsEtl[ds][\"transform\"][\"language\"] == \"node\":\n",
    "             ff=dataSetsEtl[ds][\"transform\"][\"file\"]\n",
    "             transform=f\"node {bicHome}{directory}/{ff}\"\n",
    "        elif dataSetsEtl[ds][\"transform\"][\"language\"] == \"py\":\n",
    "             ff=dataSetsEtl[ds][\"transform\"][\"file\"]\n",
    "             transform=f\"PIPENV_PIPFILE=/home/joe/bic_etl/cdor/regulations_liquor/scripts/Pipfile pipenv run python {bicHome}{directory}/{ff}\"\n",
    "     #   filetr=ff    \n",
    "        options=\"\"\n",
    "        if 'options' in dataSetsEtl[ds]['transform']:\n",
    "            for opts in dataSetsEtl[ds]['transform']['options']:\n",
    "                options+= f\" {opts}\" \n",
    "                if isinstance(opts,str):\n",
    "                    spl = opts.split(\" \")\n",
    "                    if \"-i\" in spl[0]:\n",
    "                        filetr=spl[1]\n",
    "                        if filetr[-4:] == \"xlsx\":\n",
    "                            filetr=filetr.replace(\".xlsx\",\".csv\")\n",
    "                        elif filetr[-3:] == \"xls\":\n",
    "                            filetr=filetr.replace(\".xls\",\".csv\")\n",
    "                        print(\"FFOUT \",filetr)\n",
    "             #   print(\"TR OPTIONS\",opts)\n",
    "            transform+= f\" {options}\"\n",
    "            \n",
    "        else:\n",
    "            filetr=\"\"  \n",
    "        if logging > 0:\n",
    "            print(\"Transform: \",transform)\n",
    "        \n",
    "    text2+=f\"\\n\\nActions Strings\\nExtract\\n{extract}\\n\\nTransform\\n{transform}\"\n",
    "        \n",
    "    return text2,extract,transform,filetr,directory,datasetCharId\n",
    "    \n",
    "#############################################\n",
    "\n",
    "def setRowColors(lst,col1,col2,colsp,header):\n",
    "    count=0\n",
    "    colors = {}\n",
    "    # print(\"SRC head \",header)\n",
    "    # print(\"SRC list\",lst)\n",
    "\n",
    "    nrec = header.index(\"% Missing\")\n",
    "    for vals in lst:\n",
    "        key = vals[0]\n",
    "        if count%2 == 0:\n",
    "            colors[key] = col1\n",
    "        else:\n",
    "            colors[key] = col2\n",
    "        if vals[nrec] > 99.0:\n",
    "           \n",
    "            colors[key] = colsp\n",
    "        count+=1\n",
    "    colTab = []\n",
    "    for key,colr in colors.items():\n",
    "        colTab.append(colr)\n",
    "    rowNums = [num for num in range(0,len(colTab)+1)]\n",
    "    colText = [\"black\"]*len(colTab)\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "  \n",
    "    return colrw\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def setRowColorsGeneric(lst,col1,col2):\n",
    "    count=0\n",
    "    rowNums=[]\n",
    "    colTab=[]\n",
    "\n",
    "    for vals in lst:       \n",
    "        if count%2 == 0:\n",
    "            colTab.append(col1)\n",
    "        else:\n",
    "            colTab.append(col2)\n",
    "        rowNums.append(count)\n",
    "        count+=1\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "  \n",
    "    return colrw\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def showDfRecs(df1,colUn,val,windowP,title=\"DF Unique Record Values\"):\n",
    "    global color1,color2,showDFRecswindow\n",
    "    header_list = list(df1.columns)\n",
    "  \n",
    "    col_widths = [8]*len(header_list)\n",
    " #   col_widths[0] = 25\n",
    "    columnSortStateTable1 = {}\n",
    "  \n",
    "\n",
    "    ## set up sort state for the column in both tables\n",
    "    for col in header_list:\n",
    "        columnSortStateTable1[col] = -1\n",
    "       \n",
    "            \n",
    "#    valsFile1 = getValues(stats1,header_list)\n",
    "    values = df1.values.tolist()\n",
    "    \n",
    "    rowFile1Colors = setRowColorsGeneric(values,color1,color2)\n",
    "    \n",
    "    layout = [[sg.Text(f\"Column: \",font=\"CENTAUR 10\"),\n",
    "               sg.Text(f\"{colUn}\",font=\"CENTAUR 15\")],\n",
    "              [sg.Text(f\"Unique Value: \",font=\"CENTAUR 10\"),\n",
    "               sg.Text(f\"{val}\",font=\"CENTAUR 15\")],\n",
    "               [sg.Button(\"Quit\")],\n",
    "               [sg.Table(values=values,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=20,col_widths=col_widths,font=\"CENTAUR 10\",\n",
    "                   justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                   key='-TABLEFILE-',row_colors=rowFile1Colors,headings = header_list,metadata=columnSortStateTable1)]\n",
    "               ]\n",
    "\n",
    "    colorTheme = windowP.metadata[0]          \n",
    "#    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(title,layout,finalize=True,resizable=True,metadata=[colorTheme,df1])\n",
    "    showDFRecswindow=window2\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableFile1 = window2['-TABLEFILE-']\n",
    "    tableFile1.bind('<Button-1>', \"Click\")\n",
    "    headerStore[tableFile1] = header_list\n",
    "    return window2,tableFile1,values,rowFile1Colors\n",
    "\n",
    "###################################################\n",
    "\n",
    "def splitL(data):\n",
    "    if data:\n",
    "        head, *tail = data  # This is a nicer way of doing head, tail = data[0], data[1:]\n",
    "        return {head: splitL(tail)}\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#############################################\n",
    "\n",
    "def stringArgs(string):\n",
    "#  This is set to decode the extract string to get the location and name of the \n",
    "#  extracted data file\n",
    " #   print(\"stringArg\",string)\n",
    "    h =split(string)\n",
    " #   print(\"HHH \",h)\n",
    "    inf = h.index(\"-f\")\n",
    "    inf = h[inf+1]\n",
    "    if \"-a\" in h:\n",
    "        ot = h.index(\"-a\")\n",
    "        inf=inf.replace(inf[-4:],h[ot+1])\n",
    "        of = inf.split(\"/\")  \n",
    "        of=of[-1]\n",
    "    elif \"-n\" in h:\n",
    "        of = h.index(\"-n\")\n",
    "        of=h[of+1]\n",
    "        \n",
    "\n",
    "        \n",
    "#    ot = h[ot+1]\n",
    "    od = h.index(\"-o\")\n",
    "    od = h[od+1]\n",
    "\n",
    "    finalFile = f\"{bicHome}{od}{of}\"\n",
    "    print(\"finalFile \",finalFile)\n",
    "    return finalFile\n",
    "\n",
    "######################################################    \n",
    "\n",
    "def sortTable(row,stats,table,event,header):\n",
    "    \n",
    "        e = table.user_bind_event \n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        if region == 'heading':\n",
    "            row = 0\n",
    "        elif region == 'cell':\n",
    "            row = int(table.Widget.identify_row(e.y))\n",
    "   \n",
    "        if row == 0:\n",
    "            colSortState = table.metadata\n",
    "            colClicked = int(table.Widget.identify_column(e.x)[1:])\n",
    "            header = headerStore[table]\n",
    "            \n",
    "            statClicked = header[colClicked-1].strip()\n",
    "           \n",
    "            colSortState[statClicked]*=-1\n",
    "            if colSortState[statClicked] == -1:\n",
    "                sortAsc=False\n",
    "            else:\n",
    "                sortAsc=True\n",
    "            if colClicked > 1:  # user number sort\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[1][statClicked],reverse=sortAsc))\n",
    "            else:\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[0],reverse=sortAsc))\n",
    "\n",
    "\n",
    "            statsVals=[]\n",
    "            for col in statsS:\n",
    "                 vals=[]\n",
    "                 vals.append(col)\n",
    "                 for k in header[1:]:\n",
    "                    vals.append(statsS[col][k.strip()])\n",
    "                 statsVals.append(vals)\n",
    "           # slen= len(statsVals)\n",
    "#             colorsTable = setRowColors(statsVals,\"#b3f0ff\",\"#33d6ff\",\"pink\",header_list)\n",
    "\n",
    "#             window['-TABLE-'].update(values=statsVals,row_colors=colorsTable)\n",
    "        \n",
    "        return statsVals,colSortState\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def showDFUN(col,unq,windowParent,colr1,colr2,colorTheme,title=\"\"):\n",
    "    global dataStore,showDFUNwindow\n",
    "    valuesUNQ = list(zip(unq.index.tolist(),unq.tolist()))\n",
    "    hUNQ = []\n",
    "    hUNQ.append(\"Values\")\n",
    "    hUNQ.append(\"Count\")\n",
    "\n",
    "    \n",
    "    sortState = {}\n",
    "    for val in hUNQ:\n",
    "        sortState[val]=-1\n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Showing unique Values for Column\"),sg.Text(f\" {col}\",text_color=\"white\",font='Courier 15 bold '),sg.Text(f\" and Reg Ex\",text_color=\"white\",font='Courier 10 bold ')],\n",
    "                \n",
    "                   [sg.Button('Quit')],\n",
    "            \n",
    "                   [sg.Button('Write Unique'),\n",
    "                    sg.Table(values=valuesUNQ,\n",
    "                       background_color=colr1,vertical_scroll_only=False,col_widths=60,font='Courier 10 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',alternating_row_color=colr2,\n",
    "                       key='-TABLE-', headings = hUNQ,metadata=sortState)]\n",
    "            ]\n",
    "    sg.theme(colorTheme)    \n",
    "    window2 = sg.Window(f\"Unique for {title}\", layout2,finalize=True,resizable=True, grab_anywhere=False,metadata=[windowParent,col])\n",
    "    showDFUNwindow = window2\n",
    "    table = window2['-TABLE-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    dataStore[table]=valuesUNQ\n",
    "    \n",
    "    return window2,table,valuesUNQ,hUNQ\n",
    "\n",
    "############################################################\n",
    "\n",
    "def showColAnal(xrefsO2T,xrefsT2O,colr1,colr2):\n",
    "    global dataStore\n",
    "    values=[]\n",
    "    header = [\"Original Column\",\"Transformed Column\"]\n",
    "    for col in sorted(xrefsO2T.keys()):\n",
    "        tmp = [col,xrefsO2T[col]]\n",
    "        values.append(tmp)\n",
    "    \n",
    "    rowColors = setRowColorsGeneric(values,colr1,colr2)\n",
    "    \n",
    "    sortState = {}\n",
    "    for val in header:\n",
    "        sortState[val]=-1\n",
    "        \n",
    "    \n",
    "    a = [[sg.Text(\"Columns in Program NOT in Data\",font='Courier 10 bold ',justification=\"left\")],\n",
    "         [sg.Listbox(\"\",font='Courier 15 bold ',horizontal_scroll=True ,size=(20,5),key=\"-PNOTD-\")]] \n",
    "    \n",
    "    d = sg.Column(a)\n",
    "    \n",
    "    b = [[sg.Text(\"Columns in Data NOT in Program\",font='Courier 10 bold ',justification=\"left\")],\n",
    "         [sg.Listbox(\"\",font='Courier 15 bold ' ,enable_events=True,horizontal_scroll=True ,size=(20,5),key=\"-DNOTP-\")]] \n",
    "    e = sg.Column(b)\n",
    "    \n",
    "    c = [d,sg.VerticalSeparator(color=\"black\"),e]\n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Original COlumns Transformed to Columns\")],\n",
    "                   [sg.Button(\"Compare 2 Data\"),sg.Button(\"Get SIJ Cols\"),sg.Button(\"Full Data Column Map\")],\n",
    "                   [sg.Button('Quit')],\n",
    "                   [c],\n",
    "                   [ sg.Table(values=values,\n",
    "                       vertical_scroll_only=False,col_widths=60,font='Courier 10 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',row_colors=rowColors,\n",
    "                       key='-TABLECOLUMN-', headings = header,num_rows=20,\n",
    "                       metadata=[values,rowColors,sortState])]\n",
    "                ]\n",
    "#    sg.theme(colorTheme)    \n",
    "    window2 = sg.Window(f\"Orig vs Trans Column Analysis\", layout2,finalize=True,resizable=True, grab_anywhere=False,metadata=\"nothing\")\n",
    "\n",
    "    table = window2['-TABLECOLUMN-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    dataStore[table]=values\n",
    "    headerStore[table]=header\n",
    "    windowsStore[\"columnAnalysis\"] = window2   \n",
    "    return window2,table,values,header\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def showFullDataColMap(cols,vals):\n",
    "    \n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Full Data Columns Map\")],\n",
    "                   [sg.Button('Quit')],\n",
    "                   [sg.Button('Show Missing Fields')],\n",
    "                   [ sg.Table(values=vals,\n",
    "                       vertical_scroll_only=False,col_widths=60,font='Courier 15 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',row_colors=rowColors,\n",
    "                       key='-TABLEDCMAP-', headings = cols,num_rows=20,\n",
    "                       metadata=[vals])]\n",
    "                ]\n",
    "        \n",
    "    window2 = sg.Window(f\"Orig vs Trans Column Analysis\", layout2,finalize=True,resizable=True, grab_anywhere=False,metadata=\"nothing\")\n",
    "\n",
    "    table = window2['-TABLEDCMAP-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    dataStore[table]=values\n",
    "    headerStore[table]=cols\n",
    "    windowsStore[\"fullDataColMap\"] = window2  \n",
    "\n",
    "###########################################################\n",
    "\n",
    "def showMissingColumns():\n",
    "    global missed\n",
    "\n",
    "    header_list = [\"Column\",\"% Missing\",\"Missing\",\"string\",\"integer\",\"float\",\"boolean\"]\n",
    "    stats1Ex = {}\n",
    "    \n",
    "    stats1Tr = {}\n",
    "    stats1Ci = {}\n",
    "    \n",
    "    for col in missed['Extract - Data']:\n",
    "     #   print(col,stats1Extract[col])\n",
    "        stats1Ex[col]= stats1Extract[col]\n",
    "\n",
    "    \n",
    "    for col in missed['Transform - Data']:\n",
    "      #  print(col,stats1Transform[col])\n",
    "        stats1Tr[col]= stats1Transform[col]\n",
    "\n",
    "    for col in missed['CIM - Data']:\n",
    "      #  print(col,stats1Cim[col])\n",
    "        stats1Ci[col]= stats1Cim[col]\n",
    "  \n",
    "    valsExtract = getValues(stats1Ex,header_list)\n",
    "    valsTransform = getValues(stats1Tr,header_list)\n",
    "    valsCim = getValues(stats1Ci,header_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    layout = [\n",
    "               [sg.Button(\"Quit\")],\n",
    "               [sg.Listbox(values=missed[\"BIC Inventory\"],size=(10,5),font=\"CENTAUR 10\"),\n",
    "                sg.Listbox(values=missed[\"Transform Program\"],size=(10,5),font=\"CENTAUR 10\"),\n",
    "                sg.Listbox(values=missed[\"Transform - SIJ\"],size=(10,5),font=\"CENTAUR 10\")],\n",
    "                [sg.Table(values=valsExtract,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=10,font=\"CENTAUR 10\",\n",
    "                    justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                    key='-TABLEMISSEXTR-',headings = header_list)],\n",
    "                [sg.Table(values=valsTransform,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=10,font=\"CENTAUR 10\",\n",
    "                    justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                    key='-TABLEMISSTRANS-',headings = header_list)],\n",
    "                [sg.Table(values=valsCim,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=10,font=\"CENTAUR 10\",\n",
    "                    justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                    key='-TABLEMISSCIM-',headings = header_list)]\n",
    "               ]\n",
    "\n",
    "#    colorTheme = windowP.metadata[0]  \n",
    "    theme = \"LightBrown 3\"\n",
    "    sg.theme(\"LightBrown 3\")     \n",
    "    window2 = sg.Window(\"Missing Fields\",layout,finalize=True,resizable=True,metadata=[theme])\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableex = window2['-TABLEMISSEXTR-']\n",
    "    tableex.bind('<Button-1>', \"Click\")\n",
    "    tabletr = window2['-TABLEMISSTRANS-']\n",
    "    tabletr.bind('<Button-1>', \"Click\")\n",
    "    tableci = window2['-TABLEMISSCIM-']\n",
    "    tableci.bind('<Button-1>', \"Click\")\n",
    "    \n",
    "    dataStore[tableex] = valsExtract\n",
    "    dataStore[tabletr] = valsTransform\n",
    "    dataStore[tableci] = valsCim\n",
    "    \n",
    "    \n",
    "    return window2,tableex,tabletr,tableci\n",
    "    # headerStore[tableFile1] = header_list\n",
    "    \n",
    " \n",
    "###########################################################\n",
    "\n",
    "def sortUniqe(table,window,dataStore,headerStore):\n",
    "    global color1,color2\n",
    "    try:\n",
    "        e = table.user_bind_event\n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        sortAsc = {}\n",
    "        sortAsc[1] =False\n",
    "        sortAsc[-1]=True\n",
    "   #     print(\"R \",region)\n",
    "        if region == 'heading':\n",
    "            values = dataStore[table]\n",
    "            \n",
    "           \n",
    "            header = headerStore[table]\n",
    "            # print(\"SU header \",header)\n",
    "            column = int(table.Widget.identify_column(e.x)[1:])\n",
    "            col=header[column-1]\n",
    "            \n",
    "            sortState = table.metadata\n",
    "           \n",
    "            sortState[col]*=-1\n",
    "            table.metadata = sortState\n",
    "          \n",
    "            values = sorted(values, key=lambda element: (element[column-1]),reverse=sortAsc[sortState[col]]) \n",
    "#            rowFile1Colors = setRowColors(values,color1,color2,\"pink\",header)\n",
    "            rowFile1Colors = setRowColorsGeneric(values,color1,color2)\n",
    "\n",
    "            window[\"-TABLE-\"].update(values=values)\n",
    "            dataStore[table] = values\n",
    "    except Exception as err:\n",
    "        exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "                    \n",
    "#####################################################        \n",
    "\n",
    "def tranfColXref(file):\n",
    "    global transformProgram\n",
    " #   fin = open(\"/home/joe/bic_etl/cdos/business/nonprofit/scripts/reg_finan.js\",\"r\")\n",
    "    fin = open(file,\"r\")\n",
    "    \n",
    "    lines = fin.readlines() \n",
    "    transformProgram = lines\n",
    "    fout = open(\"output.txt\",\"w\")\n",
    "    org = []\n",
    "    xrefsO2T = {}\n",
    "    xrefsT2O = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if re.findall(\"row\",line.lower()) and re.findall(\"=\",line.lower()) and not re.findall(\"^//\",line.lstrip()):\n",
    "            st1=line.find(\"[\")\n",
    "            ed1=line.find(\"]\")\n",
    "            st2=line.rfind(\"[\")\n",
    "            ed2=line.rfind(\"]\")\n",
    "            org.append(line[st2+2:ed2-1])\n",
    "    #        print(line)\n",
    "    #        print(line[st1+1:ed1],line[st2+1:ed2])\n",
    "            fout.write(f\"{line[st1+1:ed1]}  {line[st2+1:ed2]}\\n\")\n",
    "            og = line[st2+1:ed2].replace(\"'\",\"\")\n",
    "            og = og.replace('\"','')\n",
    "            \n",
    "            og = og.replace(\"].toLowerCase()\",\"\")\n",
    "\n",
    "\n",
    "            tr = line[st1+1:ed1].replace(\".toLowerCase()\",\"\")\n",
    "            tr = tr.replace('\"','')\n",
    "            tr = tr.replace(\"'\",\"\")\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            # tr = line[st1+1:ed1]\n",
    "            # og = line[st2+1:ed2]\n",
    "\n",
    "            xrefsT2O[tr]  = og\n",
    "            xrefsO2T[og]  = tr\n",
    "    return xrefsO2T,xrefsT2O\n",
    "                \n",
    "############################################################\n",
    "\n",
    "def wrap(string, lenght=60):\n",
    "    if isinstance(string,str):\n",
    "       return '\\n'.join(textwrap.wrap(string, lenght))\n",
    "    else:\n",
    "        return \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea661f2d-d94b-44a2-8ab6-4689e074aa56",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5247b38-4a96-46a3-8945-a8fd5b731a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cronGUI():\n",
    "    global ds,text2,a,string,numWindows,color1,color2,file,transform,dataStore,statsStore\n",
    "    global windowsStore,xrefsBy4x4,groupMenu,windowsReset\n",
    "    global transformProgram,dnotpLines,rowToWrite\n",
    "    global extractColumns,transformColumns,cimColumns\n",
    "    global transformSijColumns,loadSijColumns,xrefsO2T,xrefsT2O\n",
    "    global dfExtract,dfTransform,dfCim,missed,fields\n",
    "    global stats1Extract,stats1Transform,stats1Cim\n",
    "    global vals,cols,wid,dfoutput,mfShort,dataSetsEtl,cim4x4\n",
    "    global dfExtract,dfTransform,directory\n",
    "    global sourceDefFile,nfieldsadded\n",
    "    \n",
    "    dataStore = {}\n",
    "    statsStore = {}\n",
    "    windowsStore = {}\n",
    "    windowsReset = {}\n",
    "    \n",
    "    datasets = init()\n",
    "    cimColumns = []\n",
    "    transformColumns = []\n",
    "    extractColumns = []\n",
    "    transformSijColumns = []\n",
    "    loadSijColumns = []\n",
    "    \n",
    "    errorsByDate,errorsByName=getRecentErrorsNew()\n",
    "    \n",
    "##  get xrefs b/w 4x4 ids and datasert titles...yay   \n",
    "    xrefsBy4x4,xrefsByTitle,fields = getXrefs()\n",
    "\n",
    "    mf = pd.read_excel(\"BICDataInventoryandMetadata.xlsx\",skiprows=0,sheet_name=\"Inventory_Active\",engine=\"openpyxl\")\n",
    "    \n",
    "    mf[\"CIM Link\"] = mf.apply(map4x4,axis=1)\n",
    "\n",
    "    mf=mf.loc[~mf[\"Standardized Title for Dataset\"].isna()]\n",
    "    mfShort = mf[['Standardized Title for Dataset', 'Data Link','CIM Data Type','GoCodePublishYear','Standardized Short Description','CIM Link']]\n",
    "    mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str).str.strip()  \n",
    "    \n",
    "    header_list = list(mfShort.columns)\n",
    "    # mfV = []\n",
    "    # a = [\"\",\"\",nan,nan,\"\"]\n",
    "    # mfV.append(a)\n",
    "    layout = [\n",
    "              [sg.Text(\"BIC Cron DataSets\")],\n",
    "              [sg.Combo(datasets,enable_events=True,key=\"-DATASET-\",font='Courier 10 bold ')],\n",
    "              [sg.ButtonMenu('Groups', menu_def=groupMenu, key='Group Menu',font='Courier 15 bold')],\n",
    "              [sg.Text(\"4x4\",font='Courier 15 bold '),sg.Input(\"\",size=[8,1],key=\"-4x4-\",font='Courier 10 bold '),\n",
    "               sg.Button(\"4x4\")],\n",
    "              [sg.Button('Close',font='Courier 15 bold '),sg.Button(\"ReSet\",font='Courier 15 bold '),sg.Button('STDOUT',font='Courier 15 bold')],\n",
    "              [sg.Button('Recent Errors',font='Courier 15 bold '),sg.Button(\"Update Logs\",font='Courier 15 bold '),sg.Button(\"View Log Summary\",font='Courier 15 bold ')],\n",
    "              [sg.FilesBrowse(button_text=\"Local File\",initial_folder=\"/home/joe/bic_etl\",font=\"CENTAUR 15\",file_types=[(\"CSV Files\",\"*.csv\"),(\"TSV Files\",\"*.tsv\"),(\"Excel Files\",\"*.xlsx\")],enable_events=True,key='-FILE1-')],\n",
    "              [sg.Button(\"Column Analysis\",font='Courier 15 bold '),sg.Button(\"Inv Fields\",font='Courier 15 bold ')],\n",
    "   #          [sg.Button(\"GO\")],\n",
    "              [sg.Button(\"Extract\",font='Courier 15 bold ',key=\"-EXTRACT-\",visible=True),\n",
    "               sg.Button(\"Analyze-Extr\",font='Courier 15 bold ',key=\"-EXTRACTANAL-\",visible=False),\n",
    "               sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-EXTRACTINFO-\")],\n",
    "              [sg.Button(\"Transform\",visible=True,font='Courier 15 bold ',key=\"-TRANSFORM-\"),\n",
    "               sg.Button(\"Ananlyze-Trans\",font='Courier 15 bold ',key=\"-TRANSFORMANAL-\",visible=False),\n",
    "               sg.Button(\"View-Transform\",font='Courier 15 bold ',key=\"-TRANSFORMVIEW-\",visible=False),\n",
    "               sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-TRANSFORMINFO-\")\n",
    "              ],\n",
    "              [sg.Button(\"CIM API\",font='Courier 15 bold ',key=\"-CIMAPI-\",visible=False),sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-CIMINFO-\")],\n",
    "              [sg.Button(\"Source Defs\",font='Courier 15 bold ')],\n",
    "              [sg.Button(\"Create Field Xrefs\",font='Courier 15 bold '),sg.Button(\"Show Field Xrefs\",font='Courier 15 bold')],\n",
    "              [sg.Multiline(default_text=\"Dataset Summary\",enable_events=True,font='Courier 15 bold ',background_color=\"blue\",key=\"-OUTPUT-\",size=[70,10]),\n",
    "               sg.Multiline(default_text=\"ETL Summary\",key=\"-ETL-\",size=[70,20],font='Courier 15 bold ')]             \n",
    "            ]\n",
    "\n",
    "       \n",
    "    # Create the Window\n",
    "    sg.theme('Dark Green 5')\n",
    "    window2 = sg.Window('ETL', layout,finalize=True,resizable=True)\n",
    "    #window = sg.Window('Window Title', layout, web_port=2222, web_start_browser=False)\n",
    "    #table = window2['-TABLE2-']\n",
    "\n",
    "    #window2.move(window.current_location()[0]+600, window.current_location()[1])\n",
    "    try: \n",
    "        while True:\n",
    "\n",
    "         #   event, values = window2.read()\n",
    "            wid, event, values = sg.read_all_windows()\n",
    "            print(\"\\n\\n-----------------------------------\\n\")\n",
    "            print('event: ',event)\n",
    "            print(wid.Title)\n",
    "            print(wid)\n",
    "            if event == sg.WIN_CLOSED or event == 'Close':\n",
    "                window2.close()\n",
    "                break\n",
    "            elif event ==  event == 'Quit':\n",
    "                wid.close()\n",
    "### DATASET                \n",
    "            elif event == \"-DATASET-\" or event == \"4x4\" or event == \"Group Menu\":\n",
    "                window2[\"-EXTRACTANAL-\"].update(visible=True)\n",
    "                window2[\"-TRANSFORMANAL-\"].update(visible=True)\n",
    "                window2[\"-EXTRACTINFO-\"].update(\"\")\n",
    "                window2[\"-TRANSFORMINFO-\"].update(\"\")\n",
    "                window2[\"-OUTPUT-\"].update(\"\")\n",
    "                window2[\"-ETL-\"].update(\"\")  \n",
    "                window2[\"-TRANSFORMVIEW-\"].update(visible=False)\n",
    "            \n",
    "      #      elif event == \"GO\":#\n",
    "                if event == \"-DATASET-\":\n",
    "                    (ds)  = list(values.items())\n",
    "                    ds=ds[0][1]\n",
    "                elif event == \"4x4\":\n",
    "                    ds = xrefsBy4x4[values[\"-4x4-\"]]\n",
    "                  #  print(\"XREF DS \",values[\"-4x4-\"],ds)\n",
    "                elif event == \"Group Menu\":\n",
    "                    ds = values[\"Group Menu\"]\n",
    "              \n",
    "                ds = \"Charity Extension Requests\"\n",
    "                dstitle = ds \n",
    "                if ds in mapTitles:\n",
    "                    ds = mapTitles[ds]\n",
    "                print(\"Daetaset \",ds)\n",
    "                datasetTitle = ds\n",
    "                try: \n",
    "                    mmf = mfShort.loc[mfShort[\"Standardized Title for Dataset\"].str.strip() == ds.strip()]\n",
    "                    print(\"MMF \",mmf.shape[0])\n",
    "                    cim4x4 = mmf['Data Link'].values.tolist()[0]\n",
    "                    cimApi = f\"https://data.colorado.gov/api/views/{cim4x4}/rows.csv?accessType=DOWNLOAD\"\n",
    "                    if mmf.shape[0] > 0:\n",
    "                    #            mmf[\"Standardized Short Description\"] = mmf[\"Standardized Short Description\"].map(wrap)          \n",
    "                        text = f\"Title             : {mmf['Standardized Title for Dataset'].values.tolist()[0]}\\nSocrata        : {mmf['Data Link'].values.tolist()[0]}\\nData Type    : {mmf['CIM Data Type'].values.tolist()[0]}\\nPublish Year: {mmf['GoCodePublishYear'].values.tolist()[0]}\\nCIM Link : {mmf['CIM Link'].values.tolist()[0]}\\nDescription  : {mmf['Standardized Short Description'].values.tolist()[0]}\"            \n",
    "                       # display(mmf)\n",
    "                    else:\n",
    "                        text = \"None\"\n",
    "                    if ds.strip() in dataSetsEtl:\n",
    "                          text2,extract,transform,trfile,directory,datasetCharId = runETL(ds.strip())\n",
    "                          print(\"HIT HIT HIT \",text2,extract)\n",
    "                          print(\"DATASETCHARID 2\",datasetCharId)\n",
    "                    else:\n",
    "                          text2=\"\"\n",
    "                          extract = \"\"\n",
    "                    if len(extract) > 10:\n",
    "                        window2[\"-EXTRACT-\"].update(visible=True)\n",
    "                    if len(transform) > 10:\n",
    "                        window2[\"-TRANSFORM-\"].update(visible=True)\n",
    "                     #   window2[\"-TRANSFORM-\"].update(visible=True)\n",
    "\n",
    "                    if len(cimApi) > 10:                 \n",
    "                        text2+=  f\"\\n\\nCIM API\\n{cimApi}\"\n",
    "                        window2[\"-CIMAPI-\"].update(visible=True)\n",
    "                    if len(transform) > 4:\n",
    "                        spl = transform.split()\n",
    "                        a= spl[1]\n",
    "                        trfile=a\n",
    "                    print(\"TRFILE \",trfile)\n",
    "                    if len(trfile) > 4:\n",
    "                        window2[\"-TRANSFORMVIEW-\"].update(visible=True)\n",
    "                    window2[\"-OUTPUT-\"].update(text)\n",
    "                    window2[\"-ETL-\"].update(text2)\n",
    "                    link =  mmf['CIM Link'].values.tolist()[0]\n",
    "                    string = \"\\n\\nCLI Update\\n\"\n",
    "                    string+= f\"node /home/joe/bic_etl/general/scripts/bic_etl.js\"\n",
    "                    string+= f\"\\n-t '{ds}'\\n\"\n",
    "                    string+= \"-p ?\"\n",
    "                    window2[\"-ETL-\"].update(string,append=True)\n",
    "                except Exception as err:\n",
    "                    print(f\"Dataset Not Found: {ds}\")\n",
    "                    exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "                \n",
    "           #     print(\"Link \",mmf['CIM Link'],link.find(\"http\"))\n",
    "                \n",
    "                # if link.find(\"http\") > -1:\n",
    "                #      window2[\"-LINK-\"].update (visible=True)\n",
    "                # else:\n",
    "                #      window2[\"-LINK-\"].update (visible=False)\n",
    "### LINK                \n",
    "               \n",
    "            elif event == \"-LINK-\":\n",
    "                  #  print(\"Going To: \",link) \n",
    "                    if len(link) > 10:\n",
    "                        webbrowser.open(link)\n",
    "                        \n",
    "### ReSet\n",
    "            elif event == \"ReSet\":\n",
    "                for wid,val in windowsReset.items():\n",
    "                    print(\"RES \",type(wid),type(val),wid)\n",
    "                                          \n",
    "### Write Source Defs\n",
    "            elif event == \"Write Source Defs\":\n",
    "                print(\"DATASETCHARID \",datasetCharId)\n",
    "                targDir = os.path.join(bicHome, directory,definitionDir)\n",
    "                createDir(targDir)\n",
    "                sourceDefFile = writeSoureFieldList(cim4x4,values,targDir,datasetCharId)\n",
    "### SOURCE Defs\n",
    "            elif event == \"Source Defs\":        \n",
    "                sourceDefs2Fields(dfExtract.columns)\n",
    "            \n",
    "### Create Field XREFS\n",
    "            elif event == \"Create Field Xrefs\":\n",
    "                targDir = os.path.join(bicHome, directory,definitionDir)\n",
    "#                createDir(targDir)\n",
    "\n",
    "                if len(sourceDefFile) < 4:\n",
    "                    sourceDefFile = os.path.join(targDir,f\"{cim4x4}_{datasetCharId}_src_fld_defs.json\")                    \n",
    "                print(\"SDF \",sourceDefFile)\n",
    "                transTmp = createSrcTransFieldXref(cim4x4,dfExtract.columns,dfTransform.columns,sourceDefFile,targDir)\n",
    "\n",
    "### Show Field XREFS\n",
    "            elif event == \"Show Field Xrefs\":\n",
    "                targDir = os.path.join(bicHome, directory,definitionDir)\n",
    "                file = os.path.join(targDir,f\"{cim4x4}_{datasetCharId}_src_trns_xrefs.json\")\n",
    "                showSrc2TransXrefs(file)\n",
    "### ADD XREF FIELD            \n",
    "            elif event == \"Add XREF Field\":\n",
    "                nfieldsAdded+=1\n",
    "                if nfieldsAdded == 1:\n",
    "                     wid[f\"secondFrame\"].update(visible=True)\n",
    "                     wid[f\"someFrame\"].update(visible=True)\n",
    "\n",
    "                wid[f\"FRAME:CUST:{nfieldsAdded}\"].update(visible=True)\n",
    "\n",
    "### BUILD XREF FILE   (write source to Transformed XREF file)                \n",
    "            elif event == \"Write XREF File\":\n",
    "                try:\n",
    "                    writeFieldFileN(cim4x4,values,targDir,datasetCharId)\n",
    "                except Exception as err:\n",
    "                    print(\"ERROR \",err)\n",
    "                    \n",
    "### LISTBOX    (selection made in SOURCE to Transformed XREF list)\n",
    "            elif event.find(\"LISTBOX\") > -1 and values[event] == \"NONE\":\n",
    "                newname = sg.popup_get_text(\"Input Transform Field Name in Camel-Case\",font='Courier 25 bold')\n",
    "    ##  Force user to input a variable with NO Spaces..\n",
    "                while newname and (newname.find(\" \") > -1 or newname[0].isupper()):\n",
    "                    if newname.find(\" \") > -1:\n",
    "                        sg.popup(\"No Spaces Allowed\",font='Courier 25 bold')\n",
    "                    elif newname[0].isupper():\n",
    "                        sg.popup(\"Please us Camel-Case (i.e. First letter NOT Capitalized)\",font='Courier 25 bold')\n",
    "\n",
    "                    newname = sg.popup_get_text(\"Input Field Name in Camel Case\",font='Courier 25 bold')\n",
    "\n",
    "                if newname:\n",
    "                    transTmp.append(newname)\n",
    "                    transTmp = reorderList(newname,sorted(transTmp))\n",
    "                    a=transTmp.copy()\n",
    "                    a.append(\"NONE\")\n",
    "                    wid[event].update(values=a,set_to_index=0)\n",
    "                    wid.refresh()         \n",
    "\n",
    "\n",
    "### Output Text Table\n",
    "            elif event == \"Output Text Table\" or event == \"Output CSV File\":    \n",
    "                vals = wid.metadata[3]\n",
    "                cols = wid.metadata[4]\n",
    "                ff = wid.metadata[5]\n",
    "                df = pd.DataFrame(vals,columns=cols)\n",
    "                dfoutput = df.copy()\n",
    "                ofile = sg.popup_get_text(\"Output File?\",font='Courier 15 bold') \n",
    "                if event == \"Output Text Table\":\n",
    "                    fout = open(ofile.strip(),\"w+\")\n",
    "                    fout.write(f\"\\nDataset: {dstitle}\")\n",
    "                    fout.write(f\"\\nFile: {ff}\\n\\n\")\n",
    "                    fout.write(f\"Shape: {df.shape}\\n\\n\")\n",
    "                    string=tabulate(df, headers='keys', tablefmt='fancy_outline')\n",
    "                    fout.writelines(string)\n",
    "                    fout.close()\n",
    "                    sg.popup(f\"Text Table written to {ofile}\")\n",
    "                else:\n",
    "                    c1 = []\n",
    "                    c2 = []\n",
    "                    c3 = []\n",
    "                    c1.append(f\"Dataset: {dstitle}\")\n",
    "                    c2.append(f\"File: {ff}\")                  \n",
    "                    c3.append(f\"Shape: {df.shape}\")\n",
    "                    for nn in range(1,len(dfoutput.columns)):\n",
    "                        c1.append(\"\")\n",
    "                        c2.append(\"\")\n",
    "                        c3.append(\"\")\n",
    "                        \n",
    "                    columns = pd.MultiIndex.from_arrays([\n",
    "                        c1,c2,c3,dfoutput.columns\n",
    "                    ])\n",
    "                    df.columns = columns\n",
    "                    df.to_csv(ofile.strip(),index=False)\n",
    "                    \n",
    "### Output Columns\n",
    "            elif event == \"Output Columns\":\n",
    "                 df = wid.metadata[1]\n",
    "               \n",
    "                \n",
    "                 ctitle = wid.metadata[2]\n",
    "                 columns = sorted(list(df.columns))\n",
    "                 fout = open(f\"/tmp/columns.txt\",\"a+\")\n",
    "                 fout.write(f\"\\n{datetime.today()} -> {cim4x4} -> {ctitle} - {datasetTitle}\\n\")\n",
    "                 for col in columns:\n",
    "                     fout.write(col+\"\\n\")\n",
    "                 fout.close()\n",
    "                 print(f\"{len(columns)} columns written to /tmp/columns.txt\")\n",
    "### STDOUT\n",
    "            elif event == \"STDOUT\":\n",
    "                layouto = [[sg.Button(\"Quit\")],\n",
    "                          [sg.Multiline(s=(90,30),font='Courier 15 bold ',background_color=\"#F7DC6F\",text_color=\"black\",key=\"-STDOUT-\")]\n",
    "                          ] \n",
    "                wind = sg.Window('STDOUT STDERR', layouto,finalize=True,resizable=True)\n",
    "### View Log Summary\n",
    "            elif event == 'View Log Summary':\n",
    "                vals,cols = getLogSummary()\n",
    "                showLogSummary(vals,cols)\n",
    "        \n",
    "### Local File\n",
    "            elif event == '-FILE1-':\n",
    "                    file=values[\"-FILE1-\"]\n",
    "                    dfLocal,stats1Local = getFile(\"Local\",file,window2)\n",
    "                    LocalColumns = list(dfLocal.columns)\n",
    "                    color1 = colorPairs[numWindows][0]\n",
    "                    color2 = colorPairs[numWindows][1]\n",
    "                  \n",
    "                    numWindows+=1\n",
    "                    if numWindows > len(colorPairs):\n",
    "                        numWindows=0\n",
    "\n",
    "                    WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(wid,stats1Local,dfLocal,file,\"Local File Analysis\",\"DarkPurple\")\n",
    "                    dataStore[tabl1]=valsFile1\n",
    "                    windowsOpen[\"main\"].append(WindowC)    \n",
    "        \n",
    "### Recent Errors\n",
    "            elif event == 'Recent Errors':\n",
    "                w = showRecentLogs(errorsByDate)\n",
    "            \n",
    "### Include Completed Errors\n",
    "            elif event == \"Include Completed\":\n",
    "                errorStatus = getErrorStatus()\n",
    "                values,rowColrs = orderErrors(errorsByDate,errorStatus,1)\n",
    "                wid[\"-DAILY-\"].update(values=values,row_colors=rowColrs)\n",
    "        \n",
    "            \n",
    "### Update Logs\n",
    "            elif event == \"Update Logs\":\n",
    "                nfiles,files = updateLogs(1)\n",
    "                print(f\"Downloaded {nfiles} for THIS month\")\n",
    "                nfiles,files = updateLogs(2)\n",
    "                print(f\"Downloaded {nfiles} for Last month\")\n",
    "                errorsByDate,errorsByName=getRecentErrorsNew()\n",
    "                string=f\"{nfiles} Downloaded\\n\"\n",
    "            \n",
    "### Daily-click\n",
    "            elif event == '-DAILY-Click':\n",
    "                xx=wid.metadata\n",
    "\n",
    "                table=wid[\"-DAILY-\"]\n",
    "                e = table.user_bind_event\n",
    "                region = table.Widget.identify('region', e.x, e.y)\n",
    "                if region == 'heading':\n",
    "                    row = 0\n",
    "                elif region == 'cell':\n",
    "                    row = int(table.Widget.identify_row(e.y))\n",
    "                elif region == 'separator':\n",
    "                    continue\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "             #   print(row,xx[row-1])\n",
    "\n",
    "                string = f\"Date: {xx[row-1][0]}\\n\\nDataset: {xx[row-1][1]}\\n\\nMessage: {xx[row-1][3]}\\n\"\n",
    "                showError(xx[row-1])\n",
    "\n",
    "### Show Missing Columns\n",
    "            elif event == \"Show Missing Fields\":\n",
    "                  window2,tableex,tabletr,tableci = showMissingColumns()\n",
    "            \n",
    "###  Write Log\n",
    "            elif event == \"Write Log\":\n",
    "                row=wid.metadata\n",
    "            #    print(row)\n",
    "                rowToWrite = [row[0],\"Joe Comeaux\",row[1],row[2],values[\"-ERRORTITLE-\"],\n",
    "                              row[4],values[\"-ERRORNOTES-\"],values[\"-ERRORJIRA-\"],row[-1]]\n",
    "                count=0\n",
    "                for val in rowToWrite:\n",
    "                  #  print(count,val)\n",
    "                    count+=1\n",
    "    #            yy = [date,errorsByDate[date][\"name\"][nn],errorsByDate[date][\"4x4\"][nn],errorsByDate[date][\"title\"][nn],msg,errorsByDate[date][\"stitle\"][nn]]\n",
    "                ret = toGoogleSheet(rowToWrite)\n",
    "                sg.Popup(f\"Result of {event}\\n{ret}\",font='Courier 10 bold ')\n",
    "               \n",
    "### Mark Done\n",
    "            elif event == \"Mark Done\" or event == \"Mark Skip\":\n",
    "                row=wid.metadata\n",
    "        \n",
    "                status=\"Fixed\"\n",
    "                if event == \"Mark Skip\":\n",
    "                    status=\"Skipped\"\n",
    "                toMark = [row[-1],row[1],row[3],row[2],status]\n",
    "                ret = markDone(toMark)\n",
    "                sg.Popup(f\"Result of {event}\\n{ret}\",font='Courier 10 bold ')\n",
    "\n",
    "### Full Data Column Map\n",
    "            elif event == \"Full Data Column Map\":\n",
    "                cols,vals,missed = fullDataColumnMap(cim4x4)\n",
    "                showFullDataColMap(cols,vals)\n",
    "            \n",
    "### Get SIJ Cols\n",
    "            elif event == \"Get SIJ Cols\":\n",
    "                getSijColumns(\"\")\n",
    "              #  print(\"Tr SIJ \",transformSijColumns)\n",
    "              #  print(\"LD SIJ \",loadSijColumns)\n",
    "                 \n",
    "### DNOTP\n",
    "\n",
    "            elif event == \"-DNOTP-\":\n",
    "                col = values[\"-DNOTP-\"][0]\n",
    "                if col in dnotpLines:\n",
    "                    string=\"\"\n",
    "                    string = \"\\n\".join(dnotpLines[col])\n",
    "                else:\n",
    "                    string=\"NOTHING FOUND\"\n",
    "                sg.Popup(string)\n",
    "                    \n",
    "             #   print(\"DNOTP STRai\",string)\n",
    "### Column Analysis                \n",
    "            elif event == \"Column Analysis\":\n",
    "           #     trfile = dataSetsEtl[ds][\"transform\"][\"file\"]\n",
    "                if transform[0:4] == \"node\":\n",
    "                    trfile = transform[5:]\n",
    "        \n",
    "                \n",
    "                xrefsO2T,xrefsT2O = tranfColXref(trfile)\n",
    "                color1 = colorPairs[numWindows][0]\n",
    "                color2 = colorPairs[numWindows][1]\n",
    "                \n",
    "                numWindows+=1\n",
    "                if numWindows > len(colorPairs):\n",
    "                    numWindows=0\n",
    "                showColAnal(xrefsO2T,xrefsT2O,color1,color2)\n",
    "                \n",
    "### Inv Fields \n",
    "            elif event == \"Inv Fields\":\n",
    "                showInvFields(cim4x4)\n",
    "        \n",
    "             \n",
    "### Compare 2 Data                 \n",
    "            elif event == \"Compare 2 Data\":   \n",
    "              #  print(\"HERE We GO\")\n",
    "                ww = windowsStore[\"extract\"]\n",
    "                wdf = ww.metadata[1]\n",
    "                \n",
    "                compare2Data(wdf,xrefsO2T)\n",
    "                         \n",
    "### CIMAPI                \n",
    "            elif event == \"-CIMAPI-\":\n",
    "                  #  df1,stats1 = getFilesClicked(cimApi,window2)\n",
    "                    dfCim,stats1Cim = getFile(\"Fetch\",cimApi,window2)\n",
    "                    cimColumns = list(dfCim.columns)\n",
    "                    color1 = colorPairs[numWindows][0]\n",
    "                    color2 = colorPairs[numWindows][1]\n",
    "\n",
    "                    numWindows+=1\n",
    "                    if numWindows > len(colorPairs):\n",
    "                        numWindows=0\n",
    "\n",
    "                    WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(wid,stats1Cim,dfCim,cimApi,\"CMI Analysis\",\"DarkRed\")\n",
    "                    dataStore[tabl1]=valsFile1\n",
    "                    \n",
    "                    windowsOpen[\"main\"].append(WindowC)  \n",
    "                    \n",
    "### TRANSFORM               \n",
    "            elif event == \"-TRANSFORM-\":\n",
    "                print(\"TRANSFORM \")\n",
    "                print(\"tr \",transform)\n",
    "                a=subprocess.run(transform,shell=True,capture_output=True,text=True)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"TRANSFORM Output\\n\"\n",
    "                tfile=\"\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= f\"Error:\\n {a.stderr}\"\n",
    "                elif len(a.stdout) > 0 or len(trfile) > 0:\n",
    "                    if len(a.stdout) > 0:\n",
    "                        for msg in a.stdout.split(\"debug msg:\"):    \n",
    "                            if msg.find(\"final file is at:\") > -1:\n",
    "                                tmp = msg.split(\" \")\n",
    "                                tfile = tmp[-3]\n",
    "                            elif \"Output File\" in msg:\n",
    "                                il = msg.index(\"Output File\")\n",
    "                                tmp = msg[il+13:]\n",
    "                                tfile = tmp\n",
    "                            tfile=tfile.strip()\n",
    "                        #    print(f\"TTTFILE {tfile}:\")   \n",
    "                    elif len(trfile) > 0:\n",
    "                        tfile=trfile\n",
    "                    if os.path.isfile(tfile):\n",
    "\n",
    "                        window2[\"-TRANSFORMANAL-\"].update(visible=True)\n",
    "                        fileStats = os.stat(tfile)\n",
    "                    #    print(\"FSTATS \",fileStats)\n",
    "                        dt = datetime.fromtimestamp(fileStats.st_ctime)\n",
    "                        string = f\"{fileStats.st_size:,} bytes Created: {dt}  file: {tfile}\"\n",
    "                     #   print(\"STRING \",string)\n",
    "                        window2[\"-TRANSFORMINFO-\"].update(string,visible=True)\n",
    "                            \n",
    "                    string+=f\"STDOUT: {a.stdout}\"\n",
    "                    window2[\"-ETL-\"].update(string,append=True)\n",
    "                    \n",
    "### TRANSFORMANAL\n",
    "            elif event == \"-TRANSFORMANAL-\":\n",
    "                #    df1,stats1 = getFilesClicked(tfile,window2)\n",
    "                    try: \n",
    "                        dfTransform,stats1Transform = getFile(\"Local\",tfile,window2)\n",
    "                        transformColumns = list(dfTransform.columns)\n",
    "                        color1 = colorPairs[numWindows][0]\n",
    "                        color2 = colorPairs[numWindows][1]\n",
    "\n",
    "                        numWindows+=1\n",
    "                        if numWindows > len(colorPairs):\n",
    "                            numWindows=0\n",
    "                        print(\"TFILE \",tfile)\n",
    "                        WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(wid,stats1Transform,dfTransform,tfile,\"Transform Analysis\",\"DarkPurple\")\n",
    "                        dataStore[tabl1]=valsFile1\n",
    "                        windowsOpen[\"main\"].append(WindowC)    \n",
    "                    except  Exception as err: \n",
    "                        exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "### TRANSFORMVIEW\n",
    "            elif event == \"-TRANSFORMVIEW-\":\n",
    "                showFile(trfile)\n",
    "             \n",
    "### CREATE FIELD LISTING\n",
    "            elif event == \"Field Xrefs\":\n",
    "                fieldXrefs = createFieldFile(w4x4,list(dfExtract.columns),list(dfTransform.columns))\n",
    "\n",
    "### WRITE FIELD LIST FILE\n",
    "            elif event == \"Write Fields\":\n",
    "                writeFieldFile(w4x4,values,fieldXrefs,f\"{bicHome}{directory}\")\n",
    "                                \n",
    "### EXTRACT                  \n",
    "            elif event == \"-EXTRACT-\":\n",
    "                print(\"EXTACT: \",extract)\n",
    "                a=subprocess.run(extract,shell=True,capture_output=True,text=True)\n",
    "                print(\"RETURN \",a)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"Extract Output\\n\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= \"fError:\\n {a.stderr}\"\n",
    "                string+=f\"STDOUT: {a.stdout}\"\n",
    "                window2[\"-ETL-\"].update(string,append=True)\n",
    "                sx = string.find(\"successfully download to\")\n",
    "                string[sx+25:]\n",
    "                sxo = string[sx+25:].find(\"!\")\n",
    "             \n",
    "                file=f\"/home/joe/bic_etl{string[sx+25:sx+25+sxo]}\"\n",
    "              \n",
    "                if os.path.isfile(file):\n",
    "                  \n",
    "                    window2[\"-EXTRACTANAL-\"].update(visible=True)\n",
    "                    fileStats = os.stat(file)\n",
    "                    dt = datetime.fromtimestamp(fileStats.st_ctime)\n",
    "                    string = f\"{fileStats.st_size:,} bytes Created: {dt}  file: {file}\"\n",
    "                    window2[\"-EXTRACTINFO-\"].update(string,visible=True)\n",
    "                    \n",
    "### EXTRACTANAL                      \n",
    "            elif event == \"-EXTRACTANAL-\":\n",
    "                file=stringArgs(extract)\n",
    "                \n",
    "             #   df1,stats1 = getFilesClicked(file,window2)\n",
    "                dfExtract,stats1Extract = getFile(\"Local\",file,window2)\n",
    "                extractColumns = list(dfExtract.columns)\n",
    "                color1 = colorPairs[numWindows][0]\n",
    "                color2 = colorPairs[numWindows][1]\n",
    "                \n",
    "                numWindows+=1\n",
    "                if numWindows > len(colorPairs):\n",
    "                    numWindows=0\n",
    "                    \n",
    "                WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(wid,stats1Extract,dfExtract,file,\"Extract Analysis\",\"DarkBlue16\")\n",
    "                dataStore[tabl1]=valsFile1\n",
    "                windowsOpen[\"main\"].append(WindowC)\n",
    "                windowsStore[\"extract\"] = WindowC\n",
    "                \n",
    "### TABLEFILE-CLICK\n",
    "            elif event == \"-TABLEFILE-Click\":\n",
    "                try:\n",
    "                    tabl1 = wid[\"-TABLEFILE-\"]\n",
    "                    dat = wid.metadata[3]\n",
    "                    \n",
    "                    row,col=getRowClicked(tabl1,dat)\n",
    "                    if row == 0:\n",
    "                       tabl1 = wid[\"-TABLEFILE-\"]\n",
    "                       header = headerStore[tabl1]\n",
    "                       stats1 = statsStore[tabl1]\n",
    "                       valsFile1,columnSortStateTable1 = sortTable(row,stats1,tabl1,event,header)          \n",
    "                       rowFile1Colors=setRowColors(valsFile1,color1,color2,\"pink\",header)\n",
    "                       wid[\"-TABLEFILE-\"].update(values=valsFile1,row_colors=rowFile1Colors)\n",
    "                       wid[\"-TABLEFILE-\"].metadata=columnSortStateTable1\n",
    "                    else:\n",
    "                        \n",
    "                        df1 = wid.metadata[1]\n",
    "                        unq = df1[col].value_counts()\n",
    "                        colorTheme=wid.metadata[0]\n",
    "                        \n",
    "                        w,t,values,uHead = showDFUN(col,unq,wid,color1,color2,colorTheme)\n",
    "                      #dataStore[t] = values\n",
    "                        headerStore[t] = uHead\n",
    "                        windowsOpen[\"main\"].append(w)\n",
    "                except  Exception as err: \n",
    "                       exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "                    \n",
    "                    \n",
    "### TABLE-Click\n",
    "            elif event == \"-TABLE-Click\":  # This is the Unique Values tables\n",
    "                try: \n",
    "                    table = wid['-TABLE-']                              \n",
    "                    row,val =getRowClickedUN(table)\n",
    "                    if row == 0:\n",
    "                        sortUniqe(table,wid,dataStore,headerStore)\n",
    "                    else:\n",
    "                        widP = wid.metadata[0]\n",
    "                        col = wid.metadata[1]\n",
    "                        df = widP.metadata[1]\n",
    "                        tmp = df.loc[df[col] == val]\n",
    "                        showDfRecs(tmp,col,val,widP,title=\"DF Unique Record Values\")\n",
    "                except  Exception as err: \n",
    "                   exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "\n",
    "###  -TABLEMISSEXTR-Click                   \n",
    "            elif event in [\"-TABLEMISSEXTR-Click\",\"-TABLEMISSTRANS-Click\",\"-TABLEMISSCIM-Click\"] :\n",
    "                if event == \"-TABLEMISSEXTR-Click\":\n",
    "                   tabl1 = wid[\"-TABLEMISSEXTR-\"]\n",
    "                   title = \"EXTRACT\"\n",
    "                   df = dfExtract\n",
    "                elif event == \"-TABLEMISSTRANS-Click\":\n",
    "                   tabl1 = wid[\"-TABLEMISSTRANS-\"]\n",
    "                   df =  dfTransform\n",
    "                   title = \"TRANSFORM\"\n",
    "                elif event == \"-TABLEMISSCIM-Click\":\n",
    "                   tabl1 = wid[\"-TABLEMISSCIM-\"]\n",
    "                   df =  dfCim\n",
    "                   title=\"CIM\"\n",
    "                 \n",
    "                \n",
    "                vals = dataStore[tabl1]\n",
    "                row,col=getRowClicked(tabl1,vals)\n",
    "                unq = df[col].value_counts()\n",
    "                colorTheme=wid.metadata[0]\n",
    "                w,t,values,uHead = showDFUN(col,unq,wid,color1,color2,colorTheme,title)\n",
    "                  #dataStore[t] = values\n",
    "                headerStore[t] = uHead\n",
    "                windowsOpen[\"main\"].append(w)\n",
    "                   \n",
    "         \n",
    "    except  Exception as err: \n",
    "       exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    " \n",
    "    for wid in windowsOpen[\"main\"]:\n",
    "      #  print(\"window MA\",wid)\n",
    "        if wid:\n",
    "          #  print(\"cosing \",wid)\n",
    "            wid.close()\n",
    "            wid = None\n",
    "\n",
    "cronGUI()\n",
    "\n",
    "\n",
    "\n",
    "### Bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85668fba-579d-4a7d-bc1a-c15bfd856ad9",
   "metadata": {},
   "source": [
    "# Bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d59ffb-21d9-49a8-9911-03aac60a6549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525ef23-a15e-4a34-afa2-a7fddbcf53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file=\"/home/joe/bic_etl/cdos/business/nonprofit/defs/icqv-mi3c_char_orgs_ext_src_trns_xrefs.json\"        \n",
    "        \n",
    "\n",
    "    \n",
    "showSrc2TransXrefs(file)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99a035-2dba-4c72-bea1-78ece1698c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "    \n",
    "def tkPopup(string,title,bgColor=\"grey\"):\n",
    "    def close():\n",
    "       popup.destroy()\n",
    "       popup.quit()\n",
    "\n",
    "    popup = tk.Tk()\n",
    "    popup.wm_title(title)\n",
    "    label = Label(popup, text=string,font=('Courier',20),justify=\"left\", relief=\"groove\")\n",
    "    label.configure(bg=bgColor)\n",
    "    label.pack(side=\"top\", fill=\"x\", pady=10)\n",
    "    my_button= Button(popup, text= \"OK\", font=('Courier',25),\n",
    "    borderwidth=2, command= close)\n",
    "    my_button.pack(pady=20)\n",
    "    popup.mainloop()\n",
    "        \n",
    "#############################################################   \n",
    "\n",
    "    \n",
    "def sourceDefs2Fields(fields,defs): \n",
    "    '''Reads a csv with the definition listings,and gets the fields listings from\n",
    "       the Extract process, and creates a form for creating a Source Field list to Source\n",
    "       Definition file\n",
    "    '''\n",
    "    global mapping\n",
    "    rows = []\n",
    "    fieldsTmp = fields.copy()\n",
    "    tmpD2F = {}\n",
    "    mapping = {}\n",
    "    for col in defs:\n",
    "        cc = getMostLike(col,fields)\n",
    "        tmpD2F[col]=cc\n",
    "    \n",
    "    for nn,col in enumerate(defs):\n",
    "        row=[]\n",
    "        fieldsTmp = reorderList(tmpD2F[col],sorted(fieldsTmp))\n",
    "        row.append(sg.Combo(fieldsTmp,default_value=tmpD2F[col],enable_events=True,  \n",
    "                            font='Courier 15 bold ',key=f\"DEFS::{col}\",\n",
    "                     #       select_mode=\"LISTBOX_SELECT_MODE_SINGLE\",\n",
    "                            size=(30,6)))\n",
    "        row.append(sg.Text(col,font='Courier 15',key=f\"{col}\",size=(30,3)))\n",
    "        rows.append([sg.Frame(\"\",[row])])\n",
    "        \n",
    "    layout = [[sg.Button(\"Quit\")],\n",
    "              [sg.Button(\"Source Analysis\",key=\"-EXTRACTANAL-\")],\n",
    "              [sg.Button(\"Create Defs\")],\n",
    "               [sg.Column(rows,scrollable=True)]\n",
    "             ]\n",
    "    try:\n",
    "        sg.theme(\"LightBrown4\")     \n",
    "        window2 = sg.Window(\"Input Source Definitions\",layout,finalize=True,resizable=True)\n",
    "        a = window2.CurrentLocation()\n",
    "        screen_width, screen_height = window2.get_screen_dimensions()\n",
    "        win_width, win_height = window2.size\n",
    "        x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "        x=200\n",
    "        y=200\n",
    "        window2.move(x, y)\n",
    "        # for col in orig:\n",
    "        #    window2[f\"LISTBOX:{col}\"].bind('<Button-1>', \"Click\")\n",
    "\n",
    "        nfieldsAdded=0\n",
    "        while True:\n",
    "\n",
    "    #      #   event, values = window2.read()\n",
    "            wid, event, values = sg.read_all_windows()\n",
    "            print(\"\\n\\n-----------------------------------\\n\")\n",
    "            print('event: ',event)\n",
    "    #        print('values: ',values)\n",
    "            print(wid.Title)\n",
    "            print(wid)\n",
    "            if event == sg.WIN_CLOSED or event == 'Quit':\n",
    "                window2.close()\n",
    "                break  \n",
    "                \n",
    "            elif event == \"-EXTRACTANAL-\":\n",
    "                file=stringArgs(extract)                \n",
    "             #   df1,stats1 = getFilesClicked(file,window2)\n",
    "                dfExtract,stats1Extract = getFile(\"Local\",file,window2)\n",
    "                extractColumns = list(dfExtract.columns)\n",
    "                color1 = colorPairs[numWindows][0]\n",
    "                color2 = colorPairs[numWindows][1]\n",
    "                \n",
    "                numWindows+=1\n",
    "                if numWindows > len(colorPairs):\n",
    "                    numWindows=0\n",
    "                    \n",
    "                WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(wid,stats1Extract,dfExtract,file,\"Extract Analysis\",\"DarkBlue16\")\n",
    "                dataStore[tabl1]=valsFile1\n",
    "                windowsOpen[\"main\"].append(WindowC)\n",
    "                windowsStore[\"extract\"] = WindowC    \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            elif event == \"Create Defs\":\n",
    "                print(\"Values\")\n",
    "                \n",
    "                for k,v in values.items():\n",
    "                    if k[:4] == \"DEFS\":\n",
    "                       if v not in mapping:\n",
    "                          mapping[v] = []\n",
    "                       mapping[v].append(k[6:].strip())\n",
    "                stringGood=\"\"\n",
    "                stringBad=\"\"\n",
    "                nbad=0\n",
    "                for col,v in mapping.items():\n",
    "                    if len(v) > 1:\n",
    "                       for val in v:\n",
    "                            stringBad+= f\"{col}  -> {val}\\n\"\n",
    "                       nbad+=1\n",
    "                       stringBad+= f\"\\n\"\n",
    "                    else:\n",
    "                       stringGood+= f\"{col}  -> {v[0]}\\n\\n\"\n",
    "                if len(stringBad) > 0:\n",
    "                    stringAll = f\"Dataset: w4x4\\nError Inputing Definitions for Source Fields\\n\"\n",
    "                    stringAll+= f\"{nbad} out of {len(mapping)} Fields have Multiple Definitions\\n\\n\"\n",
    "                    print(f\"Bad {nbad} out of {len(mapping)} \",stringBad)\n",
    "                    stringAll+=stringBad\n",
    "                    tkPopup(stringAll,\"Errors in Creating Source Definitions\",\"pink\")\n",
    "                else:\n",
    "                    print(\"Good\",stringGood)\n",
    "                    tkPopup(stringGood,\"Creating Source Definitions\",\"white\")\n",
    "    except Exception as err:\n",
    "        print(\"ERR \",err)\n",
    "sourceDefs2Fields(dfExtract.columns,origDesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b137b-0ce5-4950-8a59-265ef31681ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "stringGood=\"\"\n",
    "stringBad=\"\"\n",
    "nbad=0\n",
    "for col,v in mapping.items():\n",
    "    if len(v) > 1:\n",
    "       for val in v:\n",
    "            stringBad+= f\"{col}  -> {val}\\n\"\n",
    "       nbad+=1\n",
    "       stringBad+= f\"\\n\"\n",
    "    else:\n",
    "       stringGood+= f\"{col}  -> {v[0]}\\n\\n\"\n",
    "    \n",
    "\n",
    "if len(stringBad) > 0:\n",
    "    stringAll = f\"Dataset: w4x4\\nError Inputing Definitions for Source Fields\\n\"\n",
    "    stringAll+= f\"{nbad} out of {len(mapping)} Fields have Multiple Definitions\\n\\n\"\n",
    "    print(f\"Bad {nbad} out of {len(mapping)} \",stringBad)\n",
    "    stringAll+=stringBad\n",
    "    tkPopup(stringAll,\"Errors in Creating Source Definitions\",\"pink\")\n",
    "else:\n",
    "    print(\"Good\",stringGood)\n",
    "    tkPopup(stringGood,\"Creating Source Definitions\",\"white\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e2942-7a4d-42fb-98a4-ff9e1a4a1d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def reorderList(string:str,a:list):\n",
    "    ''' If string exists in list a, it will be moved to the top of the list '''\n",
    "    b = a.copy()\n",
    "    if string in b:\n",
    "        ai = b.index(string)\n",
    "        b.pop(ai)\n",
    "        c = [string]\n",
    "        c[1:] = b\n",
    "    else:\n",
    "        c=a.copy()\n",
    "        \n",
    "    return c\n",
    "def getMostLike(a:str,b:list):\n",
    "    '''Searchs a list of strings for the value that is most like input the string a\n",
    "       Returns the string most like a\n",
    "       \n",
    "       col = getMostLike(\"someString\",someList)\n",
    "    '''\n",
    "    rmax = SequenceMatcher(None,a.lower(),b[0].lower()).ratio()\n",
    "    column=b[0]\n",
    "    if len(b) > 1:\n",
    "        for col in b[1:]:\n",
    "            r=SequenceMatcher(None,a.lower(),col.lower()).ratio()\n",
    "            if r > rmax:\n",
    "                rmax=r\n",
    "                column=col\n",
    "    return column\n",
    "\n",
    "\n",
    "        \n",
    "def createFieldFile(w4x4,orig,trans):\n",
    "    todayDate=f\"{today.year}-{today.month}-{today.day}\"    \n",
    "    tmp = {}\n",
    "# create a dictionary of the descripitons of the transform fields for easy lookup\n",
    "    for nn,fld in enumerate(fields[w4x4]['cim']):\n",
    "        tmp[fld] = fields[cim4x4]['description'][nn]\n",
    "    tmpT2O = {}\n",
    "    for col in trans:\n",
    "        cc = getMostLike(col,orig)\n",
    "        tmpT2O[col]=cc\n",
    "    col1 = []\n",
    "    col2 = []\n",
    "    col3 = []\n",
    "    rows = []\n",
    "    origTmp = orig.copy()\n",
    "    for col in trans:\n",
    "        if col in tmp:\n",
    "          row=[]\n",
    "          origTmp = reorderList(tmpT2O[col],sorted(origTmp))\n",
    "          row.append(sg.Combo(origTmp,default_value=tmpT2O[col],enable_events=True,  \n",
    "                                font='Courier 15 bold ',key=f\"LISTBOX:{col}\",\n",
    "                         #       select_mode=\"LISTBOX_SELECT_MODE_SINGLE\",\n",
    "                                size=(20,6)))\n",
    "          row.append(sg.Text(col,font='Courier 15 bold ',size=(30,1)))\n",
    "          row.append(sg.Multiline(tmp[col],font='Courier 12',size=(30,2)))\n",
    "          row.append(sg.Multiline(\"\",font='Courier 12',size=(30,2),key=f\"NOTES:{col}\"))\n",
    "          row.append(sg.Input(todayDate,font='Courier 15 bold ',size=(10,1),key=f\"DATE:{col}\"))\n",
    "        \n",
    "          rows.append([sg.Frame(\"\",[row])])\n",
    "            \n",
    "                            \n",
    "            \n",
    "    layout = [[sg.Button(\"Close\"),sg.Button(\"Build File\")],rows]\n",
    "             \n",
    "   \n",
    "\n",
    "    sg.theme(\"LightBrown6\")     \n",
    "    window2 = sg.Window(\"Log Summary\",layout,finalize=True,resizable=True)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "   \n",
    "\n",
    "    return tmp\n",
    "\n",
    "#     while True:\n",
    "\n",
    "# #      #   event, values = window2.read()\n",
    "#         wid, event, values = sg.read_all_windows()\n",
    "#         print(\"\\n\\n-----------------------------------\\n\")\n",
    "#         print('event: ',event)\n",
    "#         print('values: ',values)\n",
    "#         print(wid.Title)\n",
    "#         print(wid)\n",
    "#         if event == sg.WIN_CLOSED or event == 'Close':\n",
    "#             window2.close()\n",
    "#             break  \n",
    "#         elif event == \"Build File\":\n",
    "#             writeFieldFile(w4x4,values,tmp)\n",
    "#             mapped = {}\n",
    "#             mapped[w4x4] = {}\n",
    "#             xrefs = {}\n",
    "#             notes = {}\n",
    "#             dates = {}\n",
    "#             for key,val in values.items():\n",
    "#                 print(key,val)\n",
    "#                 if isinstance(key,str) and \":\" in key:\n",
    "#                #     'LISTBOX:entityId': 'Entity Id', 0: 'Entity Id', 'NOTES:entityId':\n",
    "#                     spl = key.split(\":\")\n",
    "#                     val = val.strip()\n",
    "#                     spl[1]=spl[1].strip()\n",
    "#                     spl[0]=spl[0].strip()\n",
    "                     \n",
    "                        \n",
    "#                     if spl[0] == \"LISTBOX\":  \n",
    "#                         if val not in mapped[w4x4]:                        \n",
    "#                             mapped[w4x4][val] = {}  \n",
    "#                         mapped[w4x4][val][\"xref\"] =spl[1]\n",
    "#                         mapped[w4x4][val][\"desc\"] = tmp[spl[1]]\n",
    "#                         xrefs[spl[1]] = val\n",
    "#                     elif spl[0] == \"NOTES\":\n",
    "#                         notes[spl[1]] = val\n",
    "#                     elif spl[0] == \"DATE\":\n",
    "#                         dates[spl[1]] = val\n",
    "#             for id in notes:\n",
    "#                 xrf = xrefs[id]\n",
    "#                 mapped[w4x4][xrf][\"notes\"] = notes[id]\n",
    "#                 mapped[w4x4][xrf][\"date\"] = dates[id]\n",
    "                \n",
    "#             print(\"MAP \",mapped) \n",
    "#             with open(\"test.json\",\"w\") as jfile:\n",
    "#                 jfile.write(json.dumps(mapped))\n",
    "#             for k in mapped[w4x4].keys():\n",
    "#                 print(k,mapped[w4x4][k]['xref'],mapped[w4x4][k]['desc'])\n",
    "createFieldFile(cim4x4,list(dfExtract.columns),list(dfTransform.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a167e-6fe3-4e76-bdb4-086cac9e0d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "def traverseSearch(path: str, obj: Any,find: Any,pathl: list) -> None:\n",
    "    \"\"\"\n",
    "    Traverse the object recursively and print every path / value pair.\n",
    "    \"\"\"\n",
    "    global foundPath\n",
    "   \n",
    "    print(\"Path \",path)\n",
    "    if isinstance(obj, list):\n",
    "        for i, subnode in enumerate(obj):\n",
    "            if i == find:\n",
    "            #    print(\"Found \")\n",
    "                break\n",
    "            traverseSearch(path + f'[{i!r}]', subnode)\n",
    "    elif isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            if k == find:\n",
    "                print(\"found \")\n",
    "                print(path)\n",
    "                foundPath = path\n",
    "                break\n",
    "       #     pathl.append(k)\n",
    "            print(\"Path 2\",path)\n",
    "            traverseSearch(path + f'[{k!r}]', v,find,pathl)\n",
    "    # else:\n",
    "    #     print(path + ' => ' + f'{obj!r}')\n",
    "    \n",
    "#    print(path)\n",
    "\n",
    "def traverse(path: str, obj: Any) -> None:\n",
    "    \"\"\"\n",
    "    Traverse the object recursively and print every path / value pair.\n",
    "    \"\"\"\n",
    " #   print(\"Path \",path)\n",
    "    \n",
    "    if isinstance(obj, list):\n",
    "        for i, subnode in enumerate(obj):\n",
    "            traverse(path + f'[{i!r}]', subnode)\n",
    "    elif isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            traverse(path + f'[{k!r}]', v)\n",
    "    else:\n",
    "        print(path + ' => ' + f'{obj!r}')\n",
    "#    print(path)\n",
    "\n",
    "\n",
    "def read_file(fpath: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Read the JSON file and return its content as a Python data structure.\n",
    "    \"\"\"\n",
    "    with open(fpath, encoding='utf8') as f:\n",
    "        return json.load(f)    # type: ignore\n",
    "\n",
    "\n",
    "def processFile(fname: str) -> None:\n",
    "    \"\"\"\n",
    "    Process the given JSON file.\n",
    "    \"\"\"\n",
    "    d: Dict = read_file(fname)\n",
    "    traverse(\"root\", d)\n",
    "    \n",
    "def processDict(someDict: dict) -> None:\n",
    "    \"\"\"\n",
    "    Process the given JSON file.\n",
    "    \"\"\"\n",
    "    global path\n",
    "    d: Dict = someDict\n",
    "    print(\"d \",d)\n",
    "    traverse(\"top\", d)\n",
    "    \n",
    "def searchDict(someDict: dict,find: Any) -> None:\n",
    "    \"\"\"\n",
    "    Process the given JSON file.\n",
    "    \"\"\"\n",
    "    global foundPath\n",
    "    d: Dict = someDict\n",
    "    print(\"d \",d)\n",
    "    pathl = []\n",
    "   # path = \"top\"\n",
    "    traverseSearch(\"top\", d,find,pathl)\n",
    "    print(\"PP \",foundPath)\n",
    "    return foundPath\n",
    "\n",
    "a = {\"b\":19,\"c\":{\"d\":\"e\",\"f\":{\"g\":\"h\",\"i\":{\"j\":\"k\"}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be25a94-518b-4c1b-9183-58ecf96cdbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = searchDict(a,\"j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e037d-6360-4e56-be0a-aff0f0329b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "x = re.findall(\"\\[\",p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efc6ef-3810-4e52-b70d-1bb22852abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [ (i.start(), i.end()) for i in re.finditer('\\[', p)]\n",
    "y = [ (i.start(), i.end()) for i in re.finditer('\\]', p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426fdb7-e31f-4894-acb4-f8c6e15f57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nn in range(len(x)):\n",
    "    print(x[nn][0],y[nn][1])\n",
    "    print(p[x[nn][0]:y[nn][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad58f3e-0820-4746-b730-c9d6ce4e08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55003e9-0198-4e77-842c-e13d94318509",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c99edf-3ec4-4c80-b4c0-438f401d9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.findall(\"[\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d423e5b4-f271-4afc-96d9-8bdfc0329957",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,v in windowsReset.items():\n",
    "    b = list(v.keys())[0]\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f591c7-ff27-4d53-8c08-5579541df021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = searchDict(windowsReset,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce1bf99-7d76-4e01-9b66-eccacd10e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"b\":19,\"c\":{\"d\":\"e\",\"f\":{\"g\":\"h\",\"i\":{\"j\":\"k\"}}}}\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6c0f3-6cd6-4438-bf0c-24c37b897e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "processDict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb966c-dfc0-49a3-aa52-e52986b848ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = searchDict(a,\"j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbe98f-95cd-4c43-8b85-e1b8d10b26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13850c03-a74b-47f3-bd22-b467aa4aa571",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = a.copy()\n",
    "for val in path:\n",
    "    print(val)\n",
    "    x = x[val]\n",
    "    print(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a315f-2b5b-4037-b5c2-5b15bb0584cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd3e2fb-e693-4a7f-92b6-815d44cc3b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rich\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057a2c2-8c60-4e02-87c0-c5527dcb4553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0a028-3dc8-455f-b8cd-b9b04dd7f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[italic red]Hello[/italic red] World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a942a1-f508-479d-ac6b-d14dec7ef872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.syntax import Syntax\n",
    "\n",
    "console = Console()\n",
    "with open(\"purpose.js\", \"rt\") as code_file:\n",
    "    syntax = Syntax(code_file.read(), \"javascript\")\n",
    "console.print(syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aeb719-f666-4a3a-8928-f62378521388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4defbc3-aa7e-4fd4-9ea4-d3ebd9c171dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showTest():\n",
    "    with open(\"purpose.js\", \"rt\") as code_file:\n",
    "        syntax = Syntax(code_file.read(), \"javascript\")\n",
    "    \n",
    "    layout = [[sg.Text(f\"Log Summary\",font=\"CENTAUR 15 bold\")],\n",
    "              [sg.Button(\"Quit\")],\n",
    "              [sg.Multiline(syntax,s=(50,10),key=\"-ERRORSINGLE-\",font=\"CENTAUR 15 bold\")]\n",
    "               ]\n",
    "    \n",
    "\n",
    "#    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(\"Log Summary\",layout,finalize=True,resizable=True)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    \n",
    "     while True:\n",
    "\n",
    "         #   event, values = window2.read()\n",
    "            wid, event, values = sg.read_all_windows()\n",
    "            print(\"\\n\\n-----------------------------------\\n\")\n",
    "            print('event: ',event)\n",
    "            print(wid.Title)\n",
    "            print(wid)\n",
    "            if event == sg.WIN_CLOSED or event == 'Close':\n",
    "                window2.close()\n",
    "                break\n",
    "    \n",
    "showTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7afdaf-95eb-4c77-8b39-d5826b37508e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4557e-b61f-449f-b0cd-ee7778225296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fileCompare",
   "language": "python",
   "name": "filecompare"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
