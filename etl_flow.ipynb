{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18405b17-d473-4f5b-a49c-f5bd6d28158f",
   "metadata": {},
   "source": [
    "## Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5247b38-4a96-46a3-8945-a8fd5b731a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 run_etl.json files found\n",
      "GROUP  catalog\n",
      "GROUP  cdos\n",
      "GROUP  cdos\n",
      "GROUP  cdos\n",
      "GROUP  cdos\n",
      "GROUP  cdos\n",
      "GROUP  cdos\n",
      "GROUP  cdhe\n",
      "GROUP  dpa\n",
      "GROUP  tchd\n",
      "GROUP  boulder\n",
      "GROUP  denver\n",
      "GROUP  cdot\n",
      "GROUP  cdot\n",
      "GROUP  cdot\n",
      "GROUP  cdot\n",
      "GROUP  irs\n",
      "GROUP  dola\n",
      "GROUP  dola\n",
      "GROUP  dola\n",
      "GROUP  cdor\n",
      "GROUP  cdor\n",
      "GROUP  cdor\n",
      "GROUP  ceo\n",
      "GROUP  general\n",
      "GROUP  dora\n",
      "GGGGG  {'id': '1pVj8GwL13QtiyX7qG1xWf0kLacZwG7gV2wGT4xqmHCE', 'name': 'BIC Data Inventory and Metadata', 'createdTime': '2023-06-14T16:13:40.567Z', 'modifiedTime': '2023-08-17T03:30:49.859Z'}\n",
      "GGGGG  {'id': '1WTaOglzbSsYiHhAGguGxHQXmAGmOhfFHkGkMLowxAOA', 'name': 'BIC Data Inventory and Metadata-OLD', 'createdTime': '2021-05-19T20:34:56.598Z', 'modifiedTime': '2023-06-14T17:17:41.383Z'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5968/735637673.py:1235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event:  4x4 values:  {'-DATASET-': '', 'Group Menu': None, '-4x4-': 'w6kb-3vsj', '-ETL-': 'ETL Summary'}\n",
      "XREF DS  w6kb-3vsj Communication Methods Used in Solicitation Campaigns in Colorado\n",
      "Daetaset  Communication Methods Used in Solicitation Campaigns in Colorado\n",
      "event:  -EXTRACT- values:  {'-DATASET-': '', 'Group Menu': None, '-4x4-': 'w6kb-3vsj', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/sol_typ_entity.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/sol_typ_entity.js\\n\\n\\nload:\\n    file             :  sol_typ_entity.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  sol_typ_entity.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/sol_typ_entity.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/sol_typ_entity.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/w6kb-3vsj/rows.csv?accessType=DOWNLOAD'}\n",
      "event:  -EXTRACTANAL- values:  {'-DATASET-': '', 'Group Menu': None, '-4x4-': 'w6kb-3vsj', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/sol_typ_entity.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/sol_typ_entity.js\\n\\n\\nload:\\n    file             :  sol_typ_entity.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  sol_typ_entity.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/sol_typ_entity.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/sol_typ_entity.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/w6kb-3vsj/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-20T22:29:23.811Z\\ninfo msg: Connection to SFTP server made at 2023-08-20T22:29:24.206Z\\ndebug msg: Saving charity/sol_typ_entity.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:24.207Z\\nwarn msg: File charity/sol_typ_entity.txt not updated since 2023-08-16T19:06:16-06:00 at 2023-08-20T22:29:24.224Z\\ninfo msg: charity/sol_typ_entity.txt was successfully download to /cdos/business/nonprofit/data_source/sol_typ_entity.tsv! at 2023-08-20T22:29:24.576Z'}\n",
      "STATS  {'Entity Id': {'string': 0, 'integer': 2448, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}, 'Document Id': {'string': 2448, 'integer': 0, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}, 'Ce Fein': {'string': 0, 'integer': 0, 'float': 2448, 'boolean': 0, 'Missing': 2448, '% Missing': 100.0}, 'Org Name': {'string': 2448, 'integer': 0, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}, 'Sol Type Dscrp': {'string': 2448, 'integer': 0, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}}\n",
      "event:  -TRANSFORM- values:  {'-DATASET-': '', 'Group Menu': None, '-4x4-': 'w6kb-3vsj', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/sol_typ_entity.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/sol_typ_entity.js\\n\\n\\nload:\\n    file             :  sol_typ_entity.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  sol_typ_entity.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/sol_typ_entity.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/sol_typ_entity.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/w6kb-3vsj/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-20T22:29:23.811Z\\ninfo msg: Connection to SFTP server made at 2023-08-20T22:29:24.206Z\\ndebug msg: Saving charity/sol_typ_entity.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:24.207Z\\nwarn msg: File charity/sol_typ_entity.txt not updated since 2023-08-16T19:06:16-06:00 at 2023-08-20T22:29:24.224Z\\ninfo msg: charity/sol_typ_entity.txt was successfully download to /cdos/business/nonprofit/data_source/sol_typ_entity.tsv! at 2023-08-20T22:29:24.576Z'}\n",
      "event:  -TRANSFORMANAL- values:  {'-DATASET-': '', 'Group Menu': None, '-4x4-': 'w6kb-3vsj', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/sol_typ_entity.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/sol_typ_entity.js\\n\\n\\nload:\\n    file             :  sol_typ_entity.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  sol_typ_entity.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/sol_typ_entity.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/sol_typ_entity.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/w6kb-3vsj/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-20T22:29:23.811Z\\ninfo msg: Connection to SFTP server made at 2023-08-20T22:29:24.206Z\\ndebug msg: Saving charity/sol_typ_entity.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:24.207Z\\nwarn msg: File charity/sol_typ_entity.txt not updated since 2023-08-16T19:06:16-06:00 at 2023-08-20T22:29:24.224Z\\ninfo msg: charity/sol_typ_entity.txt was successfully download to /cdos/business/nonprofit/data_source/sol_typ_entity.tsv! at 2023-08-20T22:29:24.576Z\\n154,652 bytes Created: 2023-08-20 16:29:27.850544  file: /home/joe/bic_etl/cdos/business/nonprofit/data_transformed/sol_typ_entity.csvSTDOUT: debug msg: Program Started at 2023-08-20T22:29:27.813Z\\ndebug msg: Files to be transformed: /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:27.814Z\\ndebug msg: All items have been processed, final file is at: /home/joe/bic_etl/cdos/business/nonprofit/data_transformed/sol_typ_entity.csv at 2023-08-20T22:29:27.859Z'}\n",
      "STATS  {'entityId': {'string': 0, 'integer': 2448, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}, 'documentId': {'string': 2448, 'integer': 0, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}, 'orgName': {'string': 2448, 'integer': 0, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}, 'solTypeDscrp': {'string': 2448, 'integer': 0, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}}\n",
      "event:  -CIMAPI- values:  {'-DATASET-': '', 'Group Menu': None, '-4x4-': 'w6kb-3vsj', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/sol_typ_entity.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/sol_typ_entity.js\\n\\n\\nload:\\n    file             :  sol_typ_entity.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  sol_typ_entity.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/sol_typ_entity.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/sol_typ_entity.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/w6kb-3vsj/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-20T22:29:23.811Z\\ninfo msg: Connection to SFTP server made at 2023-08-20T22:29:24.206Z\\ndebug msg: Saving charity/sol_typ_entity.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:24.207Z\\nwarn msg: File charity/sol_typ_entity.txt not updated since 2023-08-16T19:06:16-06:00 at 2023-08-20T22:29:24.224Z\\ninfo msg: charity/sol_typ_entity.txt was successfully download to /cdos/business/nonprofit/data_source/sol_typ_entity.tsv! at 2023-08-20T22:29:24.576Z\\n154,652 bytes Created: 2023-08-20 16:29:27.850544  file: /home/joe/bic_etl/cdos/business/nonprofit/data_transformed/sol_typ_entity.csvSTDOUT: debug msg: Program Started at 2023-08-20T22:29:27.813Z\\ndebug msg: Files to be transformed: /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:27.814Z\\ndebug msg: All items have been processed, final file is at: /home/joe/bic_etl/cdos/business/nonprofit/data_transformed/sol_typ_entity.csv at 2023-08-20T22:29:27.859Z'}\n",
      "STATS  {'entityId': {'string': 0, 'integer': 2448, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}, 'documentId': {'string': 2448, 'integer': 0, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}, 'name': {'string': 2448, 'integer': 0, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}, 'communicationType': {'string': 2448, 'integer': 0, 'float': 0, 'boolean': 0, 'Missing': 0, '% Missing': 0.0}}\n",
      "event:  Column Analysis values:  {'-DATASET-': '', 'Group Menu': None, '-4x4-': 'w6kb-3vsj', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/sol_typ_entity.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/sol_typ_entity.js\\n\\n\\nload:\\n    file             :  sol_typ_entity.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  sol_typ_entity.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/sol_typ_entity.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/sol_typ_entity.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/w6kb-3vsj/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-20T22:29:23.811Z\\ninfo msg: Connection to SFTP server made at 2023-08-20T22:29:24.206Z\\ndebug msg: Saving charity/sol_typ_entity.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:24.207Z\\nwarn msg: File charity/sol_typ_entity.txt not updated since 2023-08-16T19:06:16-06:00 at 2023-08-20T22:29:24.224Z\\ninfo msg: charity/sol_typ_entity.txt was successfully download to /cdos/business/nonprofit/data_source/sol_typ_entity.tsv! at 2023-08-20T22:29:24.576Z\\n154,652 bytes Created: 2023-08-20 16:29:27.850544  file: /home/joe/bic_etl/cdos/business/nonprofit/data_transformed/sol_typ_entity.csvSTDOUT: debug msg: Program Started at 2023-08-20T22:29:27.813Z\\ndebug msg: Files to be transformed: /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:27.814Z\\ndebug msg: All items have been processed, final file is at: /home/joe/bic_etl/cdos/business/nonprofit/data_transformed/sol_typ_entity.csv at 2023-08-20T22:29:27.859Z'}\n",
      "event:  Compare 2 Data values:  {'-PNOTD-': [], '-DNOTP-': [], '-TABLECOLUMN-': []}\n",
      "HERE We GO\n",
      "event:  Get SIJ Cols values:  {'-PNOTD-': [], '-DNOTP-': [], '-TABLECOLUMN-': []}\n",
      "Tr SIJ  ['entityid', 'fein', 'name', 'nameoforganization', 'title', 'firstname', 'middlename', 'lastname', 'registranttypeabbr', 'registranttype', 'address', 'city', 'state', 'zipcode', 'zipcode4', 'mailingaddress', 'mailingcity', 'mailingstate', 'mailingzipcode', 'mailingzipcode4', 'performedaddress', 'performedcity', 'performedstate', 'performedzipcode', 'performedzipcode4', 'phone']\n",
      "LD SIJ  ['entityid', 'fein', 'name', 'nameoforganization', 'title', 'firstname', 'middlename', 'lastname', 'registranttypeabbr', 'registranttype', 'address', 'city', 'state', 'zipcode', 'zipcode4', 'mailingaddress', 'mailingcity', 'mailingstate', 'mailingzipcode', 'mailingzipcode4', 'performedaddress', 'performedcity', 'performedstate', 'performedzipcode', 'performedzipcode4', 'phone']\n",
      "event:  Full Data Column Map values:  {'-PNOTD-': [], '-DNOTP-': [], '-TABLECOLUMN-': []}\n",
      "MAP  Entity Id\n",
      "MAP  Document Id\n",
      "MAP  Ce Fein\n",
      "MAP  Org Name\n",
      "MAP  Sol Type Dscrp\n",
      "event:  Quit values:  {'-TABLEDCMAP-': []}\n",
      "event:  Quit values:  {'-PNOTD-': [], '-DNOTP-': [], '-TABLECOLUMN-': []}\n",
      "event:  Close values:  {'-DATASET-': '', 'Group Menu': None, '-4x4-': 'w6kb-3vsj', '-ETL-': 'info:\\n    directory   :  cdos/business/nonprofit\\n    group           :  cdos\\n\\n\\nextract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/sol_typ_entity.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/sol_typ_entity.js\\n\\n\\nload:\\n    file             :  sol_typ_entity.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  sol_typ_entity.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/sol_typ_entity.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\nTransform\\nnode /home/joe/bic_etl/cdos/business/nonprofit/scripts/sol_typ_entity.js\\n\\nCIM API\\nhttps://data.colorado.gov/api/views/w6kb-3vsj/rows.csv?accessType=DOWNLOAD\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-20T22:29:23.811Z\\ninfo msg: Connection to SFTP server made at 2023-08-20T22:29:24.206Z\\ndebug msg: Saving charity/sol_typ_entity.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:24.207Z\\nwarn msg: File charity/sol_typ_entity.txt not updated since 2023-08-16T19:06:16-06:00 at 2023-08-20T22:29:24.224Z\\ninfo msg: charity/sol_typ_entity.txt was successfully download to /cdos/business/nonprofit/data_source/sol_typ_entity.tsv! at 2023-08-20T22:29:24.576Z\\n154,652 bytes Created: 2023-08-20 16:29:27.850544  file: /home/joe/bic_etl/cdos/business/nonprofit/data_transformed/sol_typ_entity.csvSTDOUT: debug msg: Program Started at 2023-08-20T22:29:27.813Z\\ndebug msg: Files to be transformed: /home/joe/bic_etl/cdos/business/nonprofit/data_source/sol_typ_entity.tsv at 2023-08-20T22:29:27.814Z\\ndebug msg: All items have been processed, final file is at: /home/joe/bic_etl/cdos/business/nonprofit/data_transformed/sol_typ_entity.csv at 2023-08-20T22:29:27.859Z'}\n",
      "window MA <PySimpleGUI.PySimpleGUI.Window object at 0x7f985c851300>\n",
      "cosing  <PySimpleGUI.PySimpleGUI.Window object at 0x7f985c851300>\n",
      "window MA <PySimpleGUI.PySimpleGUI.Window object at 0x7f985c853f70>\n",
      "cosing  <PySimpleGUI.PySimpleGUI.Window object at 0x7f985c853f70>\n",
      "window MA <PySimpleGUI.PySimpleGUI.Window object at 0x7f985ca16980>\n",
      "cosing  <PySimpleGUI.PySimpleGUI.Window object at 0x7f985ca16980>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys,os,inspect\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from cronsim import CronSim\n",
    "import argparse\n",
    "import json\n",
    "import PySimpleGUI as sg\n",
    "#import PySimpleGUIWeb as sg\n",
    "import pathlib\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import re\n",
    "from shlex import split\n",
    "import webbrowser\n",
    "import subprocess\n",
    "import collections\n",
    "import pyglet,tkinter\n",
    "from pyglet import font\n",
    "\n",
    "import requests\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "global datasets\n",
    "# import OpenGL\n",
    "# from OpenGL import GLU\n",
    "font.add_file('/etc/fonts/fonts/CENTAUR.TTF')\n",
    "font='Courier 10 bold '\n",
    "bicHome = \"/home/joe/bic_etl/\"\n",
    "numWindows=0\n",
    "headerStore = {}\n",
    "\n",
    "colorPairs = [[\"#D6EAF8\",\"#85C1E9\"],[\"#b3f0ff\",\"#33d6ff\"],[\"#D5F5E3\",\"#A3E4D7\"],[\"#FCF3CF\",\"#F7DC6F\"]]\n",
    "windowsOpen = {}\n",
    "windowsOpen[\"main\"] = []\n",
    "windowsOpen[\"unique\"] = []\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def compare2Data(df,xrefs):\n",
    "    global dcols,pcols,rowColors,values,dnotpLines\n",
    "    dcols = list(df.columns)\n",
    "    pcols = list(xrefs.keys())\n",
    "    \n",
    "    wid = windowsStore[\"columnAnalysis\"]\n",
    "    rowColors = wid[\"-TABLECOLUMN-\"].metadata[1]\n",
    "    values = wid[\"-TABLECOLUMN-\"].metadata[0]\n",
    "   \n",
    "    colr1 = rowColors[0][1]\n",
    "    colr2 = rowColors[1][1]\n",
    "    \n",
    "    pnotd = []\n",
    "    dnotp = []\n",
    "    dnotpLines = {}\n",
    "\n",
    "    for col in pcols:\n",
    "        if col not in dcols:\n",
    "            pnotd.append(col)\n",
    "\n",
    "    for col in dcols:\n",
    "        if col not in pcols:\n",
    "            dnotp.append(col)\n",
    "            for line in transformProgram:\n",
    "                if line.find(col) > -1:\n",
    "                   if col in dnotpLines:\n",
    "                     dnotpLines[col].append(line)\n",
    "                   else:\n",
    "                     dnotpLines[col] = []\n",
    "                     dnotpLines[col].append(line)\n",
    "                                 \n",
    "    for nn,value in enumerate(values):    \n",
    "        if nn%2 == 0:\n",
    "            rowColor= colr1\n",
    "        else:\n",
    "            rowColor= colr2\n",
    "\n",
    "        col = value[0]\n",
    "\n",
    "        if col in pnotd:\n",
    "            rowColor = \"pink\"\n",
    "\n",
    "        colr = (nn,rowColor)\n",
    "        rowColors.append(colr)\n",
    "\n",
    "        \n",
    "    sp = \"\\n\".join(pnotd)\n",
    "    sd = \"\\n\".join(dnotp)\n",
    "    \n",
    "        \n",
    "    wid[\"-TABLECOLUMN-\"].update(row_colors=rowColors)  \n",
    "    wid[\"-PNOTD-\"].update(pnotd)    \n",
    "    wid[\"-DNOTP-\"].update(dnotp)    \n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "\n",
    "def compareWindow(stats1,df1,file1,title=\"Compare\",colorTheme=\"'Dark Green 5'\"):\n",
    "    global color1,color2\n",
    "    header_list = [\"Column\",\"% Missing\",\"Missing\",\"string\",\"integer\",\"float\",\"boolean\"]\n",
    "  \n",
    "    col_widths = [8]*len(header_list)\n",
    "    col_widths[0] = 25\n",
    "    columnSortStateTable1 = {}\n",
    "  \n",
    "\n",
    "    ## set up sort state for the column in both tables\n",
    "    for col in header_list:\n",
    "         columnSortStateTable1[col] = -1\n",
    "       \n",
    "            \n",
    "    valsFile1 = getValues(stats1,header_list)\n",
    "   \n",
    "    \n",
    "    rowFile1Colors = setRowColors(valsFile1,color1,color2,\"pink\",header_list)\n",
    "    \n",
    "    layCol1 = [[sg.Text(f\"File 1 {file1}\",font=\"CENTAUR 15\")],[sg.Text(f\"File 1 Shape {df1.shape}\",font=\"CENTAUR 15\")],\n",
    "               [sg.Table(values=valsFile1,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=20,col_widths=col_widths,font=\"CENTAUR 10\",\n",
    "                   justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                   key='-TABLEFILE-',row_colors=rowFile1Colors,headings = header_list,metadata=columnSortStateTable1)]\n",
    "               ]\n",
    "    \n",
    "\n",
    "    layout = [[sg.Button(\"Quit\")],\n",
    "    layCol1]  \n",
    "              \n",
    "    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(title,layout,finalize=True,resizable=True,metadata=[colorTheme,df1])\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableFile1 = window2['-TABLEFILE-']\n",
    "    tableFile1.bind('<Button-1>', \"Click\")\n",
    "    headerStore[tableFile1] = header_list\n",
    "    statsStore[tableFile1] = stats1\n",
    "    print(\"STATS \",stats1)\n",
    "    return window2,tableFile1,valsFile1,rowFile1Colors\n",
    "\n",
    "#############################################\n",
    "\n",
    "def dfAnalyze(df):\n",
    "    stats = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        typs = df[col].apply(type).value_counts().to_dict()\n",
    "        stats[col] = {}\n",
    "        if str in typs:\n",
    "           stats[col][\"string\"] = typs[str]\n",
    "        else:\n",
    "           stats[col][\"string\"] = 0\n",
    "\n",
    "        if int in typs:\n",
    "           stats[col][\"integer\"] = typs[int]\n",
    "        else:\n",
    "           stats[col][\"integer\"] = 0\n",
    "\n",
    "        if float in typs:\n",
    "           stats[col][\"float\"] = typs[float]\n",
    "        else:\n",
    "           stats[col][\"float\"] = 0\n",
    "\n",
    "        if bool in typs:\n",
    "           stats[col][\"boolean\"] = typs[bool]\n",
    "        else:\n",
    "           stats[col][\"boolean\"] = 0\n",
    "\n",
    "        stats[col][\"Missing\"] = df[col].isna().sum()\n",
    "        stats[col][\"% Missing\"] = round(df[col].isna().sum()/df.shape[0]*100,1)\n",
    "        \n",
    "    return stats\n",
    "\n",
    "############################################# \n",
    "\n",
    "def exceptionLog(exception,funCall):\n",
    "  exception_message = str(exception)\n",
    "  exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "  filename = os.path.split(exception_traceback.tb_frame.f_code.co_filename)[1]\n",
    "  print(f\"{exception_message} {exception_type} {funCall}, Line {exception_traceback.tb_lineno}\")\n",
    "\n",
    "###############################################################\n",
    "\n",
    "def fullDataColumnMap(cim4x4):\n",
    "    '''Map the data fields found in the source data file to all the other sources  '''\n",
    "    global missed\n",
    "    if cim4x4 in fields:\n",
    "        invc = fields[cim4x4][\"source\"].copy()\n",
    "    else:\n",
    "        invc = []\n",
    "    tfc = transformColumns.copy()\n",
    "    exc = extractColumns.copy()\n",
    "    excMissed = []\n",
    "    tfcsij = transformSijColumns.copy()\n",
    "    loadsij = loadSijColumns.copy()\n",
    "    cim = cimColumns.copy()\n",
    "    xrfo2t = xrefsO2T.copy()\n",
    "    names = []\n",
    "    columnDict = {}\n",
    "    names.append(\"BIC Inventory\")\n",
    "    names.append(\"Transform Program\")\n",
    "\n",
    "    names.append(\"Transform - Data\")\n",
    "    names.append(\"CIM - Data\")\n",
    "    names.append(\"Transform - SIJ\")\n",
    "    names.append(\"Load - SIJ\")\n",
    "\n",
    "    for k in exc:\n",
    "        print(\"MAP \",k)\n",
    "    #for k,v in xrefsO2T.items():\n",
    "        columnDict[k] = []\n",
    "        nhit=0\n",
    "        v=\"\"\n",
    "        if k in invc:\n",
    "            v=k\n",
    "            vv=k\n",
    "            invc.remove(k)\n",
    "            nhit+=1\n",
    "        else:\n",
    "            vv=\"\"\n",
    "        columnDict[k].append(vv)\n",
    "        \n",
    "        if k in xrfo2t:\n",
    "            v = xrfo2t[k]\n",
    "            vv=v\n",
    "            del xrfo2t[k]\n",
    "            nhit+=1\n",
    "        else:\n",
    "            vv = \"\"\n",
    "        columnDict[k].append(vv)  \n",
    "\n",
    "   \n",
    "        if v in tfc:\n",
    "           tfc.remove(v)\n",
    "           cc = v\n",
    "           nhit+=1\n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "\n",
    "\n",
    "        if v in cim:\n",
    "           cim.remove(v)\n",
    "           cc = v\n",
    "           nhit+=1            \n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "\n",
    "\n",
    "\n",
    "        if v.lower() in tfcsij:\n",
    "           tfcsij.remove(v.lower())\n",
    "           cc = v.lower()\n",
    "           nhit+=1            \n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "\n",
    "        if v.lower() in loadsij:\n",
    "           loadsij.remove(v.lower())\n",
    "           cc = v.lower()\n",
    "           nhit+=1\n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "        \n",
    "        if nhit == 0:\n",
    "            excMissed.append(k)\n",
    "        \n",
    "\n",
    "    a = pd.DataFrame(columnDict).T\n",
    "    a.columns = names\n",
    "    a.reset_index(inplace=True)\n",
    "    values = a.values.tolist()\n",
    "    cols = list(a.columns)\n",
    "   \n",
    "    missed = {}\n",
    "    missed[\"Extract - Data\"] = excMissed\n",
    "    missed[\"BIC Inventory\"] = invc\n",
    "    missed[\"Transform Program\"] = list(xrfo2t.keys())\n",
    "    missed[\"Transform - Data\"] = tfc\n",
    "    missed[\"CIM - Data\"] = cim\n",
    "    missed[\"Transform - SIJ\"] = tfcsij\n",
    "    missed[\"Load - SIJ\"] = loadsij\n",
    "    \n",
    "    \n",
    " #   missed = [invc,list(xrfo2t.keys()),tfc,cim,tfcsij,loadsij]\n",
    "    return cols,values,missed\n",
    "        \n",
    "\n",
    "###############################################################\n",
    "def getFilesClicked(file,window):\n",
    "#         if len(values[\"-FILE1-\"]) > 0:\n",
    "#             file = values[\"-FILE1-\"]\n",
    "#         elif len(values[\"-WEB1-\"]) > 0:\n",
    "#             file = values[\"-WEB1-\"]\n",
    "      \n",
    "        df = getFile(\"Local\",file,window)\n",
    "        stats = dfAnalyze(df)\n",
    "\n",
    "        return df,stats\n",
    "\n",
    "####################################################################\n",
    "       \n",
    "def getFile(how,file,WindowP):\n",
    "    \n",
    "    if how == \"Local\":\n",
    "        if file[-3:].lower() == \"tsv\":\n",
    "            delim = \"\\t\"\n",
    "            df=pd.read_csv(file,encoding=\"latin\",delimiter=delim)\n",
    "        elif file[-4:].lower() == \"xlsx\":\n",
    "            df=pd.read_excel(file,engine=\"openpyxl\")\n",
    "        else:\n",
    "            try:\n",
    "                df=pd.read_csv(file)\n",
    "            except Exception as err:\n",
    "                print(\"Error, trying with encoding=latin\")\n",
    "                df=pd.read_csv(file,encoding=\"latin\")\n",
    "    elif how == \"Fetch\":\n",
    "      \n",
    "  #      file=values[\"-WEB-\"]\n",
    "      #  getPrevFiles(2,file)\n",
    "\n",
    "  #      windowP[\"-PINFO-\"].update(f\"START reading WEB File:{file}:\")\n",
    "        df=pd.read_csv(file)\n",
    "      \n",
    "  #      windowP[\"-PINFO-\"].update(f\"FINISHED reading WEB File:{file}:\")\n",
    "   \n",
    "    stats = dfAnalyze(df)\n",
    "        \n",
    "    return df,stats\n",
    "\n",
    "############################################################\n",
    "\n",
    "def getRowClicked(table,columns):\n",
    "    col=\"\"\n",
    "    e = table.user_bind_event \n",
    "    region = table.Widget.identify('region', e.x, e.y)\n",
    "    if region == 'heading':\n",
    "        row = 0\n",
    "    elif region == 'cell':\n",
    "        row = int(table.Widget.identify_row(e.y))  \n",
    "        col = columns[row-1][0]\n",
    "        \n",
    "    return row,col    \n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def getRowClickedUN(table):\n",
    "    val=\"\"\n",
    "    data = dataStore[table]\n",
    "    e = table.user_bind_event \n",
    "    region = table.Widget.identify('region', e.x, e.y)\n",
    "    if region == 'heading':\n",
    "        row = 0\n",
    "    elif region == 'cell':\n",
    "        row = int(table.Widget.identify_row(e.y))  \n",
    "        val = data[row-1][0]\n",
    "        print(\"Un VAL CLICKED \",val)\n",
    "    return row,val    \n",
    "\n",
    "##########################################################\n",
    "\n",
    "def getSijColumns(file):\n",
    "    '''Get the fields for both teh contrile file content and the ftp control file content '''\n",
    "    global transformSijColumns,loadSijColumns\n",
    "    with open(\"/home/joe/bic_etl/cdos/business/nonprofit/scripts/datasync/char_paid_solicitors.sij\") as fin:\n",
    "        lines = fin.readlines()\n",
    "        line = lines[0]\n",
    "        ss = json.loads(line)\n",
    "        cfc = json.loads(ss[\"controlFileContent\"])\n",
    "        transformSijColumns = cfc[\"csv\"][\"columns\"]\n",
    "        ftp = json.loads(ss[\"ftpControlFileContent\"])\n",
    "        loadSijColumns = ftp['csv']['columns']\n",
    "\n",
    "#         for col in transformColumns:\n",
    "#             if col in loadColumns:\n",
    "#                 hit+=1\n",
    "#             else:\n",
    "#                 miss+=1\n",
    "\n",
    "#         for col in loadColumns:\n",
    "#             if col in transformColumns:\n",
    "#                 hit+=1\n",
    "#             else:\n",
    "#                 miss+=1\n",
    "\n",
    "# ##########################################################\n",
    "\n",
    "def getValues(stats,header):\n",
    "\n",
    "    statsVals=[]\n",
    "    for col in sorted(stats.keys()):\n",
    "         vals=[]\n",
    "         vals.append(col)\n",
    "         for k in header[1:]:\n",
    "            vals.append(stats[col][k.strip()])\n",
    "         statsVals.append(vals)\n",
    "    return statsVals     \n",
    "\n",
    "##############################################################\n",
    "\n",
    "def getXrefs():\n",
    "    '''Reads the Inventory google sheet and gets the datasets title and cross-refs it to the Socrata 4x4 id.  Also\n",
    "    gets the fields by 4x4 dataset id and by the title'''\n",
    "    scope = ['https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "             \"https://www.googleapis.com/auth/drive.file\",\n",
    "                  \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json',\n",
    "     scope)\n",
    "    client = gspread.authorize(creds)\n",
    "\n",
    "    gc = gspread.service_account(\"./client_secret.json\")\n",
    "    for gg in gc.list_spreadsheet_files():\n",
    "         print(\"GGGGG \",gg)\n",
    "    # https://docs.google.com/spreadsheets/d/1WTaOglzbSsYiHhAGguGxHQXmAGmOhfFHkGkMLowxAOA/edit?usp=sharing\n",
    "    sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "        'Maintenance_Framework')\n",
    "    repo_sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "        'MetadataRepository')\n",
    "    fields_sheet = client.open('BIC Data Inventory and Metadata').worksheet(\n",
    "        'Field Descriptions')\n",
    "    \n",
    "    \n",
    "#     sheet = client.open('https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/').worksheet(\n",
    "#         'Maintenance_Framework')\n",
    "#     repo_sheet = client.open('https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/').worksheet(\n",
    "#         'MetadataRepository')\n",
    "    \n",
    "#     fields_sheet = client.open('https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/').worksheet(\n",
    "#         'Field Descriptions')\n",
    "\n",
    "    dfRepo = pd.DataFrame(repo_sheet.get_all_records(head=3))\n",
    "    xrefsBy4x4 = {}\n",
    "    xrefsByTitle = {}\n",
    "\n",
    "    for index,row in dfRepo[['Dataset Title','Socrata Link']].iterrows():\n",
    "        xrefsByTitle[row['Dataset Title']] = row['Socrata Link']\n",
    "        xrefsBy4x4[row['Socrata Link']] = row['Dataset Title']\n",
    "        \n",
    "    dfFields = pd.DataFrame(fields_sheet.get_all_records(head=1))\n",
    "    fields = {}\n",
    "    for index,row in dfFields.iterrows():\n",
    "        s4x4 = row[\"Socrata ID\"]\n",
    "        of = row[\"Source Field Name\"]\n",
    "        tf = row[\"Full Field Name\"]\n",
    "        af = row[\"API Field Name\"]\n",
    "        if s4x4 in fields:\n",
    "            fields[s4x4][\"source\"].append(of)\n",
    "            fields[s4x4][\"cim\"].append(tf)\n",
    "            fields[s4x4][\"api\"].append(af)\n",
    "        else:\n",
    "            fields[s4x4] = {}\n",
    "            fields[s4x4][\"source\"] = []\n",
    "            fields[s4x4][\"cim\"] = []\n",
    "            fields[s4x4][\"api\"] = []\n",
    "            \n",
    "            fields[s4x4][\"source\"].append(of)\n",
    "            fields[s4x4][\"cim\"].append(tf)\n",
    "            fields[s4x4][\"api\"].append(af)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return xrefsBy4x4,xrefsByTitle,fields\n",
    "\n",
    "#############################################\n",
    "\n",
    "def go_deeper(aDict,value,nit):\n",
    "    nit+=1\n",
    "    for k, v in aDict.items():\n",
    "         if not bool(v):            \n",
    "             aDict[k] = []\n",
    "             aDict[k].append(value)\n",
    "         elif isinstance(v,list):\n",
    "             aDict[k].append(value)\n",
    "         else:\n",
    "             go_deeper(v,value,nit)\n",
    "   \n",
    "    return aDict\n",
    "\n",
    "###################################################    \n",
    "\n",
    "def init():\n",
    "    global dataSetsEtl,datasets,groupMenu\n",
    "    groups = []\n",
    "    desktop = pathlib.Path(\"/home/joe/bic_etl\")\n",
    "    runEtls = []\n",
    "    dataSets = []\n",
    "    info = {}\n",
    "    # .rglob() produces a generator too\n",
    "    desktop.rglob(\"*\")\n",
    "    files = list(desktop.rglob(\"*\"))\n",
    "# Which you can wrap in a list() constructor to materialize\n",
    "    for ff in files:\n",
    "\n",
    "            if (str(ff).split(\"/\")[-1] == \"run_etl.json\"):     \n",
    "                a=str(ff).split(\"/\")\n",
    "                m = a.index(\"bic_etl\")\n",
    "                b = a[m+1:-1]\n",
    "                ll = splitL(b)\n",
    "                groups.append(ll)\n",
    "                runEtls.append(ff)\n",
    "            \n",
    "    print(f\"{len(runEtls)} run_etl.json files found\")    \n",
    "    \n",
    "    dataSets = []\n",
    "    groups = []\n",
    "    for file in runEtls:\n",
    "      f = open(file,\"r\")\n",
    "      data = json.load(f)\n",
    "      # print(file)\n",
    "      # print(\"----\")\n",
    "      a=str(file).split(\"/\")\n",
    "      m = a.index(\"bic_etl\")\n",
    "      b = a[m+1:-1]\n",
    "      group = b[0]\n",
    "      ll = splitL(b)\n",
    "      bdir = \"/\".join(b)  \n",
    "      print(\"GROUP \",group)\n",
    "      \n",
    "    #  groups.append(ll)\n",
    "      for val in data:\n",
    "            if \"title\" in val:\n",
    "                  title=val[\"title\"]\n",
    "                  info[title]={}\n",
    "                  info[title][\"directory\"] = bdir\n",
    "                  info[title][\"group\"] = group\n",
    "                \n",
    "    #              print(title,ll)\n",
    "                  nit=0\n",
    "                  ll = go_deeper(ll,title,nit)\n",
    "             #     info[title][\"groups\"] = ll\n",
    "            \n",
    "     #             print(ll)\n",
    "     #             groups.append(ll)\n",
    "            dataSets.append(val)\n",
    "    #  print(\"FF \",ll) \n",
    "      groups.append(ll)\n",
    "\n",
    "    datasets = []\n",
    "    dataSetsEtl={}\n",
    "    for val in dataSets:\n",
    "        if \"title\" in val:\n",
    "          datasets.append(val[\"title\"])\n",
    "          title=val[\"title\"]\n",
    "          dataSetsEtl[title] = {}  \n",
    "          dataSetsEtl[title][\"info\"] = {}\n",
    "          dataSetsEtl[title][\"info\"][\"directory\"] = info[title][\"directory\"]\n",
    "          dataSetsEtl[title][\"info\"][\"group\"] = info[title][\"group\"]\n",
    "     #     dataSetsEtl[title][\"info\"][\"groups\"] = info[title][\"groups\"]\n",
    "            \n",
    "        \n",
    "            \n",
    "          for k,v in val.items():\n",
    "          #      print(k,v)\n",
    "                if k != \"title\":\n",
    "                    dataSetsEtl[title][k] = {}\n",
    "                    if isinstance(v,dict):\n",
    "                        for k1,v1 in v.items():\n",
    "                            dataSetsEtl[title][k][k1]=v1\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "    groupMenu = ['Groups',\n",
    "     ['boulder',\n",
    "      ['Restaurant Inspections in Boulder Colorado'],\n",
    "      'catalog',\n",
    "      ['CIM Catalog Download'],\n",
    "      'cdhe',\n",
    "      ['Enrollment Demographics for Post-Secondary Graduates in Colorado',\n",
    "       'Post-Secondary Financial Aid Demographics in Colorado'],\n",
    "      'cdor',[\n",
    "      'revenue_marijuana',\n",
    "      ['Marijuana Sales by County in Colorado',\n",
    "       'State Retail Marijuana Sales Tax Revenue by County in Colorado',\n",
    "       'Marijuana Tax and Fee Revenue in Colorado',\n",
    "       'Marijuana Sales Revenue in Colorado'],\n",
    "      'retail_reports',\n",
    "      ['Retail Sales Tax Return History in Colorado',\n",
    "       'Retail Reports by City in Colorado',\n",
    "       'Retail Reports by County in Colorado',\n",
    "       'Retail Reports by Industry and City in Colorado',\n",
    "       'Retail Reports by Industry and County in Colorado',\n",
    "       'Retail Reports by Industry in Colorado'],\n",
    "      'regulations_liquor',\n",
    "      ['Liquor Permits for Special Events in Colorado',\n",
    "       'Liquor Compliance Check Statistics in Colorado',\n",
    "       'Liquor Licenses in Colorado',\n",
    "       'Recently Approved Liquor Licenses in Colorado',\n",
    "       'Recently Expired and Surrendered Liquor Licenses in Colorado',\n",
    "       'Sales Rooms in Colorado',\n",
    "       'Manufacturer Temporary Sales Room Permits in Colorado']\n",
    "      ],\n",
    "      'cdos',[\n",
    "      'health',\n",
    "      ['Durable Medical Equipment Suppliers in Colorado'],\n",
    "      'government',\n",
    "      ['Current Notaries in Colorado'],\n",
    "      'business',[\n",
    "      'ucc',\n",
    "      ['Uniform Commercial Code (UCC) Collateral Information in Colorado',\n",
    "       'Uniform Commercial Code (UCC) Debtor Information in Colorado',\n",
    "       'Uniform Commercial Code (UCC) Filing Information in Colorado',\n",
    "       'Secured Party Information in Colorado'],\n",
    "      'business',\n",
    "      ['Business Entities in Colorado',\n",
    "       'Business Entity Transaction History',\n",
    "       'Trademarks for Businesses in Colorado',\n",
    "       'Trade Names for Businesses in Colorado',\n",
    "       'Master List in Colorado'],\n",
    "      'nonprofit',\n",
    "      ['Federal Tax-Exempt Subsection Codes in Colorado',\n",
    "       'Registration for Charities, Paid Solicitors, Professional Fundraising Consultants, and for-profit Public Benefit Corporations in Colorado',\n",
    "       'Charitable Organizations’ Offices in Colorado',\n",
    "       'Other State Solicitation of Charities’ Registrants in Colorado',\n",
    "       'Charitable Purpose of the Charity in Colorado',\n",
    "       'Paid Solicitor Solicitation Notices in Colorado',\n",
    "       'Campaign Reports for Solicitation Notices to Charities in Colorado',\n",
    "       'Solicitation Campaign Supervisors Listed on Solicitation Notices in Colorado',\n",
    "       'Charity Extension Requests',\n",
    "       'Persons Associated with Charitable Organizations, Paid Solicitors, and Professional Fundraising Consultants in Colorado',\n",
    "       'Other Names a Registered Entity Uses to Solicit Contributions',\n",
    "       'Paid Solicitors Disclosed on Charity Registration Forms in Colorado',\n",
    "       'Charitable Solicitation Call Center Locations in Colorado',\n",
    "       'Charities Solicitation Type by Solicitation in Colorado',\n",
    "       'Communication Methods Used in Solicitation Campaigns in Colorado']\n",
    "      ],\n",
    "      'lobbyist',\n",
    "      ['Directory of Lobbyists in Colorado',\n",
    "       'Directory of Lobbyist Clients in Colorado',\n",
    "       'Expenses for Lobbyists in Colorado',\n",
    "       'Characterization of Lobbyist Clients in Colorado',\n",
    "       'Subcontractors for Lobbyists in Colorado',\n",
    "       'Bill Information and Position with Income of Lobbyist in Colorado']\n",
    "      ],\n",
    "      'cdot',[\n",
    "      'transportation_road_attributes',\n",
    "      ['Highway Milepoints in Colorado',\n",
    "       'Highway Mileposts in Colorado',\n",
    "       'Highway Routes in Colorado',\n",
    "       'Highway Routes in Colorado',\n",
    "       'Local Roads in Colorado',\n",
    "       'Major Roads in Colorado',\n",
    "       'Scenic Byways in Colorado'],\n",
    "      'tops',\n",
    "      ['CDOT Expenses', 'CDOT Revenues', 'CDOT Payroll'],\n",
    "      'natural_resources',\n",
    "      ['Lakes in Colorado', 'Streams in Colorado'],\n",
    "      'transportation_infrastructure',\n",
    "      ['Airports in Colorado',\n",
    "       'Cities in Colorado',\n",
    "       'Counties in Colorado',\n",
    "       'Railroads in Colorado']\n",
    "      ],\n",
    "      'ceo',[\n",
    "      'useia',\n",
    "      ['Gasoline Prices in Colorado', 'Natural Gas Prices in Colorado']\n",
    "      ],\n",
    "      'denver',\n",
    "      ['Temporary Outdoor Expansions for Restaurants in Denver, Colorado'],\n",
    "      'dola',[\n",
    "      'special_districts',\n",
    "      ['Metro Districts in Colorado',\n",
    "       'Parks and Rec Districts in Colorado',\n",
    "       'Fire Districts in Colorado',\n",
    "       'Hospital Districts in Colorado',\n",
    "       'Water and Sanitation Districts in Colorado',\n",
    "       'Library Districts in Colorado',\n",
    "       'School Districts in Colorado',\n",
    "       'Soil Districts in Colorado',\n",
    "       'Cemetery Districts in Colorado',\n",
    "       'All Special Districts in Colorado'],\n",
    "      'boundaries',\n",
    "      ['Municipal Annexations in Colorado', 'Municipal Boundaries in Colorado'],\n",
    "      'demographics',\n",
    "      ['Population Projections in Colorado',\n",
    "       'Race Estimates in Colorado',\n",
    "       'Race Forecast in Colorado']\n",
    "      ],\n",
    "      'dora',[\n",
    "      'regulations',\n",
    "      ['Licensed Real Estate Professionals in Colorado',\n",
    "       'Professional and Occupational Licenses in Colorado']\n",
    "      ],\n",
    "      'dpa',\n",
    "      ['DPA Tops Data'],\n",
    "      'irs',\n",
    "      ['Purpose and Operational Size of Charities Operating in Colorado',\n",
    "       'Fundraising Revenue of Charities Operating in Colorado',\n",
    "       'Total Revenue of Charities Operating in Colorado',\n",
    "       'IRS Filing Information for Charities Operating in Colorado',\n",
    "       'Total Revenue and Types of Art for Charities Operating in Colorado',\n",
    "       'Conservation Easements for Charities Operating in Colorado',\n",
    "       'Activities of Charities Operating in Colorado',\n",
    "       'Expenses of Charities Operating in Colorado',\n",
    "       'Expenses of Charities Operating in Colorado'],\n",
    "      'tchd',\n",
    "      ['Restaurant Inspections in Tri-County Colorado']]]\n",
    "\n",
    "    return sorted(datasets)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def map4x4(row):\n",
    "    \n",
    "    if isinstance(row[\"Data Link\"],str) and  len(row[\"Data Link\"]) == 9 and re.findall( \"\\w{4}-\\w{4}\",row[\"Data Link\"]):\n",
    "  #      link = '<a href=\"https://data.colorado.gov/dataset/{}\">{}</a>'.format(row[\"Data Link\"],row[\"Data Link\"])\n",
    "        \n",
    "        link = 'https://data.colorado.gov/dataset/{}'.format(row[\"Data Link\"])\n",
    "    else:\n",
    "        link = \"\"\n",
    "        \n",
    "    return link\n",
    "    \n",
    "#####################################################################\n",
    "\n",
    "def runETL(k):\n",
    "    global extract,a,string,dataSetsEtl\n",
    "    text2 = \"\"\n",
    "  #  print(k)\n",
    "    directory = \"\"\n",
    "    group = \"\"\n",
    "    if \"info\" in dataSetsEtl[k]:\n",
    "        if \"directory\" in dataSetsEtl[k][\"info\"]:\n",
    "            directory = dataSetsEtl[k][\"info\"][\"directory\"]\n",
    "            group = dataSetsEtl[k][\"info\"][\"group\"]\n",
    "            \n",
    "## Build Summary Text string\n",
    "    for ky1 in dataSetsEtl[k].keys():\n",
    "        text2+=f\"{ky1}:\\n\" \n",
    "        for k2,v2 in dataSetsEtl[k][ky1].items(): \n",
    "            sl = 10 - len(k2)\n",
    "            s = \" \"*sl\n",
    "        \n",
    "            if isinstance(v2,list) == False:\n",
    "                text2+=f\"    {k2:10s}{s} :  {v2}\\n\"\n",
    "            else:\n",
    "                text2+=f\"    {k2:10s}{s} : {v2[0]}\\n\"\n",
    "                if len(v2) > 1:\n",
    "                    for val in v2[1:]:\n",
    "                        text2+= f\"                   {s} : {val}\\n\"\n",
    "        text2+=f\"\\n\\n\"\n",
    "## Build actions\n",
    "    extract = \"\"\n",
    "    if 'extract' in dataSetsEtl[ds]:\n",
    "        if (dataSetsEtl[ds]['extract']['language'] == 'node'):\n",
    "            pgm =  dataSetsEtl[ds]['extract']['file']\n",
    "            options=\"\"\n",
    "            if 'options' in dataSetsEtl[ds]['extract']:\n",
    "\n",
    "                for opts in dataSetsEtl[ds]['extract']['options']:\n",
    "                    options+= f\" {opts}\" \n",
    "            extract = f\"node {bicHome}{pgm} {options}\"\n",
    "        #    print(extract)\n",
    "    transform=\"\"    \n",
    "    if 'transform' in dataSetsEtl[ds]:\n",
    "        \n",
    "        if dataSetsEtl[ds][\"transform\"][\"language\"] == \"node\":\n",
    "            ff=dataSetsEtl[ds][\"transform\"][\"file\"]\n",
    "            transform=f\"node {bicHome}{directory}/{ff}\"\n",
    "            \n",
    "        else:\n",
    "            file=\"\"        \n",
    "        \n",
    "    text2+=f\"\\n\\nActions Strings\\nExtract\\n{extract}\\n\\nTransform\\n{transform}\"\n",
    "        \n",
    "    return text2,extract,transform\n",
    "    \n",
    "#############################################\n",
    "\n",
    "def setRowColors(lst,col1,col2,colsp,header):\n",
    "    count=0\n",
    "    colors = {}\n",
    "    # print(\"SRC head \",header)\n",
    "    # print(\"SRC list\",lst)\n",
    "\n",
    "    nrec = header.index(\"% Missing\")\n",
    "    for vals in lst:\n",
    "        key = vals[0]\n",
    "        if count%2 == 0:\n",
    "            colors[key] = col1\n",
    "        else:\n",
    "            colors[key] = col2\n",
    "        if vals[nrec] > 99.0:\n",
    "           \n",
    "            colors[key] = colsp\n",
    "        count+=1\n",
    "    colTab = []\n",
    "    for key,colr in colors.items():\n",
    "        colTab.append(colr)\n",
    "    rowNums = [num for num in range(0,len(colTab)+1)]\n",
    "    colText = [\"black\"]*len(colTab)\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "  \n",
    "    return colrw\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def setRowColorsGeneric(lst,col1,col2):\n",
    "    count=0\n",
    "    rowNums=[]\n",
    "    colTab=[]\n",
    "\n",
    "    for vals in lst:       \n",
    "        if count%2 == 0:\n",
    "            colTab.append(col1)\n",
    "        else:\n",
    "            colTab.append(col2)\n",
    "        rowNums.append(count)\n",
    "        count+=1\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "  \n",
    "    return colrw\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def showDfRecs(df1,colUn,val,windowP,title=\"DF Unique Record Values\"):\n",
    "    global color1,color2\n",
    "    header_list = list(df1.columns)\n",
    "  \n",
    "    col_widths = [8]*len(header_list)\n",
    " #   col_widths[0] = 25\n",
    "    columnSortStateTable1 = {}\n",
    "  \n",
    "\n",
    "    ## set up sort state for the column in both tables\n",
    "    for col in header_list:\n",
    "        columnSortStateTable1[col] = -1\n",
    "       \n",
    "            \n",
    "#    valsFile1 = getValues(stats1,header_list)\n",
    "    values = df1.values.tolist()\n",
    "    \n",
    "    rowFile1Colors = setRowColorsGeneric(values,color1,color2)\n",
    "    \n",
    "    layout = [[sg.Text(f\"Column: \",font=\"CENTAUR 10\"),\n",
    "               sg.Text(f\"{colUn}\",font=\"CENTAUR 15\")],\n",
    "              [sg.Text(f\"Unique Value: \",font=\"CENTAUR 10\"),\n",
    "               sg.Text(f\"{val}\",font=\"CENTAUR 15\")],\n",
    "               [sg.Button(\"Quit\")],\n",
    "               [sg.Table(values=values,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=20,col_widths=col_widths,font=\"CENTAUR 10\",\n",
    "                   justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                   key='-TABLEFILE-',row_colors=rowFile1Colors,headings = header_list,metadata=columnSortStateTable1)]\n",
    "               ]\n",
    "\n",
    "    colorTheme = windowP.metadata[0]          \n",
    "#    sg.theme(colorTheme)     \n",
    "    window2 = sg.Window(title,layout,finalize=True,resizable=True,metadata=[colorTheme,df1])\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableFile1 = window2['-TABLEFILE-']\n",
    "    tableFile1.bind('<Button-1>', \"Click\")\n",
    "    headerStore[tableFile1] = header_list\n",
    "    return window2,tableFile1,values,rowFile1Colors\n",
    "\n",
    "###################################################\n",
    "\n",
    "def splitL(data):\n",
    "    if data:\n",
    "        head, *tail = data  # This is a nicer way of doing head, tail = data[0], data[1:]\n",
    "        return {head: splitL(tail)}\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#############################################\n",
    "\n",
    "def stringArgs(string):\n",
    "#  This is set to decode the extract string to get the location and name of the \n",
    "#  extracted data file\n",
    "    h =split(string)\n",
    "    inf = h.index(\"-f\")\n",
    "    inf = h[inf+1]\n",
    "    ot = h.index(\"-a\")\n",
    "    ot = h[ot+1]\n",
    "    of = h.index(\"-o\")\n",
    "    of = h[of+1]\n",
    "    inf=inf.replace(inf[-4:],ot)\n",
    "    f = inf.split(\"/\")\n",
    "    finalFile = f\"{bicHome}{of}{f[-1]}\"\n",
    "    return finalFile\n",
    "\n",
    "######################################################    \n",
    "\n",
    "def sortTable(row,stats,table,event,header):\n",
    "    \n",
    "        e = table.user_bind_event \n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        if region == 'heading':\n",
    "            row = 0\n",
    "        elif region == 'cell':\n",
    "            row = int(table.Widget.identify_row(e.y))\n",
    "   \n",
    "        if row == 0:\n",
    "            colSortState = table.metadata\n",
    "            colClicked = int(table.Widget.identify_column(e.x)[1:])\n",
    "            header = headerStore[table]\n",
    "            \n",
    "            statClicked = header[colClicked-1].strip()\n",
    "           \n",
    "            colSortState[statClicked]*=-1\n",
    "            if colSortState[statClicked] == -1:\n",
    "                sortAsc=False\n",
    "            else:\n",
    "                sortAsc=True\n",
    "            if colClicked > 1:  # user number sort\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[1][statClicked],reverse=sortAsc))\n",
    "            else:\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[0],reverse=sortAsc))\n",
    "\n",
    "\n",
    "            statsVals=[]\n",
    "            for col in statsS:\n",
    "                 vals=[]\n",
    "                 vals.append(col)\n",
    "                 for k in header[1:]:\n",
    "                    vals.append(statsS[col][k.strip()])\n",
    "                 statsVals.append(vals)\n",
    "           # slen= len(statsVals)\n",
    "#             colorsTable = setRowColors(statsVals,\"#b3f0ff\",\"#33d6ff\",\"pink\",header_list)\n",
    "\n",
    "#             window['-TABLE-'].update(values=statsVals,row_colors=colorsTable)\n",
    "        \n",
    "        return statsVals,colSortState\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def showDFUN(col,unq,windowParent,colr1,colr2,colorTheme,title=\"\"):\n",
    "    global dataStore\n",
    "    valuesUNQ = list(zip(unq.index.tolist(),unq.tolist()))\n",
    "    hUNQ = []\n",
    "    hUNQ.append(\"Values\")\n",
    "    hUNQ.append(\"Count\")\n",
    "\n",
    "    \n",
    "    sortState = {}\n",
    "    for val in hUNQ:\n",
    "        sortState[val]=-1\n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Showing unique Values for Column\"),sg.Text(f\" {col}\",text_color=\"white\",font='Courier 15 bold '),sg.Text(f\" and Reg Ex\",text_color=\"white\",font='Courier 10 bold ')],\n",
    "                \n",
    "                   [sg.Button('Quit')],\n",
    "            \n",
    "                   [sg.Button('Write Unique'),\n",
    "                    sg.Table(values=valuesUNQ,\n",
    "                       background_color=colr1,vertical_scroll_only=False,col_widths=60,font='Courier 10 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',alternating_row_color=colr2,\n",
    "                       key='-TABLE-', headings = hUNQ,metadata=sortState)]\n",
    "            ]\n",
    "    sg.theme(colorTheme)    \n",
    "    window2 = sg.Window(f\"Unique for {title}\", layout2,finalize=True,resizable=True, grab_anywhere=False,metadata=[windowParent,col])\n",
    "\n",
    "    table = window2['-TABLE-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    dataStore[table]=valuesUNQ\n",
    "    \n",
    "    return window2,table,valuesUNQ,hUNQ\n",
    "\n",
    "############################################################\n",
    "\n",
    "def showColAnal(xrefsO2T,xrefsT2O,colr1,colr2):\n",
    "    global dataStore\n",
    "    values=[]\n",
    "    header = [\"Original Column\",\"Transformed Column\"]\n",
    "    for col in sorted(xrefsO2T.keys()):\n",
    "        tmp = [col,xrefsO2T[col]]\n",
    "        values.append(tmp)\n",
    "    \n",
    "    rowColors = setRowColorsGeneric(values,colr1,colr2)\n",
    "    \n",
    "    sortState = {}\n",
    "    for val in header:\n",
    "        sortState[val]=-1\n",
    "        \n",
    "    \n",
    "    a = [[sg.Text(\"Columns in Program NOT in Data\",font='Courier 10 bold ',justification=\"left\")],\n",
    "         [sg.Listbox(\"\",font='Courier 15 bold ',horizontal_scroll=True ,size=(20,5),key=\"-PNOTD-\")]] \n",
    "    \n",
    "    d = sg.Column(a)\n",
    "    \n",
    "    b = [[sg.Text(\"Columns in Data NOT in Program\",font='Courier 10 bold ',justification=\"left\")],\n",
    "         [sg.Listbox(\"\",font='Courier 15 bold ' ,enable_events=True,horizontal_scroll=True ,size=(20,5),key=\"-DNOTP-\")]] \n",
    "    e = sg.Column(b)\n",
    "    \n",
    "    c = [d,sg.VerticalSeparator(color=\"black\"),e]\n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Original COlumns Transformed to Columns\")],\n",
    "                   [sg.Button(\"Compare 2 Data\"),sg.Button(\"Get SIJ Cols\"),sg.Button(\"Full Data Column Map\")],\n",
    "                   [sg.Button('Quit')],\n",
    "                   [c],\n",
    "                   [ sg.Table(values=values,\n",
    "                       vertical_scroll_only=False,col_widths=60,font='Courier 10 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',row_colors=rowColors,\n",
    "                       key='-TABLECOLUMN-', headings = header,num_rows=20,\n",
    "                       metadata=[values,rowColors,sortState])]\n",
    "                ]\n",
    "#    sg.theme(colorTheme)    \n",
    "    window2 = sg.Window(f\"Orig vs Trans Column Analysis\", layout2,finalize=True,resizable=True, grab_anywhere=False,metadata=\"nothing\")\n",
    "\n",
    "    table = window2['-TABLECOLUMN-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    dataStore[table]=values\n",
    "    headerStore[table]=header\n",
    "    windowsStore[\"columnAnalysis\"] = window2   \n",
    "    return window2,table,values,header\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def showFullDataColMap(cols,vals):\n",
    "    \n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Full Data Columns Map\")],\n",
    "                   [sg.Button('Quit')],\n",
    "                   [sg.Button('Show Missing Fields')],\n",
    "                   [ sg.Table(values=vals,\n",
    "                       vertical_scroll_only=False,col_widths=60,font='Courier 15 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',row_colors=rowColors,\n",
    "                       key='-TABLEDCMAP-', headings = cols,num_rows=20,\n",
    "                       metadata=[vals])]\n",
    "                ]\n",
    "        \n",
    "    window2 = sg.Window(f\"Orig vs Trans Column Analysis\", layout2,finalize=True,resizable=True, grab_anywhere=False,metadata=\"nothing\")\n",
    "\n",
    "    table = window2['-TABLEDCMAP-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    dataStore[table]=values\n",
    "    headerStore[table]=cols\n",
    "    windowsStore[\"fullDataColMap\"] = window2  \n",
    "\n",
    "###########################################################\n",
    "\n",
    "def showMissingColumns():\n",
    "    global missed\n",
    "\n",
    "    header_list = [\"Column\",\"% Missing\",\"Missing\",\"string\",\"integer\",\"float\",\"boolean\"]\n",
    "    stats1Ex = {}\n",
    "    \n",
    "    stats1Tr = {}\n",
    "    stats1Ci = {}\n",
    "    \n",
    "    for col in missed['Extract - Data']:\n",
    "        print(col,stats1Extract[col])\n",
    "        stats1Ex[col]= stats1Extract[col]\n",
    "\n",
    "    \n",
    "    for col in missed['Transform - Data']:\n",
    "        print(col,stats1Transform[col])\n",
    "        stats1Tr[col]= stats1Transform[col]\n",
    "\n",
    "    for col in missed['CIM - Data']:\n",
    "        print(col,stats1Cim[col])\n",
    "        stats1Ci[col]= stats1Cim[col]\n",
    "  \n",
    "    valsExtract = getValues(stats1Ex,header_list)\n",
    "    valsTransform = getValues(stats1Tr,header_list)\n",
    "    valsCim = getValues(stats1Ci,header_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    layout = [\n",
    "               [sg.Button(\"Quit\")],\n",
    "               [sg.Listbox(values=missed[\"BIC Inventory\"],size=(10,5),font=\"CENTAUR 10\"),\n",
    "                sg.Listbox(values=missed[\"Transform Program\"],size=(10,5),font=\"CENTAUR 10\"),\n",
    "                sg.Listbox(values=missed[\"Transform - SIJ\"],size=(10,5),font=\"CENTAUR 10\")],\n",
    "                [sg.Table(values=valsExtract,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=10,font=\"CENTAUR 10\",\n",
    "                    justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                    key='-TABLEMISSEXTR-',headings = header_list)],\n",
    "                [sg.Table(values=valsTransform,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=10,font=\"CENTAUR 10\",\n",
    "                    justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                    key='-TABLEMISSTRANS-',headings = header_list)],\n",
    "                [sg.Table(values=valsCim,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=10,font=\"CENTAUR 10\",\n",
    "                    justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                    key='-TABLEMISSCIM-',headings = header_list)]\n",
    "               ]\n",
    "\n",
    "#    colorTheme = windowP.metadata[0]  \n",
    "    theme = \"LightBrown 3\"\n",
    "    sg.theme(\"LightBrown 3\")     \n",
    "    window2 = sg.Window(\"Missing Fields\",layout,finalize=True,resizable=True,metadata=[theme])\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableex = window2['-TABLEMISSEXTR-']\n",
    "    tableex.bind('<Button-1>', \"Click\")\n",
    "    tabletr = window2['-TABLEMISSTRANS-']\n",
    "    tabletr.bind('<Button-1>', \"Click\")\n",
    "    tableci = window2['-TABLEMISSCIM-']\n",
    "    tableci.bind('<Button-1>', \"Click\")\n",
    "    \n",
    "    dataStore[tableex] = valsExtract\n",
    "    dataStore[tabletr] = valsTransform\n",
    "    dataStore[tableci] = valsCim\n",
    "    \n",
    "    \n",
    "    return window2,tableex,tabletr,tableci\n",
    "    # headerStore[tableFile1] = header_list\n",
    "    \n",
    " \n",
    "###########################################################\n",
    "\n",
    "def sortUniqe(table,window,dataStore,headerStore):\n",
    "    global color1,color2\n",
    "    try:\n",
    "        e = table.user_bind_event\n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        sortAsc = {}\n",
    "        sortAsc[1] =False\n",
    "        sortAsc[-1]=True\n",
    "   #     print(\"R \",region)\n",
    "        if region == 'heading':\n",
    "            values = dataStore[table]\n",
    "            \n",
    "           \n",
    "            header = headerStore[table]\n",
    "            # print(\"SU header \",header)\n",
    "            column = int(table.Widget.identify_column(e.x)[1:])\n",
    "            col=header[column-1]\n",
    "            \n",
    "            sortState = table.metadata\n",
    "           \n",
    "            sortState[col]*=-1\n",
    "            table.metadata = sortState\n",
    "          \n",
    "            values = sorted(values, key=lambda element: (element[column-1]),reverse=sortAsc[sortState[col]]) \n",
    "#            rowFile1Colors = setRowColors(values,color1,color2,\"pink\",header)\n",
    "            rowFile1Colors = setRowColorsGeneric(values,color1,color2)\n",
    "\n",
    "            window[\"-TABLE-\"].update(values=values)\n",
    "            dataStore[table] = values\n",
    "    except Exception as err:\n",
    "        exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "                    \n",
    "#####################################################        \n",
    "\n",
    "def tranfColXref(file):\n",
    "    global transformProgram\n",
    " #   fin = open(\"/home/joe/bic_etl/cdos/business/nonprofit/scripts/reg_finan.js\",\"r\")\n",
    "    fin = open(file,\"r\")\n",
    "    \n",
    "    lines = fin.readlines() \n",
    "    transformProgram = lines\n",
    "    fout = open(\"output.txt\",\"w\")\n",
    "    org = []\n",
    "    xrefsO2T = {}\n",
    "    xrefsT2O = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if re.findall(\"row\",line.lower()) and re.findall(\"=\",line.lower()) and not re.findall(\"^//\",line.lstrip()):\n",
    "            st1=line.find(\"[\")\n",
    "            ed1=line.find(\"]\")\n",
    "            st2=line.rfind(\"[\")\n",
    "            ed2=line.rfind(\"]\")\n",
    "            org.append(line[st2+2:ed2-1])\n",
    "    #        print(line)\n",
    "    #        print(line[st1+1:ed1],line[st2+1:ed2])\n",
    "            fout.write(f\"{line[st1+1:ed1]}  {line[st2+1:ed2]}\\n\")\n",
    "            og = line[st2+1:ed2].replace(\"'\",\"\")\n",
    "            og = og.replace('\"','')\n",
    "            \n",
    "            og = og.replace(\"].toLowerCase()\",\"\")\n",
    "\n",
    "\n",
    "            tr = line[st1+1:ed1].replace(\".toLowerCase()\",\"\")\n",
    "            tr = tr.replace('\"','')\n",
    "            tr = tr.replace(\"'\",\"\")\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            # tr = line[st1+1:ed1]\n",
    "            # og = line[st2+1:ed2]\n",
    "\n",
    "            xrefsT2O[tr]  = og\n",
    "            xrefsO2T[og]  = tr\n",
    "    return xrefsO2T,xrefsT2O\n",
    "                \n",
    "############################################################\n",
    "\n",
    "def wrap(string, lenght=60):\n",
    "    if isinstance(string,str):\n",
    "       return '\\n'.join(textwrap.wrap(string, lenght))\n",
    "    else:\n",
    "        return \"\"\n",
    "        \n",
    "############################################################    \n",
    "       \n",
    "def cronGUI():\n",
    "    global ds,text2,a,string,numWindows,color1,color2,file,transform,dataStore,statsStore\n",
    "    global windowsStore,xrefsBy4x4,groupMenu\n",
    "    global transformProgram,dnotpLines\n",
    "    global extractColumns,transformColumns,cimColumns\n",
    "    global transformSijColumns,loadSijColumns,xrefsO2T,xrefsT2O\n",
    "    global dfExtract,dfTransform,dfCim,missed,fields\n",
    "    global stats1Extract,stats1Transform,stats1Cim\n",
    "    \n",
    "    dataStore = {}\n",
    "    statsStore = {}\n",
    "    windowsStore = {}\n",
    "    datasets = init()\n",
    "    cimColumns = []\n",
    "    transformColumns = []\n",
    "    extractColumns = []\n",
    "    transformSijColumns = []\n",
    "    loadSijColumns = []\n",
    "    \n",
    "    \n",
    "##  get xrefs b/w 4x4 ids and datasert titles...yay   \n",
    "    xrefsBy4x4,xrefsByTitle,fields = getXrefs()\n",
    "\n",
    "    mf = pd.read_excel(\"BICDataInventoryandMetadata.xlsx\",skiprows=0,sheet_name=\"Inventory_Active\",engine=\"openpyxl\")\n",
    "    \n",
    "    mf[\"CIM Link\"] = mf.apply(map4x4,axis=1)\n",
    "\n",
    "    mf=mf.loc[~mf[\"Standardized Title for Dataset\"].isna()]\n",
    "    mfShort = mf[['Standardized Title for Dataset', 'Data Link','CIM Data Type','GoCodePublishYear','Standardized Short Description','CIM Link']]\n",
    "    mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)   \n",
    "    \n",
    "    header_list = list(mfShort.columns)\n",
    "    # mfV = []\n",
    "    # a = [\"\",\"\",nan,nan,\"\"]\n",
    "    # mfV.append(a)\n",
    "    layout = [\n",
    "              [sg.Text(\"BIC Cron DataSets\")],\n",
    "              [sg.Combo(datasets,enable_events=True,key=\"-DATASET-\",font='Courier 10 bold ')],\n",
    "              [sg.ButtonMenu('Groups', menu_def=groupMenu, key='Group Menu')],\n",
    "              [sg.Text(\"4x4\",font='Courier 15 bold '),sg.Input(\"wwbh-7bpa\",size=[8,1],key=\"-4x4-\",font='Courier 10 bold '),\n",
    "               sg.Button(\"4x4\")],\n",
    "              [sg.Button('Close'),sg.Button(\"Plot Crons\")],\n",
    "              [sg.Button(\"Column Analysis\")],\n",
    "   #          [sg.Button(\"GO\")],\n",
    "              [sg.Button(\"Extract\",font='Courier 10 bold ',key=\"-EXTRACT-\",visible=True),\n",
    "               sg.Button(\"Analyze-Extr\",font='Courier 10 bold ',key=\"-EXTRACTANAL-\",visible=False),\n",
    "               sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-EXTRACTINFO-\")],\n",
    "              [sg.Button(\"Transform\",visible=False,font='Courier 10 bold ',key=\"-TRANSFORM-\"),\n",
    "               sg.Button(\"Ananlyze-Trans\",font='Courier 10 bold ',key=\"-TRANSFORMANAL-\",visible=False),\n",
    "               sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-TRANSFORMINFO-\")\n",
    "              ],\n",
    "              [sg.Button(\"CIM API\",font='Courier 15 bold ',key=\"-CIMAPI-\",visible=False),sg.Text(\"\",visible=False,font='Courier 15 bold ',key=\"-CIMINFO-\")],\n",
    "              [sg.Text(text=\"Dataset Summary\",enable_events=True,font='Courier 15 bold ',background_color=\"blue\",key=\"-OUTPUT-\",size=[70,10]),\n",
    "               sg.Multiline(default_text=\"ETL Summary\",key=\"-ETL-\",size=[70,20],font='Courier 15 bold ')]\n",
    "            ]\n",
    "\n",
    "       \n",
    "    # Create the Window\n",
    "    sg.theme('Dark Green 5')\n",
    "    window2 = sg.Window('ETL', layout,finalize=True,resizable=True)\n",
    "    #window = sg.Window('Window Title', layout, web_port=2222, web_start_browser=False)\n",
    "    #table = window2['-TABLE2-']\n",
    "\n",
    "    #window2.move(window.current_location()[0]+600, window.current_location()[1])\n",
    "    try: \n",
    "        while True:\n",
    "\n",
    "         #   event, values = window2.read()\n",
    "            wid, event, values = sg.read_all_windows()\n",
    "            print('event: ',event, 'values: ',values)\n",
    " \n",
    "            if event == sg.WIN_CLOSED or event == 'Close':\n",
    "                window2.close()\n",
    "                break\n",
    "            elif event ==  event == 'Quit':\n",
    "                wid.close()\n",
    "### DATASET                \n",
    "            elif event == \"-DATASET-\" or event == \"4x4\" or event == \"Group Menu\":\n",
    "      #      elif event == \"GO\":#\n",
    "                if event == \"-DATASET-\":\n",
    "                    (ds)  = list(values.items())\n",
    "                    ds=ds[0][1]\n",
    "                elif event == \"4x4\":\n",
    "                    ds = xrefsBy4x4[values[\"-4x4-\"]]\n",
    "                    print(\"XREF DS \",values[\"-4x4-\"],ds)\n",
    "                elif event == \"Group Menu\":\n",
    "                    ds = values[\"Group Menu\"]\n",
    "  #              ds = \"Paid Solicitors Disclosed on Charity Registration Forms in Colorado\"\n",
    "                print(\"Daetaset \",ds)\n",
    "                mmf = mfShort.loc[mfShort[\"Standardized Title for Dataset\"].str.strip() == ds.strip()]\n",
    "                cim4x4 = mmf['Data Link'].values.tolist()[0]\n",
    "                cimApi = f\"https://data.colorado.gov/api/views/{cim4x4}/rows.csv?accessType=DOWNLOAD\"\n",
    "                if mmf.shape[0] > 0:\n",
    "                #            mmf[\"Standardized Short Description\"] = mmf[\"Standardized Short Description\"].map(wrap)          \n",
    "                    text = f\"Title             : {mmf['Standardized Title for Dataset'].values.tolist()[0]}\\nSocrata        : {mmf['Data Link'].values.tolist()[0]}\\nData Type    : {mmf['CIM Data Type'].values.tolist()[0]}\\nPublish Year: {mmf['GoCodePublishYear'].values.tolist()[0]}\\nCIM Link : {mmf['CIM Link'].values.tolist()[0]}\\nDescription  : {mmf['Standardized Short Description'].values.tolist()[0]}\"            \n",
    "                   # display(mmf)\n",
    "                else:\n",
    "                    text = \"None\"\n",
    "                if ds in dataSetsEtl:\n",
    "                      text2,extract,transform = runETL(ds)\n",
    "                else:\n",
    "                      text2=\"\"\n",
    "                      extract = \"\"\n",
    "                if len(extract) > 10:\n",
    "                    window2[\"-EXTRACT-\"].update(visible=True)\n",
    "                if len(transform) > 10:\n",
    "                    window2[\"-TRANSFORM-\"].update(visible=True)\n",
    "                    window2[\"-TRANSFORM-\"].update(visible=True)\n",
    "          \n",
    "                if len(cimApi) > 10:                 \n",
    "                    text2+=  f\"\\n\\nCIM API\\n{cimApi}\"\n",
    "                    window2[\"-CIMAPI-\"].update(visible=True)\n",
    "                    \n",
    "                   \n",
    "                window2[\"-OUTPUT-\"].update(text)\n",
    "                window2[\"-ETL-\"].update(text2)\n",
    "                link =  mmf['CIM Link'].values.tolist()[0]\n",
    "           #     print(\"Link \",mmf['CIM Link'],link.find(\"http\"))\n",
    "                \n",
    "                # if link.find(\"http\") > -1:\n",
    "                #      window2[\"-LINK-\"].update (visible=True)\n",
    "                # else:\n",
    "                #      window2[\"-LINK-\"].update (visible=False)\n",
    "### LINK                \n",
    "               \n",
    "            elif event == \"-LINK-\":\n",
    "                    print(\"Going To: \",link) \n",
    "                    if len(link) > 10:\n",
    "                        webbrowser.open(link)\n",
    "### Plot Crons                \n",
    "            elif event == \"Plot Crons\":    \n",
    "                plotCrons(crons_all)\n",
    "\n",
    "### Show Missing Columns\n",
    "            elif event == \"Show Missing Fields\":\n",
    "                  window2,tableex,tabletr,tableci = showMissingColumns()\n",
    "### Full Data Column Map\n",
    "            elif event == \"Full Data Column Map\":\n",
    "                cols,vals,missed = fullDataColumnMap(cim4x4)\n",
    "                showFullDataColMap(cols,vals)\n",
    "            \n",
    "### Get SIJ Cols\n",
    "            elif event == \"Get SIJ Cols\":\n",
    "                getSijColumns(\"\")\n",
    "                print(\"Tr SIJ \",transformSijColumns)\n",
    "                print(\"LD SIJ \",loadSijColumns)\n",
    "                 \n",
    "### DNOTP\n",
    "\n",
    "            elif event == \"-DNOTP-\":\n",
    "                col = values[\"-DNOTP-\"][0]\n",
    "                if col in dnotpLines:\n",
    "                    string=\"\"\n",
    "                    string = \"\\n\".join(dnotpLines[col])\n",
    "                else:\n",
    "                    string=\"NOTHING FOUND\"\n",
    "                sg.Popup(string)\n",
    "                    \n",
    "                print(\"DNOTP STRai\",string)\n",
    "### Column Analysis                \n",
    "            elif event == \"Column Analysis\":\n",
    "           #     trfile = dataSetsEtl[ds][\"transform\"][\"file\"]\n",
    "                trfile = transform[5:]\n",
    "                \n",
    "                xrefsO2T,xrefsT2O = tranfColXref(trfile)\n",
    "                color1 = colorPairs[numWindows][0]\n",
    "                color2 = colorPairs[numWindows][1]\n",
    "                \n",
    "                numWindows+=1\n",
    "                if numWindows > len(colorPairs):\n",
    "                    numWindows=0\n",
    "                showColAnal(xrefsO2T,xrefsT2O,color1,color2)\n",
    "             \n",
    "### Compare 2 Data                 \n",
    "            elif event == \"Compare 2 Data\":   \n",
    "                print(\"HERE We GO\")\n",
    "                ww = windowsStore[\"extract\"]\n",
    "                wdf = ww.metadata[1]\n",
    "                \n",
    "                compare2Data(wdf,xrefsO2T)\n",
    "                         \n",
    "### CIMAPI                \n",
    "            elif event == \"-CIMAPI-\":\n",
    "                  #  df1,stats1 = getFilesClicked(cimApi,window2)\n",
    "                    dfCim,stats1Cim = getFile(\"Fetch\",cimApi,window2)\n",
    "                    cimColumns = list(dfCim.columns)\n",
    "                    color1 = colorPairs[numWindows][0]\n",
    "                    color2 = colorPairs[numWindows][1]\n",
    "\n",
    "                    numWindows+=1\n",
    "                    if numWindows > len(colorPairs):\n",
    "                        numWindows=0\n",
    "\n",
    "                    WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1Cim,dfCim,cimApi,\"CMI Analysis\",\"DarkRed\")\n",
    "                    dataStore[tabl1]=valsFile1\n",
    "                    \n",
    "                    windowsOpen[\"main\"].append(WindowC)  \n",
    "                    \n",
    "### TRANSFORM               \n",
    "            elif event == \"-TRANSFORM-\":\n",
    "               \n",
    "                a=subprocess.run(transform,shell=True,capture_output=True,text=True)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"TRANSFORM Output\\n\"\n",
    "                tfile=\"\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= f\"Error:\\n {a.stderr}\"\n",
    "                else:\n",
    "                    for msg in a.stdout.split(\"debug msg:\"):    \n",
    "                        if msg.find(\"final file is at:\") > -1:\n",
    "                           \n",
    "                            tmp = msg.split(\" \")\n",
    "                            tfile = tmp[-3]\n",
    "                            if os.path.isfile(tfile):\n",
    "                                \n",
    "                                window2[\"-TRANSFORMANAL-\"].update(visible=True)\n",
    "                                fileStats = os.stat(tfile)\n",
    "                                dt = datetime.fromtimestamp(fileStats.st_ctime)\n",
    "                                string = f\"{fileStats.st_size:,} bytes Created: {dt}  file: {tfile}\"\n",
    "                                window2[\"-TRANSFORMINFO-\"].update(string,visible=True)\n",
    "                            \n",
    "                    string+=f\"STDOUT: {a.stdout}\"\n",
    "                    window2[\"-ETL-\"].update(string,append=True)\n",
    "                    \n",
    "### TRANSFORMANAL\n",
    "            elif event == \"-TRANSFORMANAL-\":\n",
    "                #    df1,stats1 = getFilesClicked(tfile,window2)\n",
    "                    dfTransform,stats1Transform = getFile(\"Local\",tfile,window2)\n",
    "                    transformColumns = list(dfTransform.columns)\n",
    "                    color1 = colorPairs[numWindows][0]\n",
    "                    color2 = colorPairs[numWindows][1]\n",
    "                  \n",
    "                    numWindows+=1\n",
    "                    if numWindows > len(colorPairs):\n",
    "                        numWindows=0\n",
    "\n",
    "                    WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1Transform,dfTransform,tfile,\"Transform Analysis\",\"DarkPurple\")\n",
    "                    dataStore[tabl1]=valsFile1\n",
    "                    windowsOpen[\"main\"].append(WindowC)    \n",
    "                    \n",
    "### EXTRACT                  \n",
    "            elif event == \"-EXTRACT-\":\n",
    "                a=subprocess.run(extract,shell=True,capture_output=True,text=True)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"Extract Output\\n\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= \"fError:\\n {a.stderr}\"\n",
    "                string+=f\"STDOUT: {a.stdout}\"\n",
    "                window2[\"-ETL-\"].update(string,append=True)\n",
    "                sx = string.find(\"successfully download to\")\n",
    "                string[sx+25:]\n",
    "                sxo = string[sx+25:].find(\"!\")\n",
    "             \n",
    "                file=f\"/home/joe/bic_etl{string[sx+25:sx+25+sxo]}\"\n",
    "              \n",
    "                if os.path.isfile(file):\n",
    "                  \n",
    "                    window2[\"-EXTRACTANAL-\"].update(visible=True)\n",
    "                    fileStats = os.stat(file)\n",
    "                    dt = datetime.fromtimestamp(fileStats.st_ctime)\n",
    "                    string = f\"{fileStats.st_size:,} bytes Created: {dt}  file: {file}\"\n",
    "                    window2[\"-EXTRACTINFO-\"].update(string,visible=True)\n",
    "                    \n",
    "### EXTRACTANAL                      \n",
    "            elif event == \"-EXTRACTANAL-\":\n",
    "                file=stringArgs(extract)\n",
    "                \n",
    "             #   df1,stats1 = getFilesClicked(file,window2)\n",
    "                dfExtract,stats1Extract = getFile(\"Local\",file,window2)\n",
    "                extractColumns = list(dfExtract.columns)\n",
    "                color1 = colorPairs[numWindows][0]\n",
    "                color2 = colorPairs[numWindows][1]\n",
    "                \n",
    "                numWindows+=1\n",
    "                if numWindows > len(colorPairs):\n",
    "                    numWindows=0\n",
    "                    \n",
    "                WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1Extract,dfExtract,file,\"Extract Analysis\",\"DarkBlue16\")\n",
    "                dataStore[tabl1]=valsFile1\n",
    "                windowsOpen[\"main\"].append(WindowC)\n",
    "                windowsStore[\"extract\"] = WindowC\n",
    "                \n",
    "### TABLEFILE-CLICK\n",
    "            elif event == \"-TABLEFILE-Click\":\n",
    "               \n",
    "                row,col=getRowClicked(tabl1,valsFile1)\n",
    "               \n",
    "                if row == 0:\n",
    "                   header = headerStore[tabl1]\n",
    "                   tabl1 = wid[\"-TABLEFILE-\"]\n",
    "                   stats1 = statsStore[tabl1]\n",
    "                   valsFile1,columnSortStateTable1 = sortTable(row,stats1,tabl1,event,header)          \n",
    "                   rowFile1Colors=setRowColors(valsFile1,color1,color2,\"pink\",header)\n",
    "                   wid[\"-TABLEFILE-\"].update(values=valsFile1,row_colors=rowFile1Colors)\n",
    "                   wid[\"-TABLEFILE-\"].metadata=columnSortStateTable1\n",
    "                else:\n",
    "                    df1 = wid.metadata[1]\n",
    "                    unq = df1[col].value_counts()\n",
    "                    colorTheme=wid.metadata[0]\n",
    "                    w,t,values,uHead = showDFUN(col,unq,wid,color1,color2,colorTheme)\n",
    "                  #dataStore[t] = values\n",
    "                    headerStore[t] = uHead\n",
    "                    windowsOpen[\"main\"].append(w)\n",
    "                    \n",
    "### TABLE-Click\n",
    "            elif event == \"-TABLE-Click\":  # This is the Unique Values tables\n",
    "                table = wid['-TABLE-']               \n",
    "               \n",
    "                \n",
    "                row,val =getRowClickedUN(table)\n",
    "                if row == 0:\n",
    "                    sortUniqe(table,wid,dataStore,headerStore)\n",
    "                else:\n",
    "                    widP = wid.metadata[0]\n",
    "                    col = wid.metadata[1]\n",
    "                    df = widP.metadata[1]\n",
    "                    tmp = df.loc[df[col] == val]\n",
    "                    showDfRecs(tmp,col,val,widP,title=\"DF Unique Record Values\")\n",
    "                    \n",
    "###  -TABLEMISSEXTR-Click                   \n",
    "            elif event in [\"-TABLEMISSEXTR-Click\",\"-TABLEMISSTRANS-Click\",\"-TABLEMISSCIM-Click\"] :\n",
    "                if event == \"-TABLEMISSEXTR-Click\":\n",
    "                   tabl1 = wid[\"-TABLEMISSEXTR-\"]\n",
    "                   title = \"EXTRACT\"\n",
    "                   df = dfExtract\n",
    "                elif event == \"-TABLEMISSTRANS-Click\":\n",
    "                   tabl1 = wid[\"-TABLEMISSTRANS-\"]\n",
    "                   df =  dfTransform\n",
    "                   title = \"TRANSFORM\"\n",
    "                elif event == \"-TABLEMISSCIM-Click\":\n",
    "                   tabl1 = wid[\"-TABLEMISSCIM-\"]\n",
    "                   df =  dfCim\n",
    "                   title=\"CIM\"\n",
    "                 \n",
    "                \n",
    "                vals = dataStore[tabl1]\n",
    "                row,col=getRowClicked(tabl1,vals)\n",
    "                unq = df[col].value_counts()\n",
    "                colorTheme=wid.metadata[0]\n",
    "                w,t,values,uHead = showDFUN(col,unq,wid,color1,color2,colorTheme,title)\n",
    "                  #dataStore[t] = values\n",
    "                headerStore[t] = uHead\n",
    "                windowsOpen[\"main\"].append(w)\n",
    "                   \n",
    "         \n",
    "    except  Exception as err: \n",
    "       exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    " \n",
    "    for wid in windowsOpen[\"main\"]:\n",
    "        print(\"window MA\",wid)\n",
    "        if wid:\n",
    "            print(\"cosing \",wid)\n",
    "            wid.close()\n",
    "            wid = None\n",
    "\n",
    "cronGUI()\n",
    "\n",
    "\n",
    "\n",
    "### Bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142982a8-7994-4e81-96e6-be6d9b9bdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.theme_previewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e301a81-107c-44d6-b50e-191cee27f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://docs.google.com/spreadsheets/d/1Xc7oYpdCLwHmUCaokpfXkF4bzkwRW0xUbvBZwruF0ZI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a9b584-35ae-4a5e-b386-c094a32604d6",
   "metadata": {},
   "source": [
    "## Bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea653a-316f-4607-856d-a63ca38b3b97",
   "metadata": {},
   "source": [
    "# stats1Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac12b4e-576e-4be6-9f45-56905700222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa99847-7377-46ee-a439-59d8a4ae54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    global dataSetsEtl,datasets,groups\n",
    "    groups = []\n",
    "    desktop = pathlib.Path(\"/home/joe/bic_etl\")\n",
    "    runEtls = []\n",
    "    dataSets = []\n",
    "    info = {}\n",
    "    # .rglob() produces a generator too\n",
    "    desktop.rglob(\"*\")\n",
    "    files = list(desktop.rglob(\"*\"))\n",
    "# Which you can wrap in a list() constructor to materialize\n",
    "    for ff in files:\n",
    "\n",
    "            if (str(ff).split(\"/\")[-1] == \"run_etl.json\"):     \n",
    "                a=str(ff).split(\"/\")\n",
    "                m = a.index(\"bic_etl\")\n",
    "                b = a[m+1:-1]\n",
    "                ll = splitL(b)\n",
    "                groups.append(ll)\n",
    "                runEtls.append(ff)\n",
    "            \n",
    "    print(f\"{len(runEtls)} run_etl.json files found\")    \n",
    "    \n",
    "    dataSets = []\n",
    "    groups = []\n",
    "    for file in runEtls:\n",
    "      f = open(file,\"r\")\n",
    "      data = json.load(f)\n",
    "      # print(file)\n",
    "      # print(\"----\")\n",
    "      a=str(file).split(\"/\")\n",
    "      m = a.index(\"bic_etl\")\n",
    "      b = a[m+1:-1]\n",
    "      group = b[0]\n",
    "      ll = splitL(b)\n",
    "      bdir = \"/\".join(b)  \n",
    "      print(\"GROUP \",group)\n",
    "      \n",
    "    #  groups.append(ll)\n",
    "      for val in data:\n",
    "            if \"title\" in val:\n",
    "                  title=val[\"title\"]\n",
    "                  info[title]={}\n",
    "                  info[title][\"directory\"] = bdir\n",
    "                  info[title][\"group\"] = group\n",
    "                \n",
    "    #              print(title,ll)\n",
    "                  nit=0\n",
    "                  ll = go_deeper(ll,title,nit)\n",
    "             #     info[title][\"groups\"] = ll\n",
    "            \n",
    "     #             print(ll)\n",
    "     #             groups.append(ll)\n",
    "            dataSets.append(val)\n",
    "    #  print(\"FF \",ll) \n",
    "      groups.append(ll)\n",
    "\n",
    "    datasets = []\n",
    "    dataSetsEtl={}\n",
    "    for val in dataSets:\n",
    "        if \"title\" in val:\n",
    "          datasets.append(val[\"title\"])\n",
    "          title=val[\"title\"]\n",
    "          dataSetsEtl[title] = {}  \n",
    "          dataSetsEtl[title][\"info\"] = {}\n",
    "          dataSetsEtl[title][\"info\"][\"directory\"] = info[title][\"directory\"]\n",
    "          dataSetsEtl[title][\"info\"][\"group\"] = info[title][\"group\"]\n",
    "     #     dataSetsEtl[title][\"info\"][\"groups\"] = info[title][\"groups\"]\n",
    "            \n",
    "        \n",
    "            \n",
    "          for k,v in val.items():\n",
    "          #      print(k,v)\n",
    "                if k != \"title\":\n",
    "                    dataSetsEtl[title][k] = {}\n",
    "                    if isinstance(v,dict):\n",
    "                        for k1,v1 in v.items():\n",
    "                            dataSetsEtl[title][k][k1]=v1\n",
    "\n",
    "    return sorted(datasets)\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9158d2d-5e68-4964-bb10-07c3b4ee6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupD = {}\n",
    "for gp in groups:\n",
    "    for k1,v1 in gp.items():\n",
    "        print(k1,type(v1))\n",
    "    \n",
    "        if isinstance(v1,dict):\n",
    "            for k2,v2 in v1.items():\n",
    "                print(\"  K2 \",k2,type(v2))\n",
    "                if isinstance(v2,dict):\n",
    "                    for k3,v3 in v2.items():\n",
    "                        print(\"   K3  \",k3,type(v3))\n",
    "                        if k1 not in groupD:\n",
    "                            groupD[k1]={}\n",
    "                        if k2 not in groupD[k1]:\n",
    "                            groupD[k1][k2]={}\n",
    "                            \n",
    "                        groupD[k1][k2][k3]=v3            \n",
    "                        \n",
    "                        \n",
    "                else:\n",
    "                    if k1 not in groupD:\n",
    "                        groupD[k1] = {}\n",
    "                    if k2 not in groupD[k1]:\n",
    "                        groupD[k1][k2] = v2\n",
    "                    \n",
    "                            \n",
    "        else:\n",
    "            groupD[k1] = v1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235fd24-da40-4f95-ba60-0a9d704bd670",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupMenu = []\n",
    "for k1,v1 in sorted(groupD.items()):\n",
    "    print(k1)\n",
    "    if isinstance(v1,list):\n",
    "        groupMenu.append(k1)\n",
    "        groupMenu.append(v1)\n",
    "    else:\n",
    "        for k2,v2 in v1.items():\n",
    "            if isinstance(v2,list):\n",
    "               if k1 not in groupMenu:\n",
    "                  groupMenu.append(k1)\n",
    "               if k2 not in groupMenu:\n",
    "                  groupMenu.append(k2)\n",
    "               groupMenu.append(v2)\n",
    "            else:\n",
    "               for k3,v3 in v2.items():\n",
    "                   if isinstance(v3,list):\n",
    "                       if k1 not in groupMenu:\n",
    "                         groupMenu.append(k1)\n",
    "                       if k2 not in groupMenu:\n",
    "                         groupMenu.append(k2)\n",
    "                        \n",
    "                       groupMenu.append(k3)                     \n",
    "                       groupMenu.append(v3)\n",
    "\n",
    "\n",
    "gm = [\"Groups\",groupMenu]\n",
    "gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7155d0c-1eec-40bd-9ab0-c9877a4f2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupMenu = ['Groups',\n",
    " ['boulder',\n",
    "  ['Restaurant Inspections in Boulder Colorado'],\n",
    "  'catalog',\n",
    "  ['CIM Catalog Download'],\n",
    "  'cdhe',\n",
    "  ['Enrollment Demographics for Post-Secondary Graduates in Colorado',\n",
    "   'Post-Secondary Financial Aid Demographics in Colorado'],\n",
    "  'cdor',[\n",
    "  'revenue_marijuana',\n",
    "  ['Marijuana Sales by County in Colorado',\n",
    "   'State Retail Marijuana Sales Tax Revenue by County in Colorado',\n",
    "   'Marijuana Tax and Fee Revenue in Colorado',\n",
    "   'Marijuana Sales Revenue in Colorado'],\n",
    "  'retail_reports',\n",
    "  ['Retail Sales Tax Return History in Colorado',\n",
    "   'Retail Reports by City in Colorado',\n",
    "   'Retail Reports by County in Colorado',\n",
    "   'Retail Reports by Industry and City in Colorado',\n",
    "   'Retail Reports by Industry and County in Colorado',\n",
    "   'Retail Reports by Industry in Colorado'],\n",
    "  'regulations_liquor',\n",
    "  ['Liquor Permits for Special Events in Colorado',\n",
    "   'Liquor Compliance Check Statistics in Colorado',\n",
    "   'Liquor Licenses in Colorado',\n",
    "   'Recently Approved Liquor Licenses in Colorado',\n",
    "   'Recently Expired and Surrendered Liquor Licenses in Colorado',\n",
    "   'Sales Rooms in Colorado',\n",
    "   'Manufacturer Temporary Sales Room Permits in Colorado']\n",
    "  ],\n",
    "  'cdos',[\n",
    "  'health',\n",
    "  ['Durable Medical Equipment Suppliers in Colorado'],\n",
    "  'government',\n",
    "  ['Current Notaries in Colorado'],\n",
    "  'business',[\n",
    "  'ucc',\n",
    "  ['Uniform Commercial Code (UCC) Collateral Information in Colorado',\n",
    "   'Uniform Commercial Code (UCC) Debtor Information in Colorado',\n",
    "   'Uniform Commercial Code (UCC) Filing Information in Colorado',\n",
    "   'Secured Party Information in Colorado'],\n",
    "  'business',\n",
    "  ['Business Entities in Colorado',\n",
    "   'Business Entity Transaction History',\n",
    "   'Trademarks for Businesses in Colorado',\n",
    "   'Trade Names for Businesses in Colorado',\n",
    "   'Master List in Colorado'],\n",
    "  'nonprofit',\n",
    "  ['Federal Tax-Exempt Subsection Codes in Colorado',\n",
    "   'Registration for Charities, Paid Solicitors, Professional Fundraising Consultants, and for-profit Public Benefit Corporations in Colorado',\n",
    "   'Charitable Organizations’ Offices in Colorado',\n",
    "   'Other State Solicitation of Charities’ Registrants in Colorado',\n",
    "   'Charitable Purpose of the Charity in Colorado',\n",
    "   'Paid Solicitor Solicitation Notices in Colorado',\n",
    "   'Campaign Reports for Solicitation Notices to Charities in Colorado',\n",
    "   'Solicitation Campaign Supervisors Listed on Solicitation Notices in Colorado',\n",
    "   'Charity Extension Requests',\n",
    "   'Persons Associated with Charitable Organizations, Paid Solicitors, and Professional Fundraising Consultants in Colorado',\n",
    "   'Other Names a Registered Entity Uses to Solicit Contributions',\n",
    "   'Paid Solicitors Disclosed on Charity Registration Forms in Colorado',\n",
    "   'Charitable Solicitation Call Center Locations in Colorado',\n",
    "   'Charities Solicitation Type by Solicitation in Colorado',\n",
    "   'Communication Methods Used in Solicitation Campaigns in Colorado']\n",
    "  ],\n",
    "  'lobbyist',\n",
    "  ['Directory of Lobbyists in Colorado',\n",
    "   'Directory of Lobbyist Clients in Colorado',\n",
    "   'Expenses for Lobbyists in Colorado',\n",
    "   'Characterization of Lobbyist Clients in Colorado',\n",
    "   'Subcontractors for Lobbyists in Colorado',\n",
    "   'Bill Information and Position with Income of Lobbyist in Colorado']\n",
    "  ],\n",
    "  'cdot',[\n",
    "  'transportation_road_attributes',\n",
    "  ['Highway Milepoints in Colorado',\n",
    "   'Highway Mileposts in Colorado',\n",
    "   'Highway Routes in Colorado',\n",
    "   'Highway Routes in Colorado',\n",
    "   'Local Roads in Colorado',\n",
    "   'Major Roads in Colorado',\n",
    "   'Scenic Byways in Colorado'],\n",
    "  'tops',\n",
    "  ['CDOT Expenses', 'CDOT Revenues', 'CDOT Payroll'],\n",
    "  'natural_resources',\n",
    "  ['Lakes in Colorado', 'Streams in Colorado'],\n",
    "  'transportation_infrastructure',\n",
    "  ['Airports in Colorado',\n",
    "   'Cities in Colorado',\n",
    "   'Counties in Colorado',\n",
    "   'Railroads in Colorado']\n",
    "  ],\n",
    "  \n",
    "  'ceo',[\n",
    "  'useia',\n",
    "  ['Gasoline Prices in Colorado', 'Natural Gas Prices in Colorado']\n",
    "  ],\n",
    "  'denver',\n",
    "  ['Temporary Outdoor Expansions for Restaurants in Denver, Colorado'],\n",
    "  'dola',[\n",
    "  'special_districts',\n",
    "  ['Metro Districts in Colorado',\n",
    "   'Parks and Rec Districts in Colorado',\n",
    "   'Fire Districts in Colorado',\n",
    "   'Hospital Districts in Colorado',\n",
    "   'Water and Sanitation Districts in Colorado',\n",
    "   'Library Districts in Colorado',\n",
    "   'School Districts in Colorado',\n",
    "   'Soil Districts in Colorado',\n",
    "   'Cemetery Districts in Colorado',\n",
    "   'All Special Districts in Colorado'],\n",
    "  'boundaries',\n",
    "  ['Municipal Annexations in Colorado', 'Municipal Boundaries in Colorado'],\n",
    "  'demographics',\n",
    "  ['Population Projections in Colorado',\n",
    "   'Race Estimates in Colorado',\n",
    "   'Race Forecast in Colorado']\n",
    "  ],\n",
    "  'dora',[\n",
    "  'regulations',\n",
    "  ['Licensed Real Estate Professionals in Colorado',\n",
    "   'Professional and Occupational Licenses in Colorado']\n",
    "  ],\n",
    "  'dpa',\n",
    "  ['DPA Tops Data'],\n",
    "  'irs',\n",
    "  ['Purpose and Operational Size of Charities Operating in Colorado',\n",
    "   'Fundraising Revenue of Charities Operating in Colorado',\n",
    "   'Total Revenue of Charities Operating in Colorado',\n",
    "   'IRS Filing Information for Charities Operating in Colorado',\n",
    "   'Total Revenue and Types of Art for Charities Operating in Colorado',\n",
    "   'Conservation Easements for Charities Operating in Colorado',\n",
    "   'Activities of Charities Operating in Colorado',\n",
    "   'Expenses of Charities Operating in Colorado',\n",
    "   'Expenses of Charities Operating in Colorado'],\n",
    "  'tchd',\n",
    "  ['Restaurant Inspections in Tri-County Colorado']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831da26-5d47-44d6-9a1e-7700e2eded34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "\n",
    "# menu_def = ['Location',\n",
    "#     [\n",
    "#         'Rack 1',\n",
    "#             [\n",
    "#                 'Shelf 1', ['Bin A::11', 'Bin B::11'],\n",
    "#                 'Shelf 2', ['Bin A::12', 'Bin B::12'],\n",
    "#             ],\n",
    "#         'Rack 2',\n",
    "#             [\n",
    "#                 'Shelf 1', ['Bin A::21', 'Bin B::21'],\n",
    "#                 'Shelf 2', ['Bin A::22', 'Bin B::22'],\n",
    "#             ],\n",
    "#     ]\n",
    "# ]\n",
    "menu_def = gm\n",
    "layout = [[sg.ButtonMenu('Location', menu_def=menu_def, key='Button_Menu')],\n",
    "          [sg.Button(\"Close\")]]\n",
    "window = sg.Window('Title', layout)\n",
    "\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    print(event,values)\n",
    "    if event == sg.WIN_CLOSED or event == \"Close\":\n",
    "        break\n",
    "    elif event == 'Button_Menu':\n",
    "        print(values[event])\n",
    "\n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059de11-94c3-4893-afe0-2cd48a69297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullDataColumnMap(cim4x4):\n",
    "    global missed\n",
    "    if cim4x4 in fields:\n",
    "        invc = fields[cim4x4][\"source\"].copy()\n",
    "    else:\n",
    "        invc = []\n",
    "    tfc = transformColumns.copy()\n",
    "    exc = extractColumns.copy()\n",
    "    excMissed = []\n",
    "    tfcsij = transformSijColumns.copy()\n",
    "    loadsij = loadSijColumns.copy()\n",
    "    cim = cimColumns.copy()\n",
    "    xrfo2t = xrefsO2T.copy()\n",
    "    names = []\n",
    "    columnDict = {}\n",
    "    names.append(\"BIC Inventory\")\n",
    "    names.append(\"Transform Program\")\n",
    "\n",
    "    names.append(\"Transform - Data\")\n",
    "    names.append(\"CIM - Data\")\n",
    "    names.append(\"Transform - SIJ\")\n",
    "    names.append(\"Load - SIJ\")\n",
    "\n",
    "    for k in exc:\n",
    "        print(\"MAP \",k)\n",
    "    #for k,v in xrefsO2T.items():\n",
    "        columnDict[k] = []\n",
    "        nhit=0\n",
    "        v=\"\"\n",
    "        if k in invc:\n",
    "            v=k\n",
    "            vv=v\n",
    "            invc.remove(k)\n",
    "            nhit+=1\n",
    "        else:\n",
    "            vv=\"\"\n",
    "        columnDict[k].append(vv)\n",
    "        \n",
    "        if k in xrfo2t:\n",
    "            v = xrfo2t[k]\n",
    "            vv=v\n",
    "            del xrfo2t[k]\n",
    "            nhit+=1\n",
    "        else:\n",
    "            vv = \"\"\n",
    "        columnDict[k].append(vv)  \n",
    "\n",
    "   \n",
    "        if v in tfc:\n",
    "           tfc.remove(v)\n",
    "           cc = v\n",
    "           nhit+=1\n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "\n",
    "\n",
    "        if v in cim:\n",
    "           cim.remove(v)\n",
    "           cc = v\n",
    "           nhit+=1            \n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "\n",
    "\n",
    "\n",
    "        if v.lower() in tfcsij:\n",
    "           tfcsij.remove(v.lower())\n",
    "           cc = v.lower()\n",
    "           nhit+=1            \n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "\n",
    "        if v.lower() in loadsij:\n",
    "           loadsij.remove(v.lower())\n",
    "           cc = v.lower()\n",
    "           nhit+=1\n",
    "        else:\n",
    "            cc=\"\"\n",
    "        columnDict[k].append(cc)\n",
    "        \n",
    "        if nhit == 0:\n",
    "            excMissed.append(k)\n",
    "        \n",
    "\n",
    "    a = pd.DataFrame(columnDict).T\n",
    "    a.columns = names\n",
    "    a.reset_index(inplace=True)\n",
    "    values = a.values.tolist()\n",
    "    cols = list(a.columns)\n",
    "   \n",
    "    missed = {}\n",
    "    missed[\"Extract - Data\"] = excMissed\n",
    "    missed[\"BIC Inventory\"] = invc\n",
    "    missed[\"Transform Program\"] = list(xrfo2t.keys())\n",
    "    missed[\"Transform - Data\"] = tfc\n",
    "    missed[\"CIM - Data\"] = cim\n",
    "    missed[\"Transform - SIJ\"] = tfcsij\n",
    "    missed[\"Load - SIJ\"] = loadsij\n",
    "    \n",
    "    \n",
    " #   missed = [invc,list(xrfo2t.keys()),tfc,cim,tfcsij,loadsij]\n",
    "    return cols,values,missed\n",
    "        \n",
    "a,b,c = fullDataColumnMap(\"w6kb-3vsj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46445bd3-c66e-475a-ac0c-ed3455477c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrefsO2T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a675bad-34b3-4b71-aa8e-d2f74e2151c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fileBrowser",
   "language": "python",
   "name": "filebrowser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
