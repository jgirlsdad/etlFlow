{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306d153a-b457-46bd-bee6-9178b77fb766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 run_etl.json files found\n",
      "LL  98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2914/1163233529.py:492: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event:  GO values:  {'-DATASET-': '', '-ETL-': 'ETL Summary'}\n",
      "event:  -EXTRACT- values:  {'-DATASET-': '', '-ETL-': 'extract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv'}\n",
      "/home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv FOUND FOUND FOUND\n",
      "event:  Quit values:  {'-DATASET-': '', '-ETL-': 'extract:\\n    language     :  node\\n    file             :  general/scripts/sftp_extract.js\\n    options       : -f charity/char_orgs_sol.txt\\n                       : -o cdos/business/nonprofit/data_source/\\n                       : -a .tsv\\n\\n\\ntransform:\\n    language     :  node\\n    file             :  scripts/char_orgs_sol.js\\n\\n\\nload:\\n    file             :  char_paid_solicitors.sij\\n    type             :  datasync\\n    format         :  csv\\n    load_file   :  char_orgs_sol.csv\\n\\n\\n\\n\\nActions Strings\\nExtract\\nnode /home/joe/bic_etl/general/scripts/sftp_extract.js  -f charity/char_orgs_sol.txt -o cdos/business/nonprofit/data_source/ -a .tsv\\n\\n-------------------------------------\\nExtract Output\\nSTDOUT: info msg: Extract started at 2023-08-07T02:05:50.048Z\\ninfo msg: Connection to SFTP server made at 2023-08-07T02:05:50.665Z\\ndebug msg: Saving charity/char_orgs_sol.txt to /home/joe/bic_etl/cdos/business/nonprofit/data_source/char_orgs_sol.tsv at 2023-08-07T02:05:50.665Z\\nwarn msg: File charity/char_orgs_sol.txt not updated since 2023-08-02T19:08:30-06:00 at 2023-08-07T02:05:50.687Z\\ninfo msg: charity/char_orgs_sol.txt was successfully download to /cdos/business/nonprofit/data_source/char_orgs_sol.tsv! at 2023-08-07T02:05:56.008Z'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys,os,inspect\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from cronsim import CronSim\n",
    "import argparse\n",
    "import json\n",
    "import PySimpleGUI as sg\n",
    "#import PySimpleGUIWeb as sg\n",
    "import pathlib\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import re\n",
    "from shlex import split\n",
    "import webbrowser\n",
    "import subprocess\n",
    "import collections\n",
    "import pyglet,tkinter\n",
    "from pyglet import font\n",
    "# import OpenGL\n",
    "# from OpenGL import GLU\n",
    "font.add_file('/etc/fonts/fonts/CENTAUR.TTF')\n",
    "font='Courier 10 bold '\n",
    "bicHome = \"/home/joe/bic_etl/\"\n",
    "numWindows=0\n",
    "headerStore = {}\n",
    "\n",
    "colorPairs = [[\"#D6EAF8\",\"#85C1E9\"],[\"#b3f0ff\",\"#33d6ff\"],[\"#D5F5E3\",\"#A3E4D7\"],[\"#FCF3CF\",\"#F7DC6F\"]]\n",
    "windowsOpen = {}\n",
    "windowsOpen[\"main\"] = []\n",
    "windowsOpen[\"unique\"] = []\n",
    "\n",
    "#############################################\n",
    "def compareWindow(stats1,df1,file1):\n",
    "    global color1,color2\n",
    "    header_list = [\"Column\",\"% Missing\",\"Missing\",\"string\",\"integer\",\"float\",\"boolean\"]\n",
    "    print(\"IN COMP\")\n",
    "    col_widths = [8]*len(header_list)\n",
    "    col_widths[0] = 25\n",
    "    columnSortStateTable1 = {}\n",
    "  \n",
    "\n",
    "    ## set up sort state for the column in both tables\n",
    "    for col in header_list:\n",
    "         columnSortStateTable1[col] = -1\n",
    "       \n",
    "            \n",
    "    valsFile1 = getValues(stats1,header_list)\n",
    "   \n",
    "    \n",
    "    rowFile1Colors = setRowColors(valsFile1,color1,color2,\"pink\",header_list)\n",
    "    \n",
    "    layCol1 = [[sg.Text(f\"File 1 {file1}\",font=\"CENTAUR 15\")],[sg.Text(f\"File 1 Shape {df1.shape}\",font=\"CENTAUR 15\")],\n",
    "               [sg.Table(values=valsFile1,text_color=\"black\", auto_size_columns=False,enable_events=True,num_rows=20,col_widths=col_widths,font=\"CENTAUR 10\",\n",
    "                   justification='center',pad=(5,5),vertical_scroll_only=False,\n",
    "                   key='-TABLEFILE-',row_colors=rowFile1Colors,headings = header_list,metadata=columnSortStateTable1)]\n",
    "               ]\n",
    "    \n",
    "\n",
    "    layout = [[sg.Button(\"Quit\")],\n",
    "    layCol1]  \n",
    "        \n",
    "\n",
    "              \n",
    "              \n",
    "    window2 = sg.Window('Compare',layout,finalize=True,resizable=True)\n",
    "    a = window2.CurrentLocation()\n",
    "    screen_width, screen_height = window2.get_screen_dimensions()\n",
    "    win_width, win_height = window2.size\n",
    "    x, y = (screen_width - win_width)//2, (screen_height - win_height)//2\n",
    "    x=200\n",
    "    y=200\n",
    "    window2.move(x, y)\n",
    "    tableFile1 = window2['-TABLEFILE-']\n",
    "    tableFile1.bind('<Button-1>', \"Click\")\n",
    "    headerStore[tableFile1] = header_list\n",
    "    return window2,tableFile1,valsFile1,rowFile1Colors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "\n",
    "def stringArgs(string):\n",
    "#  This is set to decode the extract string to get the location and name of the \n",
    "#  extracted data file\n",
    "    h =split(string)\n",
    "    inf = h.index(\"-f\")\n",
    "    inf = h[inf+1]\n",
    "    ot = h.index(\"-a\")\n",
    "    ot = h[ot+1]\n",
    "    of = h.index(\"-o\")\n",
    "    of = h[of+1]\n",
    "    inf=inf.replace(inf[-4:],ot)\n",
    "    f = inf.split(\"/\")\n",
    "    finalFile = f\"{bicHome}{of}{f[-1]}\"\n",
    "    return finalFile\n",
    " \n",
    "###################################################    \n",
    "\n",
    "def splitL(data):\n",
    "    if data:\n",
    "        head, *tail = data  # This is a nicer way of doing head, tail = data[0], data[1:]\n",
    "        return {head: splitL(tail)}\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def go_deeper(aDict,value,nit):\n",
    "    nit+=1\n",
    "    for k, v in aDict.items():\n",
    "         if not bool(v):            \n",
    "             aDict[k] = []\n",
    "             aDict[k].append(value)\n",
    "         elif isinstance(v,list):\n",
    "             aDict[k].append(value)\n",
    "         else:\n",
    "             go_deeper(v,value,nit)\n",
    "   \n",
    "    return aDict\n",
    "\n",
    "def init():\n",
    "    global dataSetsEtl\n",
    "    groups = []\n",
    "    desktop = pathlib.Path(\"/home/joe/bic_etl\")\n",
    "    runEtls = []\n",
    "    dataSets = []\n",
    "    # .rglob() produces a generator too\n",
    "    desktop.rglob(\"*\")\n",
    "    files = list(desktop.rglob(\"*\"))\n",
    "# Which you can wrap in a list() constructor to materialize\n",
    "    for ff in files:\n",
    "\n",
    "            if (str(ff).split(\"/\")[-1] == \"run_etl.json\"):     \n",
    "                a=str(ff).split(\"/\")\n",
    "                m = a.index(\"bic_etl\")\n",
    "                b = a[m+1:-1]\n",
    "                ll = splitL(b)\n",
    "                groups.append(ll)\n",
    "                runEtls.append(ff)\n",
    "            \n",
    "    print(f\"{len(runEtls)} run_etl.json files found\")    \n",
    "    \n",
    "    dataSets = []\n",
    "    groups = []\n",
    "    for file in runEtls:\n",
    "      f = open(file,\"r\")\n",
    "      data = json.load(f)\n",
    "      # print(file)\n",
    "      # print(\"----\")\n",
    "      a=str(file).split(\"/\")\n",
    "      m = a.index(\"bic_etl\")\n",
    "      b = a[m+1:-1]\n",
    "      ll = splitL(b)\n",
    "    #  print(ll)\n",
    "    #  groups.append(ll)\n",
    "      for val in data:\n",
    "            if \"title\" in val:\n",
    "                  title=val[\"title\"]\n",
    "    #              print(title,ll)\n",
    "                  nit=0\n",
    "                  ll = go_deeper(ll,title,nit)\n",
    "     #             print(ll)\n",
    "     #             groups.append(ll)\n",
    "            dataSets.append(val)\n",
    "    #  print(\"FF \",ll) \n",
    "      groups.append(ll)\n",
    "\n",
    "    datasets = []\n",
    "    dataSetsEtl={}\n",
    "    for val in dataSets:\n",
    "        if \"title\" in val:\n",
    "          datasets.append(val[\"title\"])\n",
    "          title=val[\"title\"]\n",
    "          dataSetsEtl[title] = {}  \n",
    "          for k,v in val.items():\n",
    "          #      print(k,v)\n",
    "                if k != \"title\":\n",
    "                    dataSetsEtl[title][k] = {}\n",
    "                    if isinstance(v,dict):\n",
    "                        for k1,v1 in v.items():\n",
    "                            dataSetsEtl[title][k][k1]=v1\n",
    "\n",
    "    return sorted(datasets)\n",
    "\n",
    "def map4x4(row):\n",
    "    \n",
    "    if isinstance(row[\"Data Link\"],str) and  len(row[\"Data Link\"]) == 9 and re.findall( \"\\w{4}-\\w{4}\",row[\"Data Link\"]):\n",
    "  #      link = '<a href=\"https://data.colorado.gov/dataset/{}\">{}</a>'.format(row[\"Data Link\"],row[\"Data Link\"])\n",
    "        \n",
    "        link = 'https://data.colorado.gov/dataset/{}'.format(row[\"Data Link\"])\n",
    "    else:\n",
    "        link = \"\"\n",
    "        \n",
    "    return link\n",
    "    \n",
    "#     mf[\"CIM Link\"] = mf.apply(map4x4,axis=1)\n",
    "\n",
    "#     mf=mf.loc[~mf[\"Standardized Title for Dataset\"].isna()]\n",
    "#     mfShort = mf[['Standardized Title for Dataset', 'Data Link','CIM Data Type','GoCodePublishYear','Standardized Short Description','CIM Link']]\n",
    "#     mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def exceptionLog(exception,funCall):\n",
    "  exception_message = str(exception)\n",
    "  exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "  filename = os.path.split(exception_traceback.tb_frame.f_code.co_filename)[1]\n",
    "  print(f\"{exception_message} {exception_type} {funCall}, Line {exception_traceback.tb_lineno}\")\n",
    "\n",
    "######################################################    \n",
    "    \n",
    "def getFile(how,file,WindowP):\n",
    "    if how == \"Local\":\n",
    "        if file[-3:].lower() == \"tsv\":\n",
    "            delim = \"\\t\"\n",
    "            df=pd.read_csv(file,encoding=\"latin\",delimiter=delim)\n",
    "        elif file[-4:].lower() == \"xlsx\":\n",
    "            df=pd.read_excel(file,engine=\"openpyxl\")\n",
    "        else:\n",
    "            try:\n",
    "                df=pd.read_csv(file)\n",
    "            except Exception as err:\n",
    "                print(\"Error, trying with encoding=latin\")\n",
    "                df=pd.read_csv(file,encoding=\"latin\")\n",
    "    elif how == \"Fetch\":\n",
    "       # print(\"Getting that web data\")\n",
    "        file=values[\"-WEB-\"]\n",
    "        getPrevFiles(2,file)\n",
    "\n",
    "  #      windowP[\"-PINFO-\"].update(f\"START reading WEB File:{file}:\")\n",
    "        df=pd.read_csv(file)\n",
    "  #      windowP[\"-PINFO-\"].update(f\"FINISHED reading WEB File:{file}:\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "##############################################################\n",
    "def setRowColors(lst,col1,col2,colsp,header):\n",
    "    count=0\n",
    "    colors = {}\n",
    "    nrec = header.index(\"% Missing\")\n",
    "    for vals in lst:\n",
    "        key = vals[0]\n",
    "        if count%2 == 0:\n",
    "            colors[key] = col1\n",
    "        else:\n",
    "            colors[key] = col2\n",
    "        if vals[nrec] > 99.0:\n",
    "            colors[key] = colsp\n",
    "        count+=1\n",
    "    colTab = []\n",
    "    for key,colr in colors.items():\n",
    "        colTab.append(colr)\n",
    "    rowNums = [num for num in range(0,len(colTab)+1)]\n",
    "    colText = [\"black\"]*len(colTab)\n",
    "    colrw = list(zip(rowNums,colTab))\n",
    "    print(\"SETTING COLS \",col1,col2)\n",
    "    return colrw\n",
    "\n",
    "###########################################################\n",
    "def sortTable(row,stats,table,event,header):\n",
    "    \n",
    "        e = table.user_bind_event \n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        if region == 'heading':\n",
    "            row = 0\n",
    "        elif region == 'cell':\n",
    "            row = int(table.Widget.identify_row(e.y))\n",
    "   \n",
    "        if row == 0:\n",
    "            colSortState = table.metadata\n",
    "            colClicked = int(table.Widget.identify_column(e.x)[1:])\n",
    "            header = headerStore[table]\n",
    "            statClicked = header[colClicked-1].strip()\n",
    "            print(\"clicked \",colClicked,statClicked,header)\n",
    "            colSortState[statClicked]*=-1\n",
    "            if colSortState[statClicked] == -1:\n",
    "                sortAsc=False\n",
    "            else:\n",
    "                sortAsc=True\n",
    "            if colClicked > 1:  # user number sort\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[1][statClicked],reverse=sortAsc))\n",
    "            else:\n",
    "                statsS = dict(sorted(stats.items(), key=lambda x: x[0],reverse=sortAsc))\n",
    "\n",
    "\n",
    "            statsVals=[]\n",
    "            for col in statsS:\n",
    "                 vals=[]\n",
    "                 vals.append(col)\n",
    "                 for k in header[1:]:\n",
    "                    vals.append(statsS[col][k.strip()])\n",
    "                 statsVals.append(vals)\n",
    "           # slen= len(statsVals)\n",
    "#             colorsTable = setRowColors(statsVals,\"#b3f0ff\",\"#33d6ff\",\"pink\",header_list)\n",
    "\n",
    "#             window['-TABLE-'].update(values=statsVals,row_colors=colorsTable)\n",
    "        return statsVals,colSortState\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "def dfAnalyze(df):\n",
    "    stats = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        typs = df[col].apply(type).value_counts().to_dict()\n",
    "        stats[col] = {}\n",
    "        if str in typs:\n",
    "           stats[col][\"string\"] = typs[str]\n",
    "        else:\n",
    "           stats[col][\"string\"] = 0\n",
    "\n",
    "        if int in typs:\n",
    "           stats[col][\"integer\"] = typs[int]\n",
    "        else:\n",
    "           stats[col][\"integer\"] = 0\n",
    "\n",
    "        if float in typs:\n",
    "           stats[col][\"float\"] = typs[float]\n",
    "        else:\n",
    "           stats[col][\"float\"] = 0\n",
    "\n",
    "        if bool in typs:\n",
    "           stats[col][\"boolean\"] = typs[bool]\n",
    "        else:\n",
    "           stats[col][\"boolean\"] = 0\n",
    "\n",
    "        stats[col][\"Missing\"] = df[col].isna().sum()\n",
    "        stats[col][\"% Missing\"] = round(df[col].isna().sum()/df.shape[0]*100,1)\n",
    "        \n",
    "    return stats\n",
    "\n",
    "############################################# \n",
    "\n",
    "def getValues(stats,header):\n",
    "\n",
    "    statsVals=[]\n",
    "    for col in sorted(stats.keys()):\n",
    "         vals=[]\n",
    "         vals.append(col)\n",
    "         for k in header[1:]:\n",
    "            vals.append(stats[col][k.strip()])\n",
    "         statsVals.append(vals)\n",
    "    return statsVals     \n",
    "############################################################\n",
    "\n",
    "def getFilesClicked(file,window):\n",
    "#         if len(values[\"-FILE1-\"]) > 0:\n",
    "#             file = values[\"-FILE1-\"]\n",
    "#         elif len(values[\"-WEB1-\"]) > 0:\n",
    "#             file = values[\"-WEB1-\"]\n",
    "        \n",
    "        df = getFile(\"Local\",file,window)\n",
    "        stats = dfAnalyze(df)\n",
    "\n",
    "        return df,stats\n",
    "\n",
    "############################################################\n",
    "\n",
    "def getRowClicked(table,columns):\n",
    "    col=\"\"\n",
    "    e = table.user_bind_event \n",
    "    region = table.Widget.identify('region', e.x, e.y)\n",
    "    if region == 'heading':\n",
    "        row = 0\n",
    "    elif region == 'cell':\n",
    "        row = int(table.Widget.identify_row(e.y))  \n",
    "        col = columns[row-1][0]\n",
    "    return row,col    \n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def showDFUN(col,unq,windowParent,colr1,colr2):\n",
    "    print(\"SHOWING BABY \")\n",
    "    valuesUNQ = list(zip(unq.index.tolist(),unq.tolist()))\n",
    "    hUNQ = []\n",
    "    hUNQ.append(\"Values\")\n",
    "    hUNQ.append(\"Count\")\n",
    "\n",
    "    \n",
    "    sortState = {}\n",
    "    for val in hUNQ:\n",
    "        sortState[val]=-1\n",
    "    layout2 = [    \n",
    "                   [sg.Text(f\"Showing unique Values for Column\"),sg.Text(f\" {col}\",text_color=\"red\"),sg.Text(f\" and Reg Ex\",text_color=\"black\")],\n",
    "                \n",
    "                   [sg.Button('Quit')],\n",
    "            \n",
    "                   [sg.Button('Write Unique'),\n",
    "                    sg.Table(values=valuesUNQ,\n",
    "                       background_color=colr1,vertical_scroll_only=False,col_widths=60,font='Courier 10 bold ' ,\n",
    "                       auto_size_columns=True,enable_events=True,def_col_width=25,text_color=\"black\",\n",
    "                       justification='right',alternating_row_color=colr2,\n",
    "                       key='-TABLE-', headings = hUNQ,metadata=sortState)]\n",
    "            ]\n",
    "    window2 = sg.Window(f\"Unique\", layout2,finalize=True,resizable=True, grab_anywhere=False)\n",
    "\n",
    "    table = window2['-TABLE-']\n",
    "    table.bind('<Button-1>', \"Click\")\n",
    "    return window2,table,valuesUNQ,hUNQ\n",
    "\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def sortUniqe(table,window,dataStore,headerStore):\n",
    "    try:\n",
    "        e = table.user_bind_event\n",
    "        region = table.Widget.identify('region', e.x, e.y)\n",
    "        sortAsc = {}\n",
    "        sortAsc[1] =False\n",
    "        sortAsc[-1]=True\n",
    "   #     print(\"R \",region)\n",
    "        if region == 'heading':\n",
    "            values = dataStore[table]\n",
    "           \n",
    "            header = headerStore[table]\n",
    "           \n",
    "            column = int(table.Widget.identify_column(e.x)[1:])\n",
    "            col=header[column-1]\n",
    "          \n",
    "            sortState = table.metadata\n",
    "            sortState[col]*=-1\n",
    "            table.metadata = sortState\n",
    "          \n",
    "            values = sorted(values, key=lambda element: (element[column-1]),reverse=sortAsc[sortState[col]]) \n",
    "           \n",
    "            window[\"-TABLE-\"].update(values=values)\n",
    "            dataStore[table] = values\n",
    "    except Exception as err:\n",
    "        exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    "                    \n",
    "        \n",
    "\n",
    "def wrap(string, lenght=60):\n",
    "    if isinstance(string,str):\n",
    "       return '\\n'.join(textwrap.wrap(string, lenght))\n",
    "    else:\n",
    "        return \"\"\n",
    "def runETL(k):\n",
    "    global extract,a,string\n",
    "    text2 = \"\"\n",
    "  #  print(k)\n",
    "## Build Summary Text string\n",
    "    for ky1 in dataSetsEtl[k].keys():\n",
    "        text2+=f\"{ky1}:\\n\" \n",
    "        for k2,v2 in dataSetsEtl[k][ky1].items(): \n",
    "            sl = 10 - len(k2)\n",
    "            s = \" \"*sl\n",
    "        \n",
    "            if isinstance(v2,list) == False:\n",
    "                text2+=f\"    {k2:10s}{s} :  {v2}\\n\"\n",
    "            else:\n",
    "                text2+=f\"    {k2:10s}{s} : {v2[0]}\\n\"\n",
    "                if len(v2) > 1:\n",
    "                    for val in v2[1:]:\n",
    "                        text2+= f\"                   {s} : {val}\\n\"\n",
    "\n",
    "        text2+=f\"\\n\\n\"\n",
    "## Build actions\n",
    "    extract = \"\"\n",
    "    if 'extract' in dataSetsEtl[ds]:\n",
    "        if (dataSetsEtl[ds]['extract']['language'] == 'node'):\n",
    "            pgm =  dataSetsEtl[ds]['extract']['file']\n",
    "            options=\"\"\n",
    "            if 'options' in dataSetsEtl[ds]['extract']:\n",
    "\n",
    "                for opts in dataSetsEtl[ds]['extract']['options']:\n",
    "                    options+= f\" {opts}\" \n",
    "            extract = f\"node /home/joe/bic_etl/{pgm} {options}\"\n",
    "        #    print(extract)\n",
    "    text2+=f\"\\n\\nActions Strings\\nExtract\\n{extract}\"\n",
    "        \n",
    "    return text2,extract\n",
    "    \n",
    "    \n",
    "def cronGUI():\n",
    "    global ds,text2,a,string,numWindows,color1,color2,file\n",
    "    dataStore = {}\n",
    "    datasets = init()\n",
    "    print(\"LL \",len(dataSetsEtl))\n",
    "    mf = pd.read_excel(\"BICDataInventoryandMetadata.xlsx\",skiprows=0,sheet_name=\"Inventory_Active\",engine=\"openpyxl\")\n",
    "    \n",
    "    mf[\"CIM Link\"] = mf.apply(map4x4,axis=1)\n",
    "\n",
    "    mf=mf.loc[~mf[\"Standardized Title for Dataset\"].isna()]\n",
    "    mfShort = mf[['Standardized Title for Dataset', 'Data Link','CIM Data Type','GoCodePublishYear','Standardized Short Description','CIM Link']]\n",
    "    mfShort[\"Standardized Title for Dataset\"] = mfShort[\"Standardized Title for Dataset\"].astype(str)   \n",
    "    \n",
    "    header_list = list(mfShort.columns)\n",
    "    # mfV = []\n",
    "    # a = [\"\",\"\",nan,nan,\"\"]\n",
    "    # mfV.append(a)\n",
    "    layout = [\n",
    "             [sg.Text(\"BIC Cron DataSets\")],\n",
    "             [sg.Combo(datasets,enable_events=True,key=\"-DATASET-\",font='Courier 10 bold ')],\n",
    "              [sg.Button('Quit'),sg.Button(\"Plot Crons\")],\n",
    "             [sg.Button(\"GO\")],\n",
    "              [sg.Button(\"Extract\",font='Courier 10 bold ',key=\"-EXTRACT-\",visible=False),\n",
    "               sg.Button(\"Analyze-Extr\",font='Courier 10 bold ',key=\"-EXTRACTANAL-\",visible=False),\n",
    "               sg.Text(\"\",visible=False,font='Courier 10 bold ',key=\"-EXTRACTINFO-\")],\n",
    "              [sg.Button('Go to CIM Dataset',visible=False,key=\"-LINK-\",metadata=\"\")],\n",
    "              [sg.Text(text=\"Dataset Summary\",enable_events=True,font='Courier 15 bold ',background_color=\"blue\",key=\"-OUTPUT-\",size=[70,10]),\n",
    "       #       [sg.Multiline(default_text=\"Dataset Summary\",key=\"-OUTPUT-\",size=[70,10]),\n",
    "\n",
    "               sg.Multiline(default_text=\"ETL Summary\",key=\"-ETL-\",size=[70,20],font='Courier 15 bold ')\n",
    "              ]\n",
    "\n",
    "       ]\n",
    "    # Create the Window\n",
    "    sg.theme('Dark Green 5')\n",
    "    window2 = sg.Window('ETL', layout,finalize=True,resizable=True)\n",
    "    #window = sg.Window('Window Title', layout, web_port=2222, web_start_browser=False)\n",
    "    #table = window2['-TABLE2-']\n",
    "\n",
    "    #window2.move(window.current_location()[0]+600, window.current_location()[1])\n",
    "    try: \n",
    "        while True:\n",
    "\n",
    "         #   event, values = window2.read()\n",
    "            wid, event, values = sg.read_all_windows()\n",
    "            print('event: ',event, 'values: ',values)\n",
    " #           print(\"W2\",event,values)\n",
    "        #    window, event, values = sg.read_all_windows()\n",
    "            if event == sg.WIN_CLOSED or event == 'Quit':\n",
    "                window2.close()\n",
    "        #        sys.exit(1)\n",
    "                what = \"QUIT\"\n",
    "                break\n",
    "           # elif event == \"-DATASET-\":\n",
    "            elif event == \"GO\":#\n",
    "\n",
    "                \n",
    "                (ds)  = list(values.items())\n",
    "                ds=ds[0][1]\n",
    "                ds = \"Paid Solicitors Disclosed on Charity Registration Forms in Colorado\"\n",
    "           #     print(\"DS \",ds)\n",
    "                mmf = mfShort.loc[mfShort[\"Standardized Title for Dataset\"].str.strip() == ds.strip()]\n",
    "                if mmf.shape[0] > 0:\n",
    "                #            mmf[\"Standardized Short Description\"] = mmf[\"Standardized Short Description\"].map(wrap)          \n",
    "                    text = f\"Title             : {mmf['Standardized Title for Dataset'].values.tolist()[0]}\\nSocrata        : {mmf['Data Link'].values.tolist()[0]}\\nData Type    : {mmf['CIM Data Type'].values.tolist()[0]}\\nPublish Year: {mmf['GoCodePublishYear'].values.tolist()[0]}\\nCIM Link : {mmf['CIM Link'].values.tolist()[0]}\\nDescription  : {mmf['Standardized Short Description'].values.tolist()[0]}\"            \n",
    "                   # display(mmf)\n",
    "                else:\n",
    "                    text = \"None\"\n",
    "                if ds in dataSetsEtl:\n",
    "                      text2,extract = runETL(ds)\n",
    "                else:\n",
    "                      text2=\"\"\n",
    "                      extract = \"\"\n",
    "                if len(extract) > 10:\n",
    "                    window2[\"-EXTRACT-\"].update(visible=True)\n",
    "          #      print(\"T2\",text2)\n",
    "                window2[\"-OUTPUT-\"].update(text)\n",
    "                window2[\"-ETL-\"].update(text2)\n",
    "                link =  mmf['CIM Link'].values.tolist()[0]\n",
    "           #     print(\"Link \",mmf['CIM Link'],link.find(\"http\"))\n",
    "                \n",
    "                if link.find(\"http\") > -1:\n",
    "                     window2[\"-LINK-\"].update (visible=True)\n",
    "                else:\n",
    "                     window2[\"-LINK-\"].update (visible=False)\n",
    "               \n",
    "            elif event == \"-LINK-\":\n",
    "                    print(\"Going To: \",link) \n",
    "                    if len(link) > 10:\n",
    "                        webbrowser.open(link)\n",
    "            elif event == \"Plot Crons\":    \n",
    "                plotCrons(crons_all)\n",
    "                \n",
    "            elif event == \"-EXTRACT-\":\n",
    "                a=subprocess.run(extract,shell=True,capture_output=True,text=True)\n",
    "                string= \"\\n\\n-------------------------------------\\n\"\n",
    "                string+= \"Extract Output\\n\"\n",
    "                if len(a.stderr) > 0:\n",
    "                    string+= \"fError:\\n {a.stderr}\"\n",
    "                string+=f\"STDOUT: {a.stdout}\"\n",
    "                window2[\"-ETL-\"].update(string,append=True)\n",
    "                sx = string.find(\"successfully download to\")\n",
    "                string[sx+25:]\n",
    "                sxo = string[sx+25:].find(\"!\")\n",
    "              #  print(sxo)\n",
    "                file=f\"/home/joe/bic_etl{string[sx+25:sx+25+sxo]}\"\n",
    "                \n",
    "               # print(file)\n",
    "                if os.path.isfile(file):\n",
    "                    print(f\"{file} FOUND FOUND FOUND\")\n",
    "                    window2[\"-EXTRACTANAL-\"].update(visible=True)\n",
    "                    fileStats = os.stat(file)\n",
    "                    dt = datetime.fromtimestamp(fileStats.st_ctime)\n",
    "                    string = f\"{fileStats.st_size:,} bytes Created: {dt}  file: {file}\"\n",
    "                    window2[\"-EXTRACTINFO-\"].update(string,visible=True)\n",
    "                   \n",
    "            \n",
    "           \n",
    "            elif event == \"-EXTRACTANAL-\":\n",
    "                file=stringArgs(extract)\n",
    "                print(\"FILE \",file)\n",
    "                df1,stats1 = getFilesClicked(file,window2)\n",
    "                color1 = colorPairs[numWindows][0]\n",
    "                color2 = colorPairs[numWindows][1]\n",
    "                \n",
    "                numWindows+=1\n",
    "                if numWindows > len(colorPairs):\n",
    "                    numWindows=0\n",
    "                    \n",
    "                WindowC,tabl1,valsFile1,rowFile1Colors = compareWindow(stats1,df1,file)\n",
    "                dataStore[tabl1]=valsFile1\n",
    "                windowsOpen[\"main\"].append(WindowC)\n",
    "            \n",
    "            ###########\n",
    "            elif event == \"-TABLEFILE-Click\":\n",
    "               \n",
    "                row,col=getRowClicked(tabl1,valsFile1)\n",
    "                print(\"R,C \",row,col)\n",
    "                if row == 0:\n",
    "                   print(\"HEADER BABY\",col)\n",
    "                   valsFile1,columnSortStateTable1 = sortTable(row,stats1,tabl1,event,header_list)          \n",
    "        #           setRowColors(valsFile1,\"#b3f0ff\",\"#33d6ff\",\"pink\",header_list)\n",
    "                   wid[\"-TABLEFILE-\"].update(values=valsFile1,row_colors=rowFile1Colors)\n",
    "                   wid[\"-TABLEFILE-\"].metadata=columnSortStateTable1\n",
    "                else:\n",
    "                    unq = df1[col].value_counts()\n",
    "                    w,t,values,uHead = showDFUN(col,unq,wid,\"#b3f0ff\",\"#33d6ff\")\n",
    "                    dataStore[t] = values\n",
    "                    headerStore[t] = uHead\n",
    "                    \n",
    "            elif event == \"-TABLE-Click\":\n",
    "                print(\"TC \",wid)\n",
    "                table = wid['-TABLE-']\n",
    "                print(\"TC \")\n",
    "                \n",
    "                sortUniqe(table,wid,dataStore,headerStore)\n",
    "                \n",
    "    except  Exception as err: \n",
    "       exceptionLog(err,inspect.currentframe().f_code.co_name)\n",
    " \n",
    "for wid in windowsOpen[\"main\"]:\n",
    "    print(\"window MA\",wid)\n",
    "    if wid:\n",
    "        print(\"cosing \",wid)\n",
    "        wid.close()\n",
    "        wid = None\n",
    "\n",
    "cronGUI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74538df7-0025-4f20-a71c-ec6b28b1d11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00464281-1f1a-4c2d-a0c1-a8828e3681ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb00a9fe-0918-46b3-95a9-60613e2f6bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52102185-e304-401b-bca0-e74d91dd7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timestamp = datetime.datetime.fromtimestamp(fileStats.st_ctime)\n",
    "print(timestamp.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfc6de-c80b-40b9-a3a7-f1f026b0454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.fromtimestamp(fileStats.st_atime)\n",
    "print(timestamp.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f6cb2-ee5f-418a-9614-f37c05e451ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fileBrowser",
   "language": "python",
   "name": "filebrowser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
